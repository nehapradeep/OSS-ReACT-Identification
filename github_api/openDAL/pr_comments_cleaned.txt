In which PR we bump MSRV? I remember @Xuanwo suppose to hold on that the last time.

> for the one connection it will not, and its sqlite most of the case is one user\r\n\r\nHi, opendal has native support for `op.read_with(path).concurrent(8)`. 

Also the logo?

Thanks for the contribution !

I have enabled the CI, please try again.

Nodejs does have an `exists` API but deprecated: https://nodejs.org/api/fs.html#fsexistspath-callback\r\n\r\nMaybe we can add `access` API in the future.

will do this in this PR

Thank you @dqhl76 for the review.

Inviting @erickguan for a review.\r\n

And just search some of popular lua projects\nLike Kong and Skynet\nexists is better than is_exist\n\nhttps://github.com/Kong/kong/blob/master/spec/01-unit/03-conf_loader_spec.lua\n\nhttps://github.com/cloudwu/skynet/blob/master/lualib/skynet/db/redis.lua

copy that, and make sense closing this

> Interesting. As in markdown they should be the same.\r\n\r\nYes, but we have special handling for links like this to ensure they generate correctly outside of GitHub.

Thank you @tisonkun for the review.

Thank you @dqhl76 for the review.

i also fixed one unit test failing on my local machine, but looks like it is failing in ci. i will revert it later

Considering that we will be adding more arguments for the list, how about following the same pattern to add this? https://github.com/apache/opendal/pull/5664\r\n\r\n> It is a little bit tricky to add the unit test directly, given `fs` service it self does not support recursively list.\r\n\r\nfs should support `recursive` list since we have applied some wrapper for it

> fs should support recursive list since we have applied some wrapper for it\r\n\r\nwhich service should i use? do i need to verify the capability as well? i observed error when specify the `capability.list_with_recursive`. \r\n\r\ni will update the code later to align with the pr you provided. 

> which service should i use? do i need to verify the capability as well? i observed error when specify the `capability.list_with_recursive`.\r\n\r\nI remember that all services implementing `list` will automatically support `recursive`. I will double-check this later.

> I remember that all services implementing `list` will automatically support `recursive`. I will double-check this later.\r\n\r\nagain, i may be wrong, but looks like the option for fs list is not used. so i think there is no recursive supprot for fs\r\n\r\nhttps://github.com/apache/opendal/blob/a6b04789fed735104b9a080eb4d213dbae0c38d0/core/src/services/fs/backend.rs#L364

And it might be a breaking change, if merge doc things is needed I think

HiÔºå @yihong0618Ôºå the upstream fixed https://github.com/veeso/suppaftp/issues/100, maybe you wanna try upgrade suppaftp and test if everything works as expected?

> HiÔºå @yihong0618Ôºå the upstream fixed https://github.com/veeso/suppaftp/issues/100, maybe you wanna try upgrade suppaftp and test if everything works as expected?\n\nwill try this tonight

@Xuanwo \r\n\r\nChore the dep but the `futures-rustls` doc in README is wrong they did not chore it...

Note that pulling in aws-lc-rs which uses `cmake` may cause problem when cross compiling Python wheels.

> Note that pulling in aws-lc-rs which uses `cmake` may cause problem when cross compiling Python wheels.\r\n\r\nwill take a look 

interest fail https://github.com/apache/opendal/actions/runs/13766696790/job/38494868754

> interest fail https://github.com/apache/opendal/actions/runs/13766696790/job/38494868754\r\n\r\nOh, tracked in https://github.com/apache/opendal/issues/5728

cc @meteorgan, would you mind taking a look at this PR? :)

Hi, this PR\

Thank you @yihong0618 for highlighting this.

@Xuanwo  so now with this API in place if i want to copy a file from local fs to s3 in near zero copy manner, how will a sample code look?\r\n\r\nbecause using `tokio::io::copy` or `futures::io::copy` will require AsyncRead and AsyncWrite inplementations.

> @Xuanwo so now with this API in place if i want to copy a file from local fs to s3 in near zero copy manner, how will a sample code look?\r\n\r\nHi, we can use [`SinkExt::send_all`](https://docs.rs/futures/latest/futures/prelude/sink/trait.SinkExt.html#method.send_all) to send stream into the sink in this way:\r\n\r\n```rust\r\nlet mut osink = op.writer(path).await?.into_sink();\r\nlet mut ostream = op.reader(path).await?.into_stream(..).await?;\r\nosink.send_all(&mut ostream).await?;\r\nosink.close().await?;\r\n```

@Xuanwo BufferStream is still not completely public, probably needs to be added to exports.\r\n\r\n`pub(crate) use buffer_stream::BufferStream;`

> @Xuanwo BufferStream is still not completely public, probably needs to be added to exports.\r\n> \r\n> `pub(crate) use buffer_stream::BufferStream;`\r\n\r\nFixed in https://github.com/apache/opendal/pull/5730

You are welcome!

Thank you @dqhl76 for the review.

Do we have a ticket on INFRA or mailing list for the background?\r\n\r\nI suppose the INFRA team or privacy@apache.org would have some inputs.

if you want to reintroduce the images perhaps you could put them in https://github.com/apache/opendal/tree/main/website/static/img or similar

Hi, @meteorgan, you are now an OpenDAL committer and can submit PRs directly from the remote `apache` repository. This allows all your commits to be tested against our real services.

> Hi, @meteorgan, you are now an OpenDAL committer and can submit PRs directly from the remote `apache` repository. This allows all your commits to be tested against our real services.\r\n\r\nGot it. Thanks for the reminder.

Hi, all opendal pmc members, please help review this post.

Thank you @tisonkun and @xyjixyjixyji for the review.

I also started a discussion about the issue I encountered in this PR: https://github.com/apache/opendal/discussions/5674

Hi, @geruh, this PR is almost ready to go. We are waiting for a fix on main branch to bring our CI back.

Thank you @messense for the review.

We should need an upgrade note for this somehow breaking/notable change.

> We should need an upgrade note for this somehow breaking/notable change.\r\n\r\nYes!

BTW, I think we can close #4896 once we merge this PR.

Thank you @dqhl76 for the review.

Thank you @meteorgan for the review!

~~currently only `minio_s3` failed, idk the reason.~~ fixed.\r\n

ok, I find the problem.\r\n\r\nhttps://github.com/apache/opendal/blob/7455995092c697863ab6d326b962b8543756c0ca/core/src/layers/blocking.rs#L216\r\n\r\nthe origin crate use `&str` so\r\n\r\n1. change the whole crate to use `AsRef<Path>`, too many changes.\r\n2. do the type change on python binding, I prefer this.\r\n

Thank you @asukaminato0721 for this great work! Would you like to add some tests to the python code to ensure it works as expected?

@Xuanwo added

LGTM üéâ 

> The test workflow in `.github/services` is missing, we should add one.\r\n\r\nI remembered that we failed to set up a OneDrive test.

I generated a token from a personal test account with `Files.ReadWrite`. [This workflow run](https://github.com/apache/opendal/actions/runs/13465739880/job/37631118257?pr=5632).\r\n\r\nAdditional permissions are useful for [API Graph explorer](https://developer.microsoft.com/en-us/graph/graph-explorer) which I recommend:\r\n\r\n- DelegatedPermissionGrant.ReadWrite.All\r\n- Directory.Read.All\r\n\r\nWhat do you want me next? These actions look sensible:\r\n\r\n1. Merge this PR as is.\r\n2. Set up an OpenDAL test account.\r\n3. Fix bugs in a new PR.

Rebased and ready.\r\n\r\n<details>\r\n\r\n<summary>OPENDAL_TEST=onedrive cargo test behavior  --features tests,services-onedrive -- --show-output</summary>\r\n\r\n```\r\n   Compiling opendal v0.52.0 (/home/erickg/Dev/opendal/core)\r\n    Finished `test` profile [unoptimized + debuginfo] target(s) in 11.49s\r\n     Running unittests src/lib.rs (target/debug/deps/opendal-9022af4dd162386a)\r\n\r\nrunning 0 tests\r\n\r\nsuccesses:\r\n\r\nsuccesses:\r\n\r\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 134 filtered out; finished in 0.00s\r\n\r\n     Running tests/behavior/main.rs (target/debug/deps/behavior-c8073076fdb6f2e9)\r\n\r\nrunning 102 tests\r\ntest behavior::test_delete_with_version                       ... ok\r\ntest behavior::test_delete_with_not_existing_version          ... ok\r\ntest behavior::test_list_with_start_after                     ... ok\r\ntest behavior::test_list_with_versions_and_start_after        ... ok\r\ntest behavior::test_reader_with_if_modified_since             ... ok\r\ntest behavior::test_reader_with_if_unmodified_since           ... ok\r\ntest behavior::test_reader_with_if_none_match                 ... ok\r\ntest behavior::test_read_with_if_match                        ... ok\r\ntest behavior::test_read_with_if_none_match                   ... ok\r\ntest behavior::test_read_with_if_modified_since               ... ok\r\ntest behavior::test_read_with_if_unmodified_since             ... ok\r\ntest behavior::test_list_files_with_versions                  ... ok\r\ntest behavior::test_list_files_with_deleted                   ... ok\r\ntest behavior::test_list_with_versions_and_limit              ... ok\r\ntest behavior::test_reader_with_if_match                      ... ok\r\ntest behavior::test_read_with_override_content_type           ... ok\r\ntest behavior::test_read_with_version                         ... ok\r\ntest behavior::test_read_with_not_existing_version            ... ok\r\ntest behavior::test_read_with_override_content_disposition    ... ok\r\ntest behavior::test_read_with_override_cache_control          ... ok\r\ntest behavior::test_read_not_exist                            ... ok\r\ntest behavior::test_check                                     ... ok\r\ntest behavior::test_list_non_exist_dir                        ... ok\r\ntest behavior::test_stat_with_if_match                        ... ok\r\ntest behavior::test_stat_with_if_none_match                   ... ok\r\ntest behavior::test_stat_with_if_modified_since               ... ok\r\ntest behavior::test_stat_with_if_unmodified_since             ... ok\r\ntest behavior::test_stat_with_override_cache_control          ... ok\r\ntest behavior::test_stat_with_override_content_disposition    ... ok\r\ntest behavior::test_stat_with_override_content_type           ... ok\r\ntest behavior::test_stat_root                                 ... ok\r\ntest behavior::test_stat_with_version                         ... ok\r\ntest behavior::stat_with_not_existing_version                 ... ok\r\ntest behavior::test_list_root_with_recursive                  ... ok\r\ntest behavior::test_write_with_empty_content                  ... ok\r\ntest behavior::test_write_with_dir_path                       ... ok\r\ntest behavior::test_delete_not_existing                       ... ok\r\ntest behavior::test_write_with_cache_control                  ... ok\r\ntest behavior::test_write_with_content_type                   ... ok\r\ntest behavior::test_write_with_content_disposition            ... ok\r\ntest behavior::test_write_with_content_encoding               ... ok\r\ntest behavior::test_write_with_if_none_match                  ... ok\r\ntest behavior::test_write_with_if_not_exists                  ... ok\r\ntest behavior::test_write_with_if_match                       ... ok\r\ntest behavior::test_write_with_user_metadata                  ... ok\r\ntest behavior::test_read_with_dir_path                        ... ok\r\ntest behavior::test_writer_write                              ... ok\r\ntest behavior::test_stat_not_exist                            ... ok\r\ntest behavior::test_writer_write_with_concurrent              ... ok\r\ntest behavior::test_writer_sink                               ... ok\r\ntest behavior::test_writer_sink_with_concurrent               ... ok\r\ntest behavior::test_writer_abort                              ... ok\r\ntest behavior::test_create_dir                                ... ok\r\ntest behavior::test_writer_futures_copy                       ... ok\r\ntest behavior::test_writer_futures_copy_with_concurrent       ... ok\r\ntest behavior::test_writer_return_metadata                    ... ok\r\ntest behavior::test_stat_dir                                  ... ok\r\ntest behavior::test_delete_empty_dir                          ... ok\r\ntest behavior::test_writer_abort_with_concurrent              ... ok\r\ntest behavior::test_create_dir_existing                       ... ok\r\ntest behavior::test_blocking_create_dir                       ... ok\r\ntest behavior::test_list_sub_dir                              ... ok\r\ntest behavior::test_blocking_read_not_exist                   ... ok\r\ntest behavior::test_delete_file                               ... ok\r\ntest behavior::test_stat_with_special_chars                   ... ok\r\ntest behavior::test_read_range                                ... ok\r\ntest behavior::test_delete_with_special_chars                 ... ok\r\ntest behavior::test_write_returns_metadata                    ... ok\r\ntest behavior::test_blocking_create_dir_existing              ... ok\r\ntest behavior::test_list_prefix                               ... ok\r\ntest behavior::test_stat_nested_parent_dir                    ... ok\r\ntest behavior::test_blocking_stat_not_exist                   ... ok\r\ntest behavior::test_blocking_write_with_dir_path              ... ok\r\ntest behavior::test_write_only                                ... ok\r\ntest behavior::test_blocking_stat_dir                         ... ok\r\ntest behavior::test_list_dir_with_file_path                   ... ok\r\ntest behavior::test_read_full                                 ... ok\r\ntest behavior::test_stat_file                                 ... ok\r\ntest behavior::test_list_file_with_recursive                  ... ok\r\ntest behavior::test_write_with_special_chars                  ... ok\r\ntest behavior::test_stat_not_cleaned_path                     ... ok\r\ntest behavior::test_read_with_special_chars                   ... ok\r\ntest behavior::test_list_dir                                  ... ok\r\ntest behavior::test_blocking_delete_file                      ... ok\r\ntest behavior::test_blocking_write_file                       ... ok\r\ntest behavior::test_blocking_stat_with_special_chars          ... ok\r\ntest behavior::test_blocking_remove_one_file                  ... ok\r\ntest behavior::test_blocking_read_range                       ... ok\r\ntest behavior::test_blocking_stat_file                        ... ok\r\ntest behavior::test_reader                                    ... ok\r\ntest behavior::test_blocking_write_with_special_chars         ... ok\r\ntest behavior::test_remove_one_file                           ... ok\r\ntest behavior::test_blocking_write_returns_metadata           ... ok\r\ntest behavior::test_blocking_read_full                        ... ok\r\ntest behavior::test_list_dir_with_recursive_no_trailing_slash ... ok\r\ntest behavior::test_list_nested_dir                           ... ok\r\ntest behavior::test_writer_write_with_overwrite               ... ok\r\ntest behavior::test_list_dir_with_recursive                   ... ok\r\ntest behavior::test_list_empty_dir                            ... ok\r\ntest behavior::test_remove_all                                ... ok\r\ntest behavior::test_list_rich_dir                             ... ok\r\ntest behavior::test_delete_stream                             ... ok\r\n\r\ntest result: ok. 102 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 38.88s\r\n\r\n```\r\n\r\n</details>

LGTM. Thanks for working on this. @erickguan 

@meteorgan happy to help!

By the way, @erickguan would you like to help fix the conflicts?

Sure, I will rebase it and ping you.

Rebased @Xuanwo 

Thank you @erickguan for this!

<!-- __CODSPEED_PERFORMANCE_REPORT_COMMENT__ -->\n<!-- __CODSPEED_INSTRUMENTATION_PERFORMANCE_REPORT_COMMENT__ -->\n\n## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/otel-028)\n\n### Merging #5625 will **degrade performances by 21.21%**\n\n<sub>Comparing <code>otel-028</code> (b92e819) with <code>main</code> (69c8fab)</sub>\n\n\n\n### Summary\n\n`‚ùå 12` regressions  \n`‚úÖ 61` untouched benchmarks  \n\n\n> :warning: _Please fix the performance issues or [acknowledge them on CodSpeed](https://codspeed.io/apache/opendal/branches/otel-028)._\n\n### Benchmarks breakdown\n\n|     | Benchmark | `BASE` | `HEAD` | Change |\n| --- | --------- | ----------------------- | ------------------- | ------ |\n| ‚ùå | `` buffer 256 KiB * 32 chunk `` | 125.3 ns | 154.4 ns | -18.88% |\n| ‚ùå | `` buffer 256 KiB * 4 chunk `` | 125.3 ns | 154.4 ns | -18.88% |\n| ‚ùå | `` buffer 4.00 MiB * 32 chunk `` | 125.3 ns | 154.4 ns | -18.88% |\n| ‚ùå | `` buffer 4.00 MiB * 4 chunk `` | 125.3 ns | 154.4 ns | -18.88% |\n| ‚ùå | `` 256 KiB * 1000k chunk `` | 125.3 ns | 154.4 ns | -18.88% |\n| ‚ùå | `` 256 KiB * 1000k truncate `` | 216.7 ns | 275 ns | -21.21% |\n| ‚ùå | `` 256 KiB * 100k chunk `` | 125.3 ns | 154.4 ns | -18.88% |\n| ‚ùå | `` 256 KiB * 100k truncate `` | 216.7 ns | 275 ns | -21.21% |\n| ‚ùå | `` 256 KiB * 10k chunk `` | 125.3 ns | 154.4 ns | -18.88% |\n| ‚ùå | `` 256 KiB * 10k truncate `` | 216.7 ns | 275 ns | -21.21% |\n| ‚ùå | `` 256 KiB * 1k chunk `` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `` 256 KiB * 1k truncate `` | 216.7 ns | 275 ns | -21.21% |\n

@Xuanwo Hi, where can I add test cases for newly submitted code?

> @Xuanwo Hi, where can I add test cases for newly submitted code?\r\n\r\nping @Xuanwo 

> @Xuanwo Hi, where can I add test cases for newly submitted code?\r\n\r\nOpenDAL performs behavior tests on all services. Please check https://github.com/apache/opendal/blob/main/core/tests/behavior/README.md for more details.

> > @Xuanwo Hi, where can I add test cases for newly submitted code?\r\n> \r\n> OpenDAL performs behavior tests on all services. Please check https://github.com/apache/opendal/blob/main/core/tests/behavior/README.md for more details.\r\n\r\nI have a question. These methods were not actually implemented before. How did the test cases pass?

@Xuanwo @meteorgan CI passed. PTAL

For error like:\r\n\r\n```rust\r\n---- behavior::test_blocking_write_with_append_returns_metadata ----\r\ntest panicked: append to an existing file must success: AlreadyExists (persistent) at write => /tmp/opendal/f286eb91-202c-490b-99dd-04415556e07e/c9203715-f602-4237-9e34-86ed1c8d4297 for client 127.0.0.1 already exists\r\n\tat org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:388)\r\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2536)\r\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2433)\r\n\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:791)\r\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:475)\r\n\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\r\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)\r\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)\r\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)\r\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\r\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\r\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)\r\n```\r\n\r\nYou might need to check the `WirteOptions` inside `Access::write` call, this function might be useful: https://docs.rs/hdfs-native/0.11.1/hdfs_native/client/struct.Client.html#method.append

If you want debug them locally, you can use `docker compose -f <docker-compose-file>` and `cargo test behavior --features=tests,services-hdfs-native` for them.

<!-- __CODSPEED_PERFORMANCE_REPORT_COMMENT__ -->\n<!-- __CODSPEED_INSTRUMENTATION_PERFORMANCE_REPORT_COMMENT__ -->\n\n## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/remove-dead-services)\n\n### Merging #5616 will **not alter performance**\n\n<sub>Comparing <code>remove-dead-services</code> (1b49292) with <code>main</code> (dafdee1)</sub>\n\n\n\n### Summary\n\n`‚úÖ 73` untouched benchmarks  \n\n\n\n

<!-- __CODSPEED_PERFORMANCE_REPORT_COMMENT__ -->\n<!-- __CODSPEED_INSTRUMENTATION_PERFORMANCE_REPORT_COMMENT__ -->\n\n## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/fix-content-encoding-test)\n\n### Merging #5614 will **not alter performance**\n\n<sub>Comparing <code>fix-content-encoding-test</code> (3bd5998) with <code>main</code> (30dd2a8)</sub>\n\n\n\n### Summary\n\n`‚úÖ 73` untouched benchmarks  \n\n\n\n

Do I need to add some other tests? So far I have tested this with my own program and `stat` and `write` work as expected

> Do I need to add some other tests? So far I have tested this with my own program and `stat` and `write` work as expected\r\n\r\nWe have integration tests for gcs, so it should fine as is.

Okay, I tested `presign` without `predefinedAcl`, and now it works. That problem should be addressed in a separate PR.\r\n\r\nIn my opinion this PR is ready to be merged

Sorry, opened by mistake

```\r\n  2025-02-06T17:47:18.460667Z DEBUG opendal::services::swift::backend: swift: parsing user metadata from headers: {"content-type": "application/octet-stream", "content-length": "577389", "x-object-meta-location": "everywhere", "etag": "11faa613117db981663cbfaf955e9fbb", "last-modified": "Thu, 06 Feb 2025 17:47:19 GMT", "x-timestamp": "1738864038.41972", "accept-ranges": "bytes", "x-trans-id": "txb1b180da21ac419b815c8-0067a4f5a6", "x-openstack-request-id": "txb1b180da21ac419b815c8-0067a4f5a6", "date": "Thu, 06 Feb 2025 17:47:18 GMT"}\r\n    at src/services/swift/backend.rs:239\r\n\r\n  2025-02-06T17:47:18.460698Z DEBUG opendal::services::swift::backend: swift: parsed user metadata: {}\r\n    at src/services/swift/backend.rs:242\r\n\r\n  2025-02-06T17:47:18.460865Z DEBUG opendal::services: service=swift name= path=88a28177-2f9a-4352-82cb-7fea1c287579: stat finished\r\n    at src/layers/logging.rs:220\r\n\r\nthread \

@Xuanwo CI passed. PTAL

I only ported part of the apis so the test can pass. And currently all result is using unwrap (as a first version).\r\n

Thank you so much, @asukaminato0721, for working on this. I will start reviewing this PR later next week. Wishing you a wonderful holiday in the meantime!

@Xuanwo now it\

Hi, @asukaminato0721 would you like to create a tracking issue for the following tasks? I think we need examples, tests, docs and figure how to release it.

Looks like korandoru/hawkeye is up-to-date now, so this is no longer needed.

@Xuanwo can you plz review this PR?

Need a new release tool to update versions based on a centralized file.

<!-- __CODSPEED_PERFORMANCE_REPORT_COMMENT__ -->\n<!-- __CODSPEED_INSTRUMENTATION_PERFORMANCE_REPORT_COMMENT__ -->\n\n## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/use-logforth)\n\n### Merging #5573 will **not alter performance**\n\n<sub>Comparing <code>use-logforth</code> (2c13830) with <code>main</code> (cdbcc0f)</sub>\n\n\n\n### Summary\n\n`‚úÖ 73` untouched benchmarks  \n\n\n\n

> it not touching core/src\r\n\r\nYeah. I reviewed that and notice there is already a tracing dependencies for the layer and I think no need so far to make changes there.

Preview:\r\n\r\n<img width="1728" alt="image" src="https://github.com/user-attachments/assets/7c6dc76b-6d5a-4f16-b703-8c89828041c9" />\r\n\r\nYou can test locally with:\r\n\r\n```\r\ncd bindings/java\r\n./mvnw site\r\n./mvnw javadoc:javadoc\r\nopen target/site/apidocs/org/apache/opendal/ServiceConfig.Mysql.html\r\n```

<!-- __CODSPEED_PERFORMANCE_REPORT_COMMENT__ -->\n<!-- __CODSPEED_INSTRUMENTATION_PERFORMANCE_REPORT_COMMENT__ -->\n\n## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/better-docs)\n\n### Merging #5572 will **degrade performances by 18.88%**\n\n<sub>Comparing <code>better-docs</code> (d34a03c) with <code>main</code> (1026d8a)</sub>\n\n\n\n### Summary\n\n`‚ö° 4` improvements  \n`‚ùå 12` regressions  \n`‚úÖ 57` untouched benchmarks  \n\n\n> :warning: _Please fix the performance issues or [acknowledge them on CodSpeed](https://codspeed.io/apache/opendal/branches/better-docs)._\n\n### Benchmarks breakdown\n\n|     | Benchmark | `BASE` | `HEAD` | Change |\n| --- | --------- | ----------------------- | ------------------- | ------ |\n| ‚ùå | `` buffer 256 KiB * 32 chunk `` | 125.3 ns | 154.4 ns | -18.88% |\n| ‚ùå | `` buffer 256 KiB * 4 chunk `` | 125.3 ns | 154.4 ns | -18.88% |\n| ‚ùå | `` buffer 4.00 MiB * 32 chunk `` | 125.3 ns | 154.4 ns | -18.88% |\n| ‚ùå | `` buffer 4.00 MiB * 4 chunk `` | 125.3 ns | 154.4 ns | -18.88% |\n| ‚ö° | `` bytes buf 256 KiB * 32  advance `` | 464.2 ns | 405.8 ns | +14.37% |\n| ‚ö° | `` bytes buf 256 KiB * 4  advance `` | 464.2 ns | 405.8 ns | +14.37% |\n| ‚ö° | `` bytes buf 4.00 MiB * 32  advance `` | 464.2 ns | 405.8 ns | +14.37% |\n| ‚ö° | `` bytes buf 4.00 MiB * 4  advance `` | 464.2 ns | 405.8 ns | +14.37% |\n| ‚ùå | `` 256 KiB * 1000k chunk `` | 125.3 ns | 154.4 ns | -18.88% |\n| ‚ùå | `` 256 KiB * 1000k truncate `` | 216.7 ns | 245.8 ns | -11.86% |\n| ‚ùå | `` 256 KiB * 100k chunk `` | 125.3 ns | 154.4 ns | -18.88% |\n| ‚ùå | `` 256 KiB * 100k truncate `` | 216.7 ns | 245.8 ns | -11.86% |\n| ‚ùå | `` 256 KiB * 10k chunk `` | 125.3 ns | 154.4 ns | -18.88% |\n| ‚ùå | `` 256 KiB * 10k truncate `` | 216.7 ns | 245.8 ns | -11.86% |\n| ‚ùå | `` 256 KiB * 1k chunk `` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `` 256 KiB * 1k truncate `` | 216.7 ns | 245.8 ns | -11.86% |\n

<!-- __CODSPEED_PERFORMANCE_REPORT_COMMENT__ -->\n<!-- __CODSPEED_INSTRUMENTATION_PERFORMANCE_REPORT_COMMENT__ -->\n\n## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/add-user-for-webhdfs)\n\n### Merging #5567 will **not alter performance**\n\n<sub>Comparing <code>add-user-for-webhdfs</code> (6952f66) with <code>main</code> (cca3a87)</sub>\n\n\n\n### Summary\n\n`‚úÖ 73` untouched benchmarks  \n\n\n\n

> that make sense, will try to do it\r\n\r\n`memory` services is enabled by default, so we can just use `memory` to replace `fs`.

> memory\r\n\r\nseems also need s3, will try and fix it 

> > that make sense, will try to do it\r\n> \r\n> `memory` services is enabled by default, so we can just use `memory` to replace `fs`.\r\n\r\nafter check this is not better either, old test doc is good, and s3 example is better for users, the better way is open these features when doctest

> after check this is not better either, old test doc is good, and s3 example is better for users, the better way is open these features when doctest\r\n\r\nWe can skip the only s3 test if needed.

> > after check this is not better either, old test doc is good, and s3 example is better for users, the better way is open these features when doctest\r\n> \r\n> We can skip the only s3 test if needed.\r\n\r\nthis is a better way will follow this https://users.rust-lang.org/t/doctests-that-require-a-non-default-feature-is-it-possible/29529

> > > after check this is not better either, old test doc is good, and s3 example is better for users, the better way is open these features when doctest\r\n> > \r\n> > \r\n> > We can skip the only s3 test if needed.\r\n> \r\n> this is a better way will follow this https://users.rust-lang.org/t/doctests-that-require-a-non-default-feature-is-it-possible/29529\r\n\r\n![image](https://github.com/user-attachments/assets/3391b574-014a-4326-9e55-fbb83b147571)\r\n\r\nthis works if you agree will change all the doc tests do not in default features in this way

after thinking about either way for me is not good, I think keep the old code is better so closing this

emmm, another issue related to `ceph rados`: the `Etag` returned by `CompleteMultipartUpload` doesn\

> the `Etag` returned by `CompleteMultipartUpload` doesn\

> > the `Etag` returned by `CompleteMultipartUpload` doesn\

> No. The issue is that I compare the Etag from `stat` with the one from `write` in the tests to ensure we get the correct Etag if it\

> That\

> I\

> That\

Perhaps we should introduce `write_has_content_type` flags to indicate which metadata is available in the meta returned by the write operation. Checking the `meta.content_type()` may pass the test but is meaningless to users; it could also potentially conceal incorrect implementations that developers can simplely return `Metadata::default()` to pass all tests. And it makes it more difficult for us to determine the implementation status of various services.

> No. The issue is that I compare the Etag from `stat` with the one from `write` in the tests to ensure we get the correct Etag if it\

Hi, @Xuanwo Would you mind taking some time to review this PR at your convenience? since it involves a lot of files, it may become difficult to merge if it takes too long.

> Hi, @Xuanwo Would you mind taking some time to review this PR at your convenience? since it involves a lot of files, it may become difficult to merge if it takes too long.\r\n\r\nThanks a lot for your great work! I will review this PR after https://github.com/apache/opendal/issues/5620 been addressed.

will change all the `body.copy_to_bytes(body.remaining())` in another pull request

> will change all the `body.copy_to_bytes(body.remaining())` in another pull request\r\n\r\nNext maybe I can do this, do I need to open an issue?

## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/retry-on-rate-limited)\n\n### Merging #5551 will **not alter performance**\n\n<sub>Comparing <code>retry-on-rate-limited</code> (4cb4de6) with <code>main</code> (6734787)</sub>\n\n\n\n### Summary\n\n`‚úÖ 73` untouched benchmarks  \n\n\n\n

<!-- __CODSPEED_PERFORMANCE_REPORT_COMMENT__ -->\n<!-- __CODSPEED_INSTRUMENTATION_PERFORMANCE_REPORT_COMMENT__ -->\n\n## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/gcs-list-with-deleted)\n\n### Merging #5548 will **not alter performance**\n\n<sub>Comparing <code>gcs-list-with-deleted</code> (8b0d9cc) with <code>main</code> (b8a3b7a)</sub>\n\n\n\n### Summary\n\n`‚úÖ 73` untouched benchmarks  \n\n\n\n

@Xuanwo Any other questions?

> we can simply unify them based on different `OpList` inputs.\r\n\r\nIf we get versioned output, we also need to group and sort the entities, and the processing flow is different from non-versioned.

> We should definitely avoid sorting the entries\r\n\r\nYes, I understood it wrong, and made some changes, plz review it.

Thank you @messense for the review.

pub fn format_pyerr(err: ocore::Error) -> PyErr {\r\n    match err.kind() {\r\n        ocore::ErrorKind::Unexpected => Unexpected::new_err(format!("{:?}", err)),\r\n        ocore::ErrorKind::Unsupported => Unsupported::new_err(format!("{:?}", err)),\r\n        ocore::ErrorKind::ConfigInvalid => ConfigInvalid::new_err(format!("{:?}", err)),\r\n        ocore::ErrorKind::NotFound => NotFound::new_err(format!("{:?}", err)),\r\n        ocore::ErrorKind::PermissionDenied => PermissionDenied::new_err(format!("{:?}", err)),\r\n        ocore::ErrorKind::IsADirectory => IsADirectory::new_err(format!("{:?}", err)),\r\n        ocore::ErrorKind::NotADirectory => NotADirectory::new_err(format!("{:?}", err)),\r\n        ocore::ErrorKind::AlreadyExists => AlreadyExists::new_err(format!("{:?}", err)),\r\n        ocore::ErrorKind::IsSameFile => IsSameFile::new_err(format!("{:?}", err)),\r\n        ocore::ErrorKind::ConditionNotMatch => ConditionNotMatch::new_err(format!("{:?}", err)),\r\n        _ => Unexpected::new_err(format!("{:?}", err)),\r\n    }\r\n}

Hi, this example is excellent. Could we include it in the README to make it more visible?

Forgot to attach the result of this example:\r\n![Xnip2025-01-13_19-58-49](https://github.com/user-attachments/assets/fa13d1f7-e2f2-47bc-9d8e-15cebdac5075)\r\n

## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/add-correct-check)\n\n### Merging #5538 will **not alter performance**\n\n<sub>Comparing <code>add-correct-check</code> (dcffc16) with <code>main</code> (85c3803)</sub>\n\n\n\n### Summary\n\n`‚úÖ 73` untouched benchmarks  \n\n\n\n

Thank you @WenyXu for the review.

## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/gcs-not-support-if-modified)\n\n### Merging #5537 will **not alter performance**\n\n<sub>Comparing <code>gcs-not-support-if-modified</code> (a7c73b6) with <code>main</code> (f951963)</sub>\n\n\n\n### Summary\n\n`‚úÖ 73` untouched benchmarks  \n\n\n\n

## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/oss-list-with-deleted)\n\n### Merging #5527 will **not alter performance**\n\n<sub>Comparing <code>oss-list-with-deleted</code> (f32074d) with <code>main</code> (5ae1a76)</sub>\n\n\n\n### Summary\n\n`‚úÖ 73` untouched benchmarks  \n\n\n\n

Hi, @hoslo, I have added a new test case for oss. Would you like to resolve the conflicts and test it again?

## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/bump-version)\n\n### Merging #5523 will **improve performances by 18.88%**\n\n<sub>Comparing <code>bump-version</code> (4f67590) with <code>main</code> (dc32a6a)</sub>\n\n\n\n### Summary\n\n`‚ö° 4` improvements  \n`‚úÖ 69` untouched benchmarks  \n\n\n\n### Benchmarks breakdown\n\n|     | Benchmark | `main` | `bump-version` | Change |\n| --- | --------- | ----------------------- | ------------------- | ------ |\n| ‚ö° | `` 256 KiB * 1000k chunk `` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `` 256 KiB * 100k chunk `` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `` 256 KiB * 10k chunk `` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `` 256 KiB * 1k chunk `` | 212.8 ns | 183.6 ns | +15.89% |\n

Replace by https://github.com/apache/opendal/pull/5522\r\n\r\nUpgrade to manylinux 2.28 instead.

## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/fix-list-with-deleted)\n\n### Merging #5518 will **improve performances by 18.88%**\n\n<sub>Comparing <code>fix-list-with-deleted</code> (fa98026) with <code>main</code> (4fe235a)</sub>\n\n\n\n### Summary\n\n`‚ö° 4` improvements  \n`‚úÖ 69` untouched benchmarks  \n\n\n\n### Benchmarks breakdown\n\n|     | Benchmark | `main` | `fix-list-with-deleted` | Change |\n| --- | --------- | ----------------------- | ------------------- | ------ |\n| ‚ö° | `` 256 KiB * 1000k chunk `` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `` 256 KiB * 100k chunk `` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `` 256 KiB * 10k chunk `` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `` 256 KiB * 1k chunk `` | 212.8 ns | 183.6 ns | +15.89% |\n

Hi, @meteorgan, please review again.

Thank you @meteorgan for the review!

## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/polish-docs-again)\n\n### Merging #5517 will **improve performances by 18.88%**\n\n<sub>Comparing <code>polish-docs-again</code> (03a145b) with <code>main</code> (b84172e)</sub>\n\n\n\n### Summary\n\n`‚ö° 4` improvements  \n`‚úÖ 69` untouched benchmarks  \n\n\n\n### Benchmarks breakdown\n\n|     | Benchmark | `main` | `polish-docs-again` | Change |\n| --- | --------- | ----------------------- | ------------------- | ------ |\n| ‚ö° | `` 256 KiB * 1000k chunk `` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `` 256 KiB * 100k chunk `` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `` 256 KiB * 10k chunk `` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `` 256 KiB * 1k chunk `` | 212.8 ns | 183.6 ns | +15.89% |\n

## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/polish-docs)\n\n### Merging #5516 will **degrade performances by 15.89%**\n\n<sub>Comparing <code>polish-docs</code> (c3bb036) with <code>main</code> (6ca3eab)</sub>\n\n\n\n### Summary\n\n`‚ö° 8` improvements  \n`‚ùå 4` regressions  \n`‚úÖ 61` untouched benchmarks  \n\n\n> :warning: _Please fix the performance issues or [acknowledge them on CodSpeed](https://codspeed.io/apache/opendal/branches/polish-docs)._\n\n### Benchmarks breakdown\n\n|     | Benchmark | `main` | `polish-docs` | Change |\n| --- | --------- | ----------------------- | ------------------- | ------ |\n| ‚ùå | `` buffer 256 KiB * 32 chunk `` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `` buffer 256 KiB * 4 chunk `` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `` buffer 4.00 MiB * 32 chunk `` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `` buffer 4.00 MiB * 4 chunk `` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ö° | `` 256 KiB * 1000k chunk `` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `` 256 KiB * 1000k truncate `` | 245.8 ns | 216.7 ns | +13.46% |\n| ‚ö° | `` 256 KiB * 100k chunk `` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `` 256 KiB * 100k truncate `` | 245.8 ns | 216.7 ns | +13.46% |\n| ‚ö° | `` 256 KiB * 10k chunk `` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `` 256 KiB * 10k truncate `` | 245.8 ns | 216.7 ns | +13.46% |\n| ‚ö° | `` 256 KiB * 1k chunk `` | 212.8 ns | 183.6 ns | +15.89% |\n| ‚ö° | `` 256 KiB * 1k truncate `` | 245.8 ns | 216.7 ns | +13.46% |\n

## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/cos-list-with-deleted)\n\n### Merging #5514 will **improve performances by 18.88%**\n\n<sub>Comparing <code>cos-list-with-deleted</code> (b00769f) with <code>main</code> (1c287eb)</sub>\n\n\n\n### Summary\n\n`‚ö° 4` improvements  \n`‚úÖ 69` untouched benchmarks  \n\n\n\n### Benchmarks breakdown\n\n|     | Benchmark | `main` | `cos-list-with-deleted` | Change |\n| --- | --------- | ----------------------- | ------------------- | ------ |\n| ‚ö° | `` 256 KiB * 1000k chunk `` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `` 256 KiB * 100k chunk `` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `` 256 KiB * 10k chunk `` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `` 256 KiB * 1k chunk `` | 212.8 ns | 183.6 ns | +15.89% |\n

> 1. I believe we should add more tests for `object_store_opendal`. especially for the newly added APIs. However `services::Memory` doesn\

Thank you for you advise !\r\n\r\n> Ideally, we should test `object_store_opendal` using integration tests, similar to how we test the Python bindings. Initially, we can start by testing with `fs` and `s3`. However, since `object_store` has different semantics compared to `opendal`, implementing the tests might be somewhat challenging.\r\n\r\nI\

> Our current MSRV is `1.75.0`, but this feature became stable since `1.79.0`. Should we continue using the current MSRV or is it okay to upgrade to the newer one?\r\n\r\nWe can use `io::Error::into_inner` and then `Error::downcast` as an alternative. `io::Error::downcast` is just a quick wrapper.

@Xuanwo can you plz look into this PR.

@Xuanwo I have made the changes that you suggested.

> Provide a helpful error message if users attempt to call if_none_match("*") on a service that supports write_with_if_not_exists but not write_with_if_none_match. In this scenario, the error should suggest that users switch to using if_not_exists instead.\r\n\r\nMakes sense, I\

> This is a bit awkward but I suppose the config class is relatively stable.\r\n\r\nThis is fine as a starting point. However, in the near future, we will run `just generate` in CI to ensure there are no external changes to those files. Is the Javadoc requirement optional? Will it work if we only run `just generate java && ./mvnw spotless:apply`? 

Not exactly. But I can help in make a reasonable stable version at that time.

minio should support those headers: https://github.com/minio/minio/issues/1098 

> minio should support those headers: [minio/minio#1098](https://github.com/minio/minio/issues/1098)\r\n\r\n`Minio` requires the time format to follow `RFC1123`(like: Fri, 01 Mar 2019 15:00:00 GMT)  üò¢ 

> `Minio` requires the time format to follow `RFC1123`(like: Fri, 01 Mar 2019 15:00:00 GMT) üò¢\r\n\r\nOoops, it does have the requirement for `If-Modified-Since` and `If-Unmodified-Since`: https://httpwg.org/specs/rfc9110.html#field.if-modified-since

@Xuanwo  Thanks for your response**‚ò∫Ô∏è** I would definitely love to review the existing PR. Please let me know if you‚Äôre interested in guide me in contributing to the project. I‚Äôm eager to contribute and would love to take on any specific tasks or other work that you may have. I definitely do my best work and will provide you with the best solutions as you expect. 

## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/implement-list-with-deleted)\n\n### Merging #5498 will **improve performances by 18.88%**\n\n<sub>Comparing <code>implement-list-with-deleted</code> (a739a68) with <code>main</code> (7a83013)</sub>\n\n\n\n### Summary\n\n`‚ö° 4` improvements  \n`‚úÖ 69` untouched benchmarks  \n\n\n\n### Benchmarks breakdown\n\n|     | Benchmark | `main` | `implement-list-with-deleted` | Change |\n| --- | --------- | ----------------------- | ------------------- | ------ |\n| ‚ö° | `256 KiB * 1000k chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `256 KiB * 100k chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `256 KiB * 10k chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `256 KiB * 1k chunk` | 212.8 ns | 183.6 ns | +15.89% |\n

## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/polish-api)\n\n### Merging #5497 will **degrade performances by 15.89%**\n\n<sub>Comparing <code>polish-api</code> (df43c3f) with <code>main</code> (8549524)</sub>\n\n\n\n### Summary\n\n`‚ö° 8` improvements  \n`‚ùå 4` regressions  \n`‚úÖ 61` untouched benchmarks  \n\n\n> :warning: _Please fix the performance issues or [acknowledge them on CodSpeed](https://codspeed.io/apache/opendal/branches/polish-api)._\n\n### Benchmarks breakdown\n\n|     | Benchmark | `main` | `polish-api` | Change |\n| --- | --------- | ----------------------- | ------------------- | ------ |\n| ‚ùå | `buffer 256 KiB * 32 chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `buffer 256 KiB * 4 chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `buffer 4.00 MiB * 32 chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `buffer 4.00 MiB * 4 chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ö° | `256 KiB * 1000k chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `256 KiB * 1000k truncate` | 245.8 ns | 216.7 ns | +13.46% |\n| ‚ö° | `256 KiB * 100k chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `256 KiB * 100k truncate` | 245.8 ns | 216.7 ns | +13.46% |\n| ‚ö° | `256 KiB * 10k chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `256 KiB * 10k truncate` | 245.8 ns | 216.7 ns | +13.46% |\n| ‚ö° | `256 KiB * 1k chunk` | 212.8 ns | 183.6 ns | +15.89% |\n| ‚ö° | `256 KiB * 1k truncate` | 245.8 ns | 216.7 ns | +13.46% |\n

LGTM.

> LGTM.\r\n\r\nHi, please give an `approve` instead of a comment.

I‚Äôve updated the code based on your comments. PTAL, thanks!

Hi @Xuanwo, just a little remind in case this got forgotten. I have more time right now to keep working on this

LGTM

> LGTM\n\nHi, please approve this PR if it looks good to you.

## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/fix-ghac)\n\n### Merging #5477 will **degrade performances by 15.89%**\n\n<sub>Comparing <code>fix-ghac</code> (1c21cf1) with <code>main</code> (4e99afa)</sub>\n\n\n\n### Summary\n\n`‚ö° 8` improvements  \n`‚ùå 4` regressions  \n`‚úÖ 61` untouched benchmarks  \n\n\n> :warning: _Please fix the performance issues or [acknowledge them on CodSpeed](https://codspeed.io/apache/opendal/branches/fix-ghac)._\n\n### Benchmarks breakdown\n\n|     | Benchmark | `main` | `fix-ghac` | Change |\n| --- | --------- | ----------------------- | ------------------- | ------ |\n| ‚ùå | `buffer 256 KiB * 32 chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `buffer 256 KiB * 4 chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `buffer 4.00 MiB * 32 chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `buffer 4.00 MiB * 4 chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ö° | `256 KiB * 1000k chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `256 KiB * 1000k truncate` | 245.8 ns | 216.7 ns | +13.46% |\n| ‚ö° | `256 KiB * 100k chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `256 KiB * 100k truncate` | 245.8 ns | 216.7 ns | +13.46% |\n| ‚ö° | `256 KiB * 10k chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `256 KiB * 10k truncate` | 245.8 ns | 216.7 ns | +13.46% |\n| ‚ö° | `256 KiB * 1k chunk` | 212.8 ns | 183.6 ns | +15.89% |\n| ‚ö° | `256 KiB * 1k truncate` | 245.8 ns | 216.7 ns | +13.46% |\n

> Would you like to add a test for memcached with tls enabled?\r\n\r\nNo problem, I will complete it later.

Does the Memcached service require any special configuration? During testing, I found many incorrect test results, and some tests occasionally pass while failing at other times during repeated tests. @Xuanwo \r\nHere is my Memcached service configuration: \r\n```\r\nmemcached --protocol=auto -p 11212 --enable-ssl -o ssl_chain_cert=./server.crt,ssl_key=./server.key,ssl_verify_mode=2,ssl_ca_cert=./client_ca/client_ca.crt\r\n```

## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/fix-typos)\n\n### Merging #5468 will **degrade performances by 15.89%**\n\n<sub>Comparing <code>fix-typos</code> (a0f014e) with <code>main</code> (32fc3c5)</sub>\n\n\n\n### Summary\n\n`‚ö° 8` improvements  \n`‚ùå 4` regressions  \n`‚úÖ 61` untouched benchmarks  \n\n\n> :warning: _Please fix the performance issues or [acknowledge them on CodSpeed](https://codspeed.io/apache/opendal/branches/fix-typos)._\n\n### Benchmarks breakdown\n\n|     | Benchmark | `main` | `fix-typos` | Change |\n| --- | --------- | ----------------------- | ------------------- | ------ |\n| ‚ùå | `buffer 256 KiB * 32 chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `buffer 256 KiB * 4 chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `buffer 4.00 MiB * 32 chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `buffer 4.00 MiB * 4 chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ö° | `256 KiB * 1000k chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `256 KiB * 1000k truncate` | 245.8 ns | 216.7 ns | +13.46% |\n| ‚ö° | `256 KiB * 100k chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `256 KiB * 100k truncate` | 245.8 ns | 216.7 ns | +13.46% |\n| ‚ö° | `256 KiB * 10k chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `256 KiB * 10k truncate` | 245.8 ns | 216.7 ns | +13.46% |\n| ‚ö° | `256 KiB * 1k chunk` | 212.8 ns | 183.6 ns | +15.89% |\n| ‚ö° | `256 KiB * 1k truncate` | 245.8 ns | 216.7 ns | +13.46% |\n

Thank you @dqhl76 for the review!

## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/docs)\n\n### Merging #5466 will **degrade performances by 15.89%**\n\n<sub>Comparing <code>docs</code> (8c70543) with <code>main</code> (6ccef00)</sub>\n\n\n\n### Summary\n\n`‚ö° 8` improvements  \n`‚ùå 4` regressions  \n`‚úÖ 61` untouched benchmarks  \n\n\n> :warning: _Please fix the performance issues or [acknowledge them on CodSpeed](https://codspeed.io/apache/opendal/branches/docs)._\n\n### Benchmarks breakdown\n\n|     | Benchmark | `main` | `docs` | Change |\n| --- | --------- | ----------------------- | ------------------- | ------ |\n| ‚ùå | `buffer 256 KiB * 32 chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `buffer 256 KiB * 4 chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `buffer 4.00 MiB * 32 chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `buffer 4.00 MiB * 4 chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ö° | `256 KiB * 1000k chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `256 KiB * 1000k truncate` | 245.8 ns | 216.7 ns | +13.46% |\n| ‚ö° | `256 KiB * 100k chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `256 KiB * 100k truncate` | 245.8 ns | 216.7 ns | +13.46% |\n| ‚ö° | `256 KiB * 10k chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `256 KiB * 10k truncate` | 245.8 ns | 216.7 ns | +13.46% |\n| ‚ö° | `256 KiB * 1k chunk` | 212.8 ns | 183.6 ns | +15.89% |\n| ‚ö° | `256 KiB * 1k truncate` | 245.8 ns | 216.7 ns | +13.46% |\n

Thank you @PsiACE for the review!

Hi, @trim21, sorry for force-pushing my changes. I find it much easier to do this rather than trying to resolve the conflicts.

Hi, please work on https://github.com/apache/opendal/pull/5442 instead to ensure our reviewers are aware of the full history of this contribution. \r\n\r\nThis is the third time I am repeating: do not submit new PRs for the same contribution. Please ask questions in the comments of the PR if you encounter any issues while doing so.

> How to use this file?\r\n\r\nUpdated the `dev/README.md` files.

Thanks!

> Mostly LGTM, but I think we should revist the `_bool` and `_int` type aliases (due to the use of `Operator::from_iter` that only accepts a iterator of `(String, String)`), IMHO at least the `_int` type should accepts `int`.\r\n\r\nI think runtime should be able to handle `HashMap<String, Enum(String,uint,int,bool)>`Ôºå but before that I think using alias of str provide better DX for users.

> Mostly LGTM, but I think we should revist the `_bool` and `_int` type aliases (due to the use of `Operator::from_iter` that only accepts a iterator of `(String, String)`), IMHO at least the `_int` type should accepts `int`.\r\n\r\npyo3 doesn\

> `FsConfig.root` is `Option<String>` which is actually required.\r\n\r\nI think we can fix it from the core side.

For me, the PR mostly LGTM, but some idea\r\n\r\n1.  We need to think more about `_int` type, a str type but with integer semantic\r\n2.  If we can drop support for the version under 3.12, we may can use typedict for kwargs, FYI https://peps.python.org/pep-0692/

> For me, the PR mostly LGTM, but some idea\r\n> \r\n> 1. We need to think more about `_int` type, a str type but with integer semantic\r\n> 2. If we can drop support for the version under 3.12, we may can use typedict for kwargs, FYI https://peps.python.org/pep-0692/\r\n\r\nWe do not need to drop py<3.12 to use this feature, pyi file is not runtime code, so even in old python as long as type checker support pep692, it\

I guess rust code is fine for now? Still need to resolve what kind of typing we want to generate.

Hi, @trim21 this will be large task, would you like to create a tracking issue for the progress?

Also cc @trim21 to take a look. I left the python part empty for you.

Oh right, I missed the `exception_module.add` part.

Thanks!

> I think we can generate Operator.init overloads from config directlyÔºü\r\n\r\nTotally

Hi, I like this direction. I believe we can integrate it into our workflow more effectively. Let me give it a try.

I think we should generate some kind of ir and generate types for each languages from ir

> I think we should generate some kind of ir and generate types for each languages from ir\r\n\r\n100%!\r\n\r\nWorking on this now.

can we release python package again?

> can we release python package again?\r\n\r\nWould you like to start a discussion for it? We can cut off a 0.51.1 release.

> > can we release python package again?\r\n> \r\n> Would you like to start a discussion for it? We can cut off a 0.51.1 release.\r\n\r\nAny change create a branch from 0.51.0 and backport this PR without create a new release?

> Any change create a branch from 0.51.0 and backport this PR without create a new release?\r\n\r\nHi, @Zheaoli has discovered that the `0.51.0-rc.3` release was successful. I reused the artifacts from there and published them to PyPI. Please double-check.

Thank you so much sir .\n

> # Which issue does this PR close?\n> \n> <!--\n> Indicates that this PR will close issue #5408.\n> -->\n> \n> \n> # Rationale for this change\n> \n> <!--\n> Why are you proposing this change? I am proposing this change becouse of exists or add the function path .\n> In this I added some function for existing the path.\n> -->\n> \n> # What changes are included in this PR?\n> \n> <!--\n> Adding a function path.\n> -->\n> \n> # Are there any user-facing changes?\n> \n> \n> <!--\n> Yes , when the path not found for a function then it will show a bool value\n> -->\n> \n\n\n

this issue is solved, can be closed.\r\n

Another suggestion is to make changes within the same PR instead of creating new ones. You can just push to the same branches.

Thanks!

Thank @BaurzhanSakhariev for the details analyze and test case!

Thank you @ho-229 for the fix. The only thing left is the failing clippy check: https://github.com/apache/opendal/actions/runs/12337198169/job/34430608724?pr=5416

cc @ho-229 @Xuanwo. I think this would be a release blocker

@ho-229 the test still fail on windowsÔºå do you have any ideas?

It seems like the behavior of Cloud Filter API has changed, I am trying to figure it out.

Fix #5416 

> It seems like the behavior of Cloud Filter API has changed, I am trying to figure it out.\r\n\r\nThanks! I will release 0.51.0-rc.2 after your fix 

> It looks great to me overall, except for some incorrect version bumps.\r\n\r\nFor me, when the core is in a new big version. I prefer upgrade the binding to a new big version at the same time. This is a personal style. On your call.

@Xuanwo PTAL

Thank you @tisonkun for the review, merging..

## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/remove-batch)\n\n### Merging #5393 will **degrade performances by 15.89%**\n\n<sub>Comparing <code>remove-batch</code> (dc5fb7c) with <code>main</code> (c77a07a)</sub>\n\n\n\n### Summary\n\n`‚ö° 5` improvements  \n`‚ùå 4` regressions  \n`‚úÖ 64` untouched benchmarks  \n\n\n> :warning: _Please fix the performance issues or [acknowledge them on CodSpeed](https://codspeed.io/apache/opendal/branches/remove-batch)._\n\n### Benchmarks breakdown\n\n|     | Benchmark | `main` | `remove-batch` | Change |\n| --- | --------- | ----------------------- | ------------------- | ------ |\n| ‚ö° | `buffer 256 KiB * 32 advance` | 660.6 ns | 573.1 ns | +15.27% |\n| ‚ö° | `buffer 256 KiB * 4 advance` | 660.6 ns | 573.1 ns | +15.27% |\n| ‚ö° | `buffer 4.00 MiB * 32 advance` | 660.6 ns | 573.1 ns | +15.27% |\n| ‚ö° | `buffer 4.00 MiB * 4 advance` | 660.6 ns | 573.1 ns | +15.27% |\n| ‚ùå | `256 KiB * 1000k chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `256 KiB * 100k chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `256 KiB * 10k chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `256 KiB * 1k chunk` | 183.6 ns | 212.8 ns | -13.71% |\n| ‚ö° | `concurrent 4` | 411.7 ¬µs | 365.5 ¬µs | +12.63% |\n

Thank you @WenyXu for the review!

## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/deleter)\n\n### Merging #5392 will **degrade performances by 21.37%**\n\n<sub>Comparing <code>deleter</code> (6869a44) with <code>main</code> (f3bf1d4)</sub>\n\n\n\n### Summary\n\n`‚ö° 8` improvements  \n`‚ùå 1` regressions  \n`‚úÖ 64` untouched benchmarks  \n\n\n> :warning: _Please fix the performance issues or [acknowledge them on CodSpeed](https://codspeed.io/apache/opendal/branches/deleter)._\n\n### Benchmarks breakdown\n\n|     | Benchmark | `main` | `deleter` | Change |\n| --- | --------- | ----------------------- | ------------------- | ------ |\n| ‚ö° | `buffer 256 KiB * 32 chunk` | 183.6 ns | 125.3 ns | +46.56% |\n| ‚ö° | `buffer 256 KiB * 4 chunk` | 183.6 ns | 125.3 ns | +46.56% |\n| ‚ö° | `buffer 4.00 MiB * 32 chunk` | 183.6 ns | 125.3 ns | +46.56% |\n| ‚ö° | `buffer 4.00 MiB * 4 chunk` | 183.6 ns | 125.3 ns | +46.56% |\n| ‚ö° | `256 KiB * 1000k chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `256 KiB * 100k chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `256 KiB * 10k chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `256 KiB * 1k chunk` | 212.8 ns | 183.6 ns | +15.89% |\n| ‚ùå | `concurrent 8` | 355.2 ¬µs | 451.7 ¬µs | -21.37% |\n

NOTEs to reviewer:\r\n\r\n- Most changes are related to `Access` API changes\r\n- Meaningful changes happened in `operator.rs` and `delete.rs`.

Thank you @George-Miao for the review!

> I think we need to add `content_encoding` to the metadata to properly test it? [docs.aws.amazon.com/AmazonS3/latest/API/API_HeadObject.html#API_HeadObject_ResponseSyntax](https://docs.aws.amazon.com/AmazonS3/latest/API/API_HeadObject.html#API_HeadObject_ResponseSyntax)\r\n\r\nYes, please do this!

Thank you for the updates! ü•∞

Would it be better to perform an upstream rebase and update the commit messages as well? (perf -> feat)

See https://pyo3.rs/v0.23.2/free-threading.html?highlight=gil_used#supporting-free-threaded-python-with-pyo3

BTW, please also update pyo3 to `0.23.3` to fix this soundness bug: https://github.com/PyO3/pyo3/issues/4757

> You need to either enable `generate-import-lib` feature of `pyo3` or use [Quansight-Labs/setup-python](https://github.com/Quansight-Labs/setup-python) to install a python3.13t interprerer on Windows to fix the build failure.\r\n\r\nThanks for your help.

@meteorgan You could directly run the following command, so nothing will be missed.\r\n\r\n```\r\ncargo clippy --all-targets --all-features --fix\r\n```

![Xnip2024-12-01_20-04-57](https://github.com/user-attachments/assets/e8735399-5a18-4b21-8221-148ececea242)\r\n\r\nRust has been to upgraded to 1.83.0, which has caused some issues related to `Clippy`.\r\nShould we fix these issues and recommend developers to upgrade to 1.83.0 ? @Xuanwo \r\n

I think the modification for file.rs may have lost the original meaning, this modification is a bit difficult for me.\r\n\r\n@Zheaoli @messense 

thanks for the review! would fix soon

> Thank you @Frank-III for working on this, really great!\r\n\r\nThank you again for your patient guidance! üòä

Thanks for the review. I am 2-3 PRs away from achieving the issue.

@Xuanwo added changes from cargo fmt

Please also wait #5324 to pass the CI

Great!\r\nThe PR is ready to get reviewed now.

It seems like we should add a new capability `MultiProcessingAccess` to guard the behavior.

> It seems like we should add a new capability `MultiProcessingAccess` to guard the behavior.\r\n\r\nSGTM, maybe `Pickable` would be better?

> I support temporarily adding only shared capability.\r\n\r\nWould you like to add this capability? I believe we can include them in the next 0.51 release.

> > I support temporarily adding only shared capability.\r\n> \r\n> Would you like to add this capability? I believe we can include them in the next 0.51 release.\r\n\r\nI can add it.\r\n\r\nPlease note that `shared` only indicates shared between processes but not shared between threads, it may be a little confusing if we will add backends which only support single-thread later.\r\n\r\nHowever, I guess we will not support that in a while.

Will test another PR use the CI flow, just ignore it.

## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/remove-range-writer)\n\n### Merging #5323 will **degrade performances by 18.88%**\n\n<sub>Comparing <code>remove-range-writer</code> (dbf95bb) with <code>main</code> (104727c)</sub>\n\n\n\n### Summary\n\n`‚ö° 1` improvements\n`‚ùå 8` regressions\n`‚úÖ 64` untouched benchmarks\n\n\n\n> :warning: _Please fix the performance issues or [acknowledge them on CodSpeed](https://codspeed.io/apache/opendal/branches/remove-range-writer)._\n\n### Benchmarks breakdown\n\n|     | Benchmark | `main` | `remove-range-writer` | Change |\n| --- | --------- | ----------------------- | ------------------- | ------ |\n| ‚ùå | `256 KiB * 1000k chunk` | 125.3 ns | 154.4 ns | -18.88% |\n| ‚ùå | `256 KiB * 1000k truncate` | 216.7 ns | 245.8 ns | -11.86% |\n| ‚ùå | `256 KiB * 100k chunk` | 125.3 ns | 154.4 ns | -18.88% |\n| ‚ùå | `256 KiB * 100k truncate` | 216.7 ns | 245.8 ns | -11.86% |\n| ‚ùå | `256 KiB * 10k chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `256 KiB * 10k truncate` | 216.7 ns | 245.8 ns | -11.86% |\n| ‚ùå | `256 KiB * 1k chunk` | 125.3 ns | 154.4 ns | -18.88% |\n| ‚ùå | `256 KiB * 1k truncate` | 216.7 ns | 245.8 ns | -11.86% |\n| ‚ö° | `concurrent 8` | 365.4 ¬µs | 327.3 ¬µs | +11.62% |\n

Thank you @koushiro for the review!

## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/remove-range-writer)\n\n### Merging #5322 will **degrade performances by 18.88%**\n\n<sub>Comparing <code>remove-range-writer</code> (d179ca9) with <code>main</code> (4dc0f15)</sub>\n\n\n\n### Summary\n\n`‚ùå 8` regressions\n`‚úÖ 65` untouched benchmarks\n\n\n\n> :warning: _Please fix the performance issues or [acknowledge them on CodSpeed](https://codspeed.io/apache/opendal/branches/remove-range-writer)._\n\n### Benchmarks breakdown\n\n|     | Benchmark | `main` | `remove-range-writer` | Change |\n| --- | --------- | ----------------------- | ------------------- | ------ |\n| ‚ùå | `buffer 256 KiB * 32 chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `buffer 256 KiB * 4 chunk` | 125.3 ns | 154.4 ns | -18.88% |\n| ‚ùå | `buffer 4.00 MiB * 32 chunk` | 125.3 ns | 154.4 ns | -18.88% |\n| ‚ùå | `buffer 4.00 MiB * 4 chunk` | 125.3 ns | 154.4 ns | -18.88% |\n| ‚ùå | `256 KiB * 1000k truncate` | 245.8 ns | 275 ns | -10.61% |\n| ‚ùå | `256 KiB * 100k truncate` | 245.8 ns | 275 ns | -10.61% |\n| ‚ùå | `256 KiB * 10k truncate` | 245.8 ns | 275 ns | -10.61% |\n| ‚ùå | `256 KiB * 1k truncate` | 245.8 ns | 275 ns | -10.61% |\n

Thank you @PsiACE for the review!

## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/add-write-if-not-exists)\n\n### Merging #5321 will **degrade performances by 18.88%**\n\n<sub>Comparing <code>add-write-if-not-exists</code> (f8152be) with <code>main</code> (4dc0f15)</sub>\n\n\n\n### Summary\n\n`‚ùå 8` regressions\n`‚úÖ 65` untouched benchmarks\n\n\n\n> :warning: _Please fix the performance issues or [acknowledge them on CodSpeed](https://codspeed.io/apache/opendal/branches/add-write-if-not-exists)._\n\n### Benchmarks breakdown\n\n|     | Benchmark | `main` | `add-write-if-not-exists` | Change |\n| --- | --------- | ----------------------- | ------------------- | ------ |\n| ‚ùå | `buffer 256 KiB * 32 chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `buffer 256 KiB * 4 chunk` | 125.3 ns | 154.4 ns | -18.88% |\n| ‚ùå | `buffer 4.00 MiB * 32 chunk` | 125.3 ns | 154.4 ns | -18.88% |\n| ‚ùå | `buffer 4.00 MiB * 4 chunk` | 125.3 ns | 154.4 ns | -18.88% |\n| ‚ùå | `256 KiB * 1000k truncate` | 245.8 ns | 275 ns | -10.61% |\n| ‚ùå | `256 KiB * 100k truncate` | 245.8 ns | 275 ns | -10.61% |\n| ‚ùå | `256 KiB * 10k truncate` | 245.8 ns | 275 ns | -10.61% |\n| ‚ùå | `256 KiB * 1k truncate` | 245.8 ns | 275 ns | -10.61% |\n

Thank you @ClSlaid for the review!

## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/polish-if-not-exsts)\n\n### Merging #5320 will **degrade performances by 18.88%**\n\n<sub>Comparing <code>polish-if-not-exsts</code> (98528e9) with <code>main</code> (cd2fc9f)</sub>\n\n\n\n### Summary\n\n`‚ùå 8` regressions\n`‚úÖ 65` untouched benchmarks\n\n\n\n> :warning: _Please fix the performance issues or [acknowledge them on CodSpeed](https://codspeed.io/apache/opendal/branches/polish-if-not-exsts)._\n\n### Benchmarks breakdown\n\n|     | Benchmark | `main` | `polish-if-not-exsts` | Change |\n| --- | --------- | ----------------------- | ------------------- | ------ |\n| ‚ùå | `buffer 256 KiB * 32 chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `buffer 256 KiB * 4 chunk` | 125.3 ns | 154.4 ns | -18.88% |\n| ‚ùå | `buffer 4.00 MiB * 32 chunk` | 125.3 ns | 154.4 ns | -18.88% |\n| ‚ùå | `buffer 4.00 MiB * 4 chunk` | 125.3 ns | 154.4 ns | -18.88% |\n| ‚ùå | `256 KiB * 1000k truncate` | 245.8 ns | 275 ns | -10.61% |\n| ‚ùå | `256 KiB * 100k truncate` | 245.8 ns | 275 ns | -10.61% |\n| ‚ùå | `256 KiB * 10k truncate` | 245.8 ns | 275 ns | -10.61% |\n| ‚ùå | `256 KiB * 1k truncate` | 245.8 ns | 275 ns | -10.61% |\n

## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/remove-metakey)\n\n### Merging #5319 will **degrade performances by 16.59%**\n\n<sub>Comparing <code>remove-metakey</code> (11ef737) with <code>main</code> (297bbf9)</sub>\n\n\n\n### Summary\n\n`‚ö° 4` improvements\n`‚ùå 10` regressions\n`‚úÖ 59` untouched benchmarks\n\n\n\n> :warning: _Please fix the performance issues or [acknowledge them on CodSpeed](https://codspeed.io/apache/opendal/branches/remove-metakey)._\n\n### Benchmarks breakdown\n\n|     | Benchmark | `main` | `remove-metakey` | Change |\n| --- | --------- | ----------------------- | ------------------- | ------ |\n| ‚ùå | `bytes buf 256 KiB * 32  advance` | 435 ns | 493.3 ns | -11.82% |\n| ‚ùå | `bytes buf 256 KiB * 4  advance` | 435 ns | 493.3 ns | -11.82% |\n| ‚ùå | `bytes buf 4.00 MiB * 32  advance` | 435 ns | 493.3 ns | -11.82% |\n| ‚ùå | `bytes buf 4.00 MiB * 4  advance` | 435 ns | 493.3 ns | -11.82% |\n| ‚ö° | `256 KiB * 1000k chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ùå | `256 KiB * 1000k truncate` | 245.8 ns | 275 ns | -10.61% |\n| ‚ö° | `256 KiB * 100k chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ùå | `256 KiB * 100k truncate` | 245.8 ns | 275 ns | -10.61% |\n| ‚ö° | `256 KiB * 10k chunk` | 212.8 ns | 183.6 ns | +15.89% |\n| ‚ùå | `256 KiB * 10k truncate` | 245.8 ns | 275 ns | -10.61% |\n| ‚ö° | `256 KiB * 1k chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ùå | `256 KiB * 1k truncate` | 245.8 ns | 275 ns | -10.61% |\n| ‚ùå | `concurrent 16` | 299.8 ¬µs | 359.5 ¬µs | -16.59% |\n| ‚ùå | `concurrent 8` | 319.2 ¬µs | 363.9 ¬µs | -12.3% |\n

## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/remove-metakey)\n\n### Merging #5318 will **degrade performances by 21.21%**\n\n<sub>Comparing <code>remove-metakey</code> (7c842aa) with <code>main</code> (41b6f27)</sub>\n\n\n\n### Summary\n\n`‚ö° 1` improvements\n`‚ùå 12` regressions\n`‚úÖ 60` untouched benchmarks\n\n\n\n> :warning: _Please fix the performance issues or [acknowledge them on CodSpeed](https://codspeed.io/apache/opendal/branches/remove-metakey)._\n\n### Benchmarks breakdown\n\n|     | Benchmark | `main` | `remove-metakey` | Change |\n| --- | --------- | ----------------------- | ------------------- | ------ |\n| ‚ùå | `buffer 256 KiB * 32 chunk` | 183.6 ns | 212.8 ns | -13.71% |\n| ‚ùå | `buffer 256 KiB * 4 chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `buffer 4.00 MiB * 32 chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `buffer 4.00 MiB * 4 chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `256 KiB * 1000k chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `256 KiB * 1000k truncate` | 216.7 ns | 275 ns | -21.21% |\n| ‚ùå | `256 KiB * 100k chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `256 KiB * 100k truncate` | 216.7 ns | 275 ns | -21.21% |\n| ‚ùå | `256 KiB * 10k chunk` | 183.6 ns | 212.8 ns | -13.71% |\n| ‚ùå | `256 KiB * 10k truncate` | 216.7 ns | 275 ns | -21.21% |\n| ‚ùå | `256 KiB * 1k chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `256 KiB * 1k truncate` | 216.7 ns | 275 ns | -21.21% |\n| ‚ö° | `concurrent 16` | 321 ¬µs | 289.1 ¬µs | +11.02% |\n

## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/polish-capability)\n\n### Merging #5315 will **degrade performances by 15.89%**\n\n<sub>Comparing <code>polish-capability</code> (7310ef0) with <code>main</code> (7b18680)</sub>\n\n\n\n### Summary\n\n`‚ùå 8` regressions\n`‚úÖ 65` untouched benchmarks\n\n\n\n> :warning: _Please fix the performance issues or [acknowledge them on CodSpeed](https://codspeed.io/apache/opendal/branches/polish-capability)._\n\n### Benchmarks breakdown\n\n|     | Benchmark | `main` | `polish-capability` | Change |\n| --- | --------- | ----------------------- | ------------------- | ------ |\n| ‚ùå | `buffer 256 KiB * 32 chunk` | 183.6 ns | 212.8 ns | -13.71% |\n| ‚ùå | `buffer 256 KiB * 4 chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `buffer 4.00 MiB * 32 chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `buffer 4.00 MiB * 4 chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `256 KiB * 1000k truncate` | 245.8 ns | 275 ns | -10.61% |\n| ‚ùå | `256 KiB * 100k truncate` | 245.8 ns | 275 ns | -10.61% |\n| ‚ùå | `256 KiB * 10k truncate` | 245.8 ns | 275 ns | -10.61% |\n| ‚ùå | `256 KiB * 1k truncate` | 245.8 ns | 275 ns | -10.61% |\n

> Generally LGTM\r\n\r\nAll suggestions have been applied. Please review again, thanks!

I also invite all @apache/opendal-committers to join the review.

## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/add-vision)\n\n### Merging #5309 will **degrade performances by 15.89%**\n\n<sub>Comparing <code>add-vision</code> (271b697) with <code>main</code> (de198cd)</sub>\n\n\n\n### Summary\n\n`‚ö° 8` improvements\n`‚ùå 4` regressions\n`‚úÖ 61` untouched benchmarks\n\n\n\n> :warning: _Please fix the performance issues or [acknowledge them on CodSpeed](https://codspeed.io/apache/opendal/branches/add-vision)._\n\n### Benchmarks breakdown\n\n|     | Benchmark | `main` | `add-vision` | Change |\n| --- | --------- | ----------------------- | ------------------- | ------ |\n| ‚ùå | `buffer 256 KiB * 32 chunk` | 183.6 ns | 212.8 ns | -13.71% |\n| ‚ùå | `buffer 256 KiB * 4 chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `buffer 4.00 MiB * 32 chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ùå | `buffer 4.00 MiB * 4 chunk` | 154.4 ns | 183.6 ns | -15.89% |\n| ‚ö° | `256 KiB * 1000k chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `256 KiB * 1000k truncate` | 245.8 ns | 216.7 ns | +13.46% |\n| ‚ö° | `256 KiB * 100k chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `256 KiB * 100k truncate` | 245.8 ns | 216.7 ns | +13.46% |\n| ‚ö° | `256 KiB * 10k chunk` | 212.8 ns | 183.6 ns | +15.89% |\n| ‚ö° | `256 KiB * 10k truncate` | 245.8 ns | 216.7 ns | +13.46% |\n| ‚ö° | `256 KiB * 1k chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `256 KiB * 1k truncate` | 245.8 ns | 216.7 ns | +13.46% |\n

Thank you all for the review, especially @tisonkun for the detailed comments and @xxchan for optimizing the expression. I\

Thank you @palash25 for fixing this. I will invite @PragmaTwice to take a review.

Funny to see it succeeded on redis but failed on redis cluster and kvrocks.

Fixed.

Thanks @tisonkun 

Thank you @suyanhanx for the quick review!

Thank you @dqhl76 for helping review!

Thank you @dqhl76 for helping review this!

## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/trigger-ci-5276)\n\n### Merging #5284 will **improve performances by 34.46%**\n\n<sub>Comparing <code>trigger-ci-5276</code> (af0cd9b) with <code>main</code> (6cec7b4)</sub>\n\n\n\n### Summary\n\n`‚ö° 14` improvements\n`‚úÖ 59` untouched benchmarks\n\n\n\n\n### Benchmarks breakdown\n\n|     | Benchmark | `main` | `trigger-ci-5276` | Change |\n| --- | --------- | ----------------------- | ------------------- | ------ |\n| ‚ö° | `buffer 256 KiB * 32 chunk` | 212.8 ns | 183.6 ns | +15.89% |\n| ‚ö° | `buffer 256 KiB * 4 chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `buffer 4.00 MiB * 32 chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `buffer 4.00 MiB * 4 chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `256 KiB * 1000k chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `256 KiB * 1000k truncate` | 275 ns | 216.7 ns | +26.92% |\n| ‚ö° | `256 KiB * 100k chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `256 KiB * 100k truncate` | 275 ns | 216.7 ns | +26.92% |\n| ‚ö° | `256 KiB * 10k chunk` | 212.8 ns | 183.6 ns | +15.89% |\n| ‚ö° | `256 KiB * 10k truncate` | 275 ns | 216.7 ns | +26.92% |\n| ‚ö° | `256 KiB * 1k chunk` | 183.6 ns | 154.4 ns | +18.88% |\n| ‚ö° | `256 KiB * 1k truncate` | 275 ns | 216.7 ns | +26.92% |\n| ‚ö° | `concurrent 16` | 391.2 ¬µs | 290.9 ¬µs | +34.46% |\n| ‚ö° | `concurrent 4` | 410.3 ¬µs | 365.3 ¬µs | +12.33% |\n

## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/remove-secrets-for-benchmark)\n\n### Merging #5283 will **degrade performances by 11.34%**\n\n<sub>Comparing <code>remove-secrets-for-benchmark</code> (66aa09d) with <code>main</code> (71c12a3)</sub>\n\n\n\n### Summary\n\n`‚ùå 1` regressions\n`‚úÖ 72` untouched benchmarks\n\n\n\n> :warning: _Please fix the performance issues or [acknowledge them on CodSpeed](https://codspeed.io/apache/opendal/branches/remove-secrets-for-benchmark)._\n\n### Benchmarks breakdown\n\n|     | Benchmark | `main` | `remove-secrets-for-benchmark` | Change |\n| --- | --------- | ----------------------- | ------------------- | ------ |\n| ‚ùå | `concurrent 4` | 410.2 ¬µs | 462.7 ¬µs | -11.34% |\n

> Merging https://github.com/apache/opendal/pull/5283 will degrade performances by 11.34%\r\n\r\nI found codspeed give a regression alert. It could be config in the setting. I will watch for some days to adjust the threshold. For now, it is 10%.\r\n<img width="827" alt="image" src="https://github.com/user-attachments/assets/b276a522-a443-4bc6-b93c-6dc5224039dc">\r\n

![image](https://github.com/user-attachments/assets/480c014f-c72d-45ed-b65b-3db37dc5c627)\r\n

Hi, @dqhl76, token has been created at `op://services/codspeed/token`.

## [CodSpeed Performance Report](https://codspeed.io/apache/opendal/branches/benchmark-ci)\n\n\n### Congrats! CodSpeed is installed üéâ\n\n`üÜï` **73 new benchmarks were detected.**\n\nYou will start to see performance impacts in the reports once the benchmarks are run from your default branch.\n\n<details>\n  <summary><h3>Detected benchmarks</h3></summary>\n\n- `16.0 MiB` (8.5 ms)\n- `256 KiB` (192.2 ¬µs)\n- `4.00 KiB` (62.3 ¬µs)\n- `4.00 MiB` (2.2 ms)\n- `16x16.0 MiB` (236.9 ¬µs)\n- `16x256 KiB` (237.2 ¬µs)\n- `16x4.00 KiB` (234.6 ¬µs)\n- `16x4.00 MiB` (237.4 ¬µs)\n- `1x16.0 MiB` (54.5 ¬µs)\n- `1x256 KiB` (54.7 ¬µs)\n- `1x4.00 KiB` (54.6 ¬µs)\n- `1x4.00 MiB` (54.6 ¬µs)\n- `2x16.0 MiB` (66.9 ¬µs)\n- `2x256 KiB` (67.2 ¬µs)\n- `2x4.00 KiB` (66.7 ¬µs)\n- `2x4.00 MiB` (67 ¬µs)\n- `4x16.0 MiB` (91.5 ¬µs)\n- `4x256 KiB` (91.6 ¬µs)\n- `4x4.00 KiB` (90.2 ¬µs)\n- `4x4.00 MiB` (91.8 ¬µs)\n- `8x16.0 MiB` (141.2 ¬µs)\n- `8x256 KiB` (140 ¬µs)\n- `8x4.00 KiB` (139.2 ¬µs)\n- `8x4.00 MiB` (140.7 ¬µs)\n- `16.0 MiB` (57 ¬µs)\n- `256 KiB` (56.7 ¬µs)\n- `4.00 KiB` (56.7 ¬µs)\n- `4.00 MiB` (56.8 ¬µs)\n- `1` (91.6 ¬µs)\n- `2` (91.8 ¬µs)\n- `4` (91.9 ¬µs)\n- `8` (92 ¬µs)\n- `buffer 256 KiB * 32 advance` (660.6 ns)\n- `buffer 256 KiB * 32 chunk` (212.8 ns)\n- `buffer 256 KiB * 32 truncate` (375.3 ns)\n- `buffer 256 KiB * 4 advance` (660.6 ns)\n- `buffer 256 KiB * 4 chunk` (183.6 ns)\n- `buffer 256 KiB * 4 truncate` (375.3 ns)\n- `buffer 4.00 MiB * 32 advance` (660.6 ns)\n- `buffer 4.00 MiB * 32 chunk` (183.6 ns)\n- `buffer 4.00 MiB * 32 truncate` (375.3 ns)\n- `buffer 4.00 MiB * 4 advance` (660.6 ns)\n- `buffer 4.00 MiB * 4 chunk` (183.6 ns)\n- `buffer 4.00 MiB * 4 truncate` (375.3 ns)\n- `bytes buf 256 KiB * 32  advance` (493.3 ns)\n- `bytes buf 256 KiB * 32  chunk` (0 s)\n- `bytes buf 256 KiB * 32  truncate` (552.8 ns)\n- `bytes buf 256 KiB * 4  advance` (493.3 ns)\n- `bytes buf 256 KiB * 4  chunk` (0 s)\n- `bytes buf 256 KiB * 4  truncate` (552.8 ns)\n- `bytes buf 4.00 MiB * 32  advance` (493.3 ns)\n- `bytes buf 4.00 MiB * 32  chunk` (0 s)\n- `bytes buf 4.00 MiB * 32  truncate` (552.8 ns)\n- `bytes buf 4.00 MiB * 4  advance` (493.3 ns)\n- `bytes buf 4.00 MiB * 4  chunk` (0 s)\n- `bytes buf 4.00 MiB * 4  truncate` (552.8 ns)\n- `256 KiB * 1000k advance` (17.4 ms)\n- `256 KiB * 1000k chunk` (154.4 ns)\n- `256 KiB * 1000k truncate` (216.7 ns)\n- `256 KiB * 100k advance` (1.7 ms)\n- `256 KiB * 100k chunk` (154.4 ns)\n- `256 KiB * 100k truncate` (216.7 ns)\n- `256 KiB * 10k advance` (174.1 ¬µs)\n- `256 KiB * 10k chunk` (183.6 ns)\n- `256 KiB * 10k truncate` (216.7 ns)\n- `256 KiB * 1k advance` (17.9 ¬µs)\n- `256 KiB * 1k chunk` (154.4 ns)\n- `256 KiB * 1k truncate` (216.7 ns)\n- `concurrent 1` (268.8 ¬µs)\n- `concurrent 16` (324.6 ¬µs)\n- `concurrent 2` (530.1 ¬µs)\n- `concurrent 4` (419.1 ¬µs)\n- `concurrent 8` (361.4 ¬µs)\n\n</details>

The benchmark is identified by name, and we can expand it to support various services. We can implement this in future PRs.

Hi @Xuanwo, All comments are applied, could you please take a look again? Thanks!

Manually tested with a config file

hi, @Zheaoli, https://github.com/apache/opendal/pull/5279 has been merged, would you like to update the changelogs?

See https://github.com/apache/opendal/pull/5284

Nice work!\r\n\r\n![image](https://github.com/user-attachments/assets/cd3a726b-70f8-42b6-9b6c-5d7e1da47782)\r\n\r\n

@LYZJU2019 any updates on this?

Updates are underway. Stay tuned!

> Updates are underway. Stay tuned!\r\n\r\nHi, perhaps we can divide this work into parts so that community members can participate as well. Considering our recent changes, this PR is almost deprecated, so we need a new one.\r\n\r\nMaybe we (@LYZJU2019 and @Eason0729) can discuss the detailed tasks in https://github.com/apache/opendal/issues/2442 and collaborate together?

I have outlined some brief ideas regarding the tasks we need to complete. Feel free to join the discussion: https://github.com/apache/opendal/issues/2442#issuecomment-2708017211

Hi, @koushiro, there are some conflicts preventing us from merging this PR. Could you take a look?

This is a breaking change, we will need to wait for https://github.com/apache/opendal/discussions/5257

Yeah, we can reopen this PR when we need it

I think we can close this PR for now and reopen it when MSRV is upgraded to 1.80

Why??\r\n```bash\r\n================================================================================\r\n    "operator advanced operations" - Unsupported\r\n================================================================================\r\n    /home/kassane/opendal/bindings/zig/src/opendal.zig:269:5: 0x103d9a0 in codeToError (test)\r\n        return switch (code) {\r\n        ^\r\n    /home/kassane/opendal/bindings/zig/src/opendal.zig:113:13: 0x103f725 in copy (test)\r\n                try codeToError(err.*.code);\r\n                ^\r\n    /home/kassane/opendal/bindings/zig/src/opendal.zig:385:5: 0x1040031 in test.operator advanced operations (test)\r\n        try op.copy("/testdir/renamed.txt", "/testdir/copied.txt");\r\n        ^\r\n```\r\nhttps://github.com/apache/opendal/blob/b2c839c89ee7d3f193d50991bbcef45c9ab71355/bindings/zig/src/opendal.zig#L394-L402

@Xuanwo,\r\n\r\nasync unittest get error:\r\n<details>\r\n<summary>GDB output</summary>\r\n\r\n```bash\r\nWarning: \

Thank you @kassane for you effort, I will review this PR later this week.

> Thank you @kassane for you effort, I will review this PR later this week.\r\n\r\nNice!\r\nNow, latest commit clean `build.zig` - `opendal_module` provide all dependencies.

> * `fn set_scheme(&mut self, scheme: Scheme) -> &mut Self` => `fn set_scheme(mut self, scheme: Scheme) -> Self`\r\n> * `fn set_root(&mut self, root: &str) -> &mut Self` => `fn set_root(mut self, root: &str) -> Self`\r\n> * `fn set_name(&mut self, name: &str) -> &mut Self` => `fn set_name(mut self, name: &str) -> Self`\r\n> * `fn set_native_capability(&mut self, capability: Capability) -> &mut Self` => `fn set_native_capability(mut self, capability: Capability) -> Self`\r\n\r\nHi, this is our API naming style that:\r\n\r\n- `fn abc(&self) -> Abc`\r\n- `fn set_abc(&mut self, v: Abc) -> &mut Self`\r\n- `fn with_abc(mut self, v: Abc) -> Self`.

> Hi, this is our API naming style that:\r\n> \r\n> * `fn abc(&self) -> Abc`\r\n> * `fn set_abc(&mut self, v: Abc) -> &mut Self`\r\n> * `fn with_abc(mut self, v: Abc) -> Self`.\r\n\r\n@Xuanwo So do you think this change is ok, except for the API naming style?

> So do you think this change is ok, except for the API naming style?\r\n\r\nI believe we only need to add `set_full_capability` and mark `full_capability_mut` as deprecated. Other changes seem not needed.

> In general, we don\

Thank you @PsiACE for the review!

Thank you @Zheaoli for the review.

Thank you @dqhl76 for the quick review!

Thanks for your contribution

Thank you @XmchxUp for working on this and thank you @PsiACE for the quick review üôè 

Hi, I implemented this to support the use of a proxy as follows:\r\n\r\n```\r\nln oli ocp\r\nocp <src> <dst>\r\n\r\nln oli ols\r\nols <src>\r\n```\r\n\r\nUsers can use `ocp` in exactly the same way as `oli cp`.\r\n\r\nAfter this change, can we still operate in this manner?

> Hi, I implemented this to support the use of a proxy as follows:\r\n> \r\n> ```\r\n> ln oli ocp\r\n> ocp <src> <dst>\r\n> \r\n> ln oli ols\r\n> ols <src>\r\n> ```\r\n> \r\n> Users can use `ocp` in exactly the same way as `oli cp`.\r\n> \r\n> After this change, can we still operate in this manner?\r\n\r\nNo, but I can try to support this manner.\r\nDo you think the other parts are ok?

> Do you think the other parts are ok?\r\n\r\nOther parts looks good to me, thank you for working on this!

> Hi, I implemented this to support the use of a proxy as follows:\r\n> \r\n> ```\r\n> ln oli ocp\r\n> ocp <src> <dst>\r\n> \r\n> ln oli ols\r\n> ols <src>\r\n> ```\r\n> \r\n> Users can use `ocp` in exactly the same way as `oli cp`.\r\n> \r\n\r\nI encountered two problems:\r\n1. The previous (before this PR) implementation had the following problem:\r\n```\r\n‚ûú  oli git:(main) ln target/release/oli ols\r\n‚ûú  oli git:(main) ‚úó ./ols src\r\nerror: \

Thanks, merging...

Thank you @dqhl76 for the quick review and merge!

I did some experimentation ([patch](https://gist.github.com/erickguan/80bbf2ea82a10c69d260c53f0dd2f97b)) with async support for listing operations, which helps reduce runtime as expected. However, extending `OpList `introduces a "breaking" change. Since OpenDAL has a compatibility package, I‚Äôm happy to coordinate with you when you\

Also related to https://github.com/apache/opendal/discussions/5287

Thanks for tentative checking in with metakey!

After a closer look, can I pause this PR until your metakey work?

> After a closer look, can I pause this PR until your metakey work?\r\n\r\nYes, after the metakey is refactored, our work here will be much cleaner.\r\n

> Yes, after the metakey is refactored, our work here will be much cleaner.\r\n\r\nHi, you can continue your work now.

Not sure if we test services mysql against bindings and how we add such tests.

> Not sure if we test services mysql against bindings and how we add such tests.\r\n\r\nThey are always tested but not released because Linux x86_64 consistently works correctly, whereas other platforms do not.

Thank you @dqhl76 for the review!

Thank you @dqhl76 for the quick review! I will merge this PR after the release workflow finished.

Thank you @oowl for the quick review! I will merge this PR while CI all green.

There are some critical bug fixes that need to be released. I will merge this after we create a new release.

Thank you @PsiACE for the review!

See also https://github.com/apache/opendal/discussions/5077#discussioncomment-10973047

Inviting @silver-ymz and @xyjixyjixyji to take another look.

CC @yuchanns, please review [`8071f91` (#5185)](https://github.com/apache/opendal/pull/5185/commits/8071f913abc5edde41039b99b7aae190ad5f428f) and let me know if it looks good to you.

LGTM on green

My CI/CD test: https://github.com/kassane/opendal/actions/runs/11391182857\r\n\r\nshow\r\n```bash\r\nwarning: use of deprecated method `opendal::BlockingOperator::is_exist`: rename to `exists` for consistence with `std::fs::exists`\r\n   --> src/operator.rs:530:22\r\n    |\r\n530 |     match op.deref().is_exist(path) {\r\n    |                      ^^^^^^^^\r\n    |\r\n    = note: `#[warn(deprecated)]` on by default\r\n```\r\n\r\nfixed in https://github.com/apache/opendal/pull/5198 ? (No, cpp-binding only)

Rebased, single commit!

Thank you @dqhl76 for the quick review!

Thank you @George-Miao for the review!

Wow, thank you @XmchxUp a lot for this!

@yuchanns now compile can work but test failed. Please see https://github.com/apache/opendal/actions/runs/11230441983/job/31217839150.

@yuchanns I fixed the go cases now.

Oops! The rebase overwrites your real commits. Sorry.\r\n\r\nSince #5179 has been merged, the go-binding can now be easily debugged. See https://github.com/apache/opendal/tree/main/bindings/go#development\r\n\r\nAnd I will debug the go part in this PR

The Go binding CI is green now. @tisonkun 

the change in readme: <https://stackoverflow.com/a/21594/13040423>\r\n

Fair enough to move forward in my opinion.\r\n\r\nWhat do you think? @Xuanwo @yuchanns @xyjixyjixyji 

> Does it make a difference in understanding or performance in a public API on the C side?\r\n\r\nno.\r\n\r\nTuple style is just a syntax sugar that has `0` instead of `inner` as a field.\r\n

So we may suspend this request and perhaps review it again before we build the release process for the C binding.

IMO `inner` name provides better semantics when developers are reading the actual header files.

Closed due to discussions above. I am open to reopen this if someone favors this approach and illustrate reasons.

This is ready to be reviewed, cc @Xuanwo @PsiACE , I also fixed the bug in Go bindings\r\n\r\n

It makes main branch tests continue to fail, Thanks, merged 

@Xuanwo @tisonkun PTAL

@Xuanwo @tisonkun PTAL, thanks :)

I think Serializer cannot be demonstrated independently at the moment as it works in conjunction with the operations. It is used for serializing any class (by default, we use Jackson Databind). Here‚Äôs an example of how it can be used:\r\n\r\n```java\r\npublic class ExampleEntity {\r\n    private String id;\r\n    private String name;\r\n\r\n    // Getters and setters\r\n    public String getId() {\r\n        return id;\r\n    }\r\n\r\n    public void setId(String id) {\r\n        this.id = id;\r\n    }\r\n\r\n    public String getName() {\r\n        return name;\r\n    }\r\n\r\n    public void setName(String name) {\r\n        this.name = name;\r\n    }\r\n}\r\n```\r\nThen Opertions can be applied by \r\n```java\r\nOpenDALOpertions<ExampleEntity> ops = openDALTemplate.opsForMeasurement(\r\n                ExampleEntity.class);\r\n```\r\nThen he can do opendal options by this ops handle/

Thanks a lot for your review!\r\n\r\n> Thanks for your work! The code LGTM. However, I am not sure if the failed test related with this PR because it has so many lines of log information, it makes me hard to find the specific failed test üò¢.\r\n\r\n- Aliyun Drive and Google Drive are unstable; this is a known issue. \r\n- I will try to make the logs less verbose.\r\n

why is there no `#` before `use opendal::Operator;` at line 127 ? is a mistake or intentional ? do we have any guidelines for this ?\r\n\r\nhttps://github.com/apache/opendal/blob/d479ac39efa9a88e10448ad81e47292b3b4ed688/core/src/types/operator/operator.rs#L122-L133

Ready for review

After difficult debugging on macOS environment ( macOS has the big gap in fuse feature compared to BSD and Linux.)\r\n\r\n```shell\r\n‚ï≠‚îÄouyangjun@ouyangs-air ~/code/opendal/bin/ofs ‚Äπfeat/owl/ofs-macos‚óè‚Ä∫\r\n‚ï∞‚îÄ$ uname -a                                                                                                                                                                                                                             1 ‚Üµ\r\nDarwin ouyangs-air.lan 23.4.0 Darwin Kernel Version 23.4.0: Wed Feb 21 21:51:37 PST 2024; root:xnu-10063.101.15~2/RELEASE_ARM64_T8112 arm64\r\n‚ï≠‚îÄouyangjun@ouyangs-air ~/code/opendal/bin/ofs ‚Äπfeat/owl/ofs-macos‚óè‚Ä∫\r\n‚ï∞‚îÄ$ umount -f /Users/ouyangjun/code/opendal/bin/ofs/exampless\r\n‚ï≠‚îÄouyangjun@ouyangs-air ~/code/opendal/bin/ofs ‚Äπfeat/owl/ofs-macos‚óè‚Ä∫\r\n‚ï∞‚îÄ$ ./target/debug/ofs ~/code/opendal/bin/ofs/exampless "fs://?root=/Users/ouyangjun/code/libuv/src"\r\n```\r\n\r\n```\r\n‚ï≠‚îÄouyangjun@ouyangs-air ~/code/opendal/bin/ofs ‚Äπfeat/owl/ofs-macos‚óè‚Ä∫\r\n‚ï∞‚îÄ$ ls -al ~/code/opendal/bin/ofs/exampless/\r\ntotal 0\r\nls: /Users/ouyangjun/code/opendal/bin/ofs/exampless/: Device not configured\r\n‚ï≠‚îÄouyangjun@ouyangs-air ~/code/opendal/bin/ofs ‚Äπfeat/owl/ofs-macos‚óè‚Ä∫\r\n‚ï∞‚îÄ$ ls -al ~/code/opendal/bin/ofs/exampless/                                                                                                                                                                                             1 ‚Üµ\r\ntotal 288\r\ndrwxrwxr-x   0 ouyangjun  staff      0 Apr  3 01:15 .\r\ndrwxr-xr-x  10 ouyangjun  staff    320 Apr  2 16:30 ..\r\n-rwxrwxr-x   0 ouyangjun  staff      0 Apr  3 01:14 .aaa.swp\r\n-rwxrwxr-x   0 ouyangjun  staff      0 Apr  3 01:14 aaa\r\n-rwxrwxr-x   0 ouyangjun  staff   7607 May 30  2023 fs-poll.c\r\n-rwxrwxr-x   0 ouyangjun  staff   7053 May 30  2023 heap-inl.h\r\n-rwxrwxr-x   0 ouyangjun  staff   6393 May 30  2023 idna.c\r\n-rwxrwxr-x   0 ouyangjun  staff   1455 May 30  2023 idna.h\r\n-rwxrwxr-x   0 ouyangjun  staff   8068 May 30  2023 inet.c\r\n-rwxrwxr-x   0 ouyangjun  staff   2671 May 30  2023 queue.h\r\n-rwxrwxr-x   0 ouyangjun  staff   3423 May 30  2023 random.c\r\n-rwxrwxr-x   0 ouyangjun  staff   1449 May 30  2023 strscpy.c\r\n-rwxrwxr-x   0 ouyangjun  staff   1748 May 30  2023 strscpy.h\r\n-rwxrwxr-x   0 ouyangjun  staff   1656 May 30  2023 strtok.c\r\n-rwxrwxr-x   0 ouyangjun  staff   1271 May 30  2023 strtok.h\r\n-rwxrwxr-x   0 ouyangjun  staff   3941 May 30  2023 thread-common.c\r\n-rwxrwxr-x   0 ouyangjun  staff  11089 May 30  2023 threadpool.c\r\n-rwxrwxr-x   0 ouyangjun  staff   4731 May 30  2023 timer.c\r\ndrwxrwxr-x   0 ouyangjun  staff   1760 May 30  2023 unix\r\n-rwxrwxr-x   0 ouyangjun  staff  23323 May 30  2023 uv-common.c\r\n-rwxrwxr-x   0 ouyangjun  staff  17118 May 30  2023 uv-common.h\r\n-rwxrwxr-x   0 ouyangjun  staff   3126 May 30  2023 uv-data-getter-setters.c\r\n-rwxrwxr-x   0 ouyangjun  staff   1751 May 30  2023 version.c\r\ndrwxrwxr-x   0 ouyangjun  staff   1120 May 30  2023 win\r\n‚ï≠‚îÄouyangjun@ouyangs-air ~/code/opendal/bin/ofs ‚Äπfeat/owl/ofs-macos‚óè‚Ä∫\r\n‚ï∞‚îÄ$ ls -al ~/code/opendal/bin/ofs/exampless/\r\ntotal 288\r\ndrwxrwxr-x   0 ouyangjun  staff      0 Apr  3 01:15 .\r\ndrwxr-xr-x  10 ouyangjun  staff    320 Apr  2 16:30 ..\r\n-rwxrwxr-x   0 ouyangjun  staff      0 Apr  3 01:14 .aaa.swp\r\n-rwxrwxr-x   0 ouyangjun  staff      0 Apr  3 01:14 aaa\r\n-rwxrwxr-x   0 ouyangjun  staff   7607 May 30  2023 fs-poll.c\r\n-rwxrwxr-x   0 ouyangjun  staff   7053 May 30  2023 heap-inl.h\r\n-rwxrwxr-x   0 ouyangjun  staff   6393 May 30  2023 idna.c\r\n-rwxrwxr-x   0 ouyangjun  staff   1455 May 30  2023 idna.h\r\n-rwxrwxr-x   0 ouyangjun  staff   8068 May 30  2023 inet.c\r\n-rwxrwxr-x   0 ouyangjun  staff   2671 May 30  2023 queue.h\r\n-rwxrwxr-x   0 ouyangjun  staff   3423 May 30  2023 random.c\r\n-rwxrwxr-x   0 ouyangjun  staff   1449 May 30  2023 strscpy.c\r\n-rwxrwxr-x   0 ouyangjun  staff   1748 May 30  2023 strscpy.h\r\n-rwxrwxr-x   0 ouyangjun  staff   1656 May 30  2023 strtok.c\r\n-rwxrwxr-x   0 ouyangjun  staff   1271 May 30  2023 strtok.h\r\n-rwxrwxr-x   0 ouyangjun  staff   3941 May 30  2023 thread-common.c\r\n-rwxrwxr-x   0 ouyangjun  staff  11089 May 30  2023 threadpool.c\r\n-rwxrwxr-x   0 ouyangjun  staff   4731 May 30  2023 timer.c\r\ndrwxrwxr-x   0 ouyangjun  staff   1760 May 30  2023 unix\r\n-rwxrwxr-x   0 ouyangjun  staff  23323 May 30  2023 uv-common.c\r\n-rwxrwxr-x   0 ouyangjun  staff  17118 May 30  2023 uv-common.h\r\n-rwxrwxr-x   0 ouyangjun  staff   3126 May 30  2023 uv-data-getter-setters.c\r\n-rwxrwxr-x   0 ouyangjun  staff   1751 May 30  2023 version.c\r\ndrwxrwxr-x   0 ouyangjun  staff   1120 May 30  2023 win\r\n‚ï≠‚îÄouyangjun@ouyangs-air ~/code/opendal/bin/ofs ‚Äπfeat/owl/ofs-macos‚óè‚Ä∫\r\n‚ï∞‚îÄ$ cat ~/code/opendal/bin/ofs/exampless/\r\ncat: /Users/ouyangjun/code/opendal/bin/ofs/exampless/: Is a directory\r\n‚ï≠‚îÄouyangjun@ouyangs-air ~/code/opendal/bin/ofs ‚Äπfeat/owl/ofs-macos‚óè‚Ä∫\r\n‚ï∞‚îÄ$ cat ~/code/opendal/bin/ofs/exampless/idna.h                                                                                                                                                                                          1 ‚Üµ\r\n/* Copyright (c) 2011, 2018 Ben Noordhuis <info@bnoordhuis.nl>\r\n *\r\n * Permission to use, copy, modify, and/or distribute this software for any\r\n * purpose with or without fee is hereby granted, provided that the above\r\n * copyright notice and this permission notice appear in all copies.\r\n *\r\n * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES\r\n * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\r\n * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\r\n * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\r\n * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\r\n * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF\r\n * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\r\n */\r\n\r\n#ifndef UV_SRC_IDNA_H_\r\n#define UV_SRC_IDNA_H_\r\n\r\n/* Decode a single codepoint. Returns the codepoint or UINT32_MAX on error.\r\n * |p| is updated on success _and_ error, i.e., bad multi-byte sequences are\r\n * skipped in their entirety, not just the first bad byte.\r\n */\r\nunsigned uv__utf8_decode1(const char** p, const char* pe);\r\n\r\n/* Convert a UTF-8 domain name to IDNA 2008 / Punycode. A return value >= 0\r\n * is the number of bytes written to |d|, including the trailing nul byte.\r\n * A return value < 0 is a libuv error code. |s| and |d| can not overlap.\r\n */\r\nlong uv__idna_toascii(const char* s, const char* se, char* d, char* de);\r\n\r\n#endif  /* UV_SRC_IDNA_H_ */\r\n```

> It mostly looks good to me. To make this feature work, we should also add a flag in `Capability` called `write_with_if_none_match`. Additionally, we can add a behavior test based on this.\r\n\r\n Thank you very much for your careful help. I have revised all your comments. üòÑ 

`if_none_match` also supported by gcs and azblob, would you like to implement them too? cc @ForestLH 

@Xuanwo After a quick search I found many occurrences of this pattern.\r\nWould you be open to a PR with that many changes?

Hi, @suyanhanx, thanks a lot for your review!

![image](https://github.com/user-attachments/assets/9d576f66-0cea-4ccf-b3a2-211bf8bec518)\r\nThe CI error in Node.js seems to be not caused by this modification. The latest branch I updated locally did not include my code, and this error still occurs

> ![image](https://private-user-images.githubusercontent.com/127465317/367160161-9d576f66-0cea-4ccf-b3a2-211bf8bec518.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjY1OTAyMDgsIm5iZiI6MTcyNjU4OTkwOCwicGF0aCI6Ii8xMjc0NjUzMTcvMzY3MTYwMTYxLTlkNTc2ZjY2LTBjZWEtNGNjZi1iM2EyLTIxMWJmOGJlYzUxOC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwOTE3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDkxN1QxNjE4MjhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT03NTVhYWI5YTEwNDQxODc2ZGYzNjcwN2M1OThkMjIzYjYxZjJlZTg2NDhjZTljMWNmNjdjNzE1NmM3ODI1N2M5JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.K8pwcanr8XoKlHrtM-eCMOUPqpnCxzQ9bc4bzDrvX-4) The CI error in Node.js seems to be not caused by this modification. The latest branch I updated locally did not include my code, and this error still occurs\r\n\r\nShould be fixed by https://github.com/apache/opendal/pull/5121

Test results are as follows:\r\n```\r\n$ OPENDAL_TEST=nebulagraph cargo test behavior --features tests -- --nocapture --test-threads=20\r\n    Finished `test` profile [unoptimized + debuginfo] target(s) in 0.32s\r\n     Running unittests src/lib.rs (target/debug/deps/opendal-20c211e669cef355)\r\n\r\nrunning 0 tests\r\n\r\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 128 filtered out; finished in 0.00s\r\n\r\n     Running tests/behavior/main.rs (target/debug/deps/behavior-0bda2893f3ecdc95)\r\n\r\nrunning 90 tests\r\ntest behavior::test_delete_with_version                       ... ok\r\ntest behavior::test_delete_with_not_existing_version          ... ok\r\ntest behavior::test_delete_not_existing                       ... ok\r\ntest behavior::test_list_with_start_after                     ... ok\r\ntest behavior::test_check                                     ... ok\r\ntest behavior::test_list_non_exist_dir                        ... ok\r\ntest behavior::test_delete_empty_dir                          ... ok\r\ntest behavior::test_create_dir                                ... ok\r\ntest behavior::test_create_dir_existing                       ... ok\r\ntest behavior::test_list_files_with_version                   ... ok\r\ntest behavior::test_list_with_version_and_limit               ... ok\r\ntest behavior::test_list_with_version_and_start_after         ... ok\r\ntest behavior::test_list_root_with_recursive                  ... ok\r\ntest behavior::test_list_sub_dir                              ... ok\r\ntest behavior::test_list_file_with_recursive                  ... ok\r\ntest behavior::test_list_empty_dir                            ... ok\r\ntest behavior::test_read_with_if_match                        ... ok\r\ntest behavior::test_read_with_if_none_match                   ... ok\r\ntest behavior::test_list_dir                                  ... ok\r\ntest behavior::test_read_not_exist                            ... ok\r\ntest behavior::test_read_with_override_cache_control          ... ok\r\ntest behavior::test_read_with_override_content_disposition    ... ok\r\ntest behavior::test_read_with_override_content_type           ... ok\r\ntest behavior::test_read_with_version                         ... ok\r\ntest behavior::test_read_with_not_existing_version            ... ok\r\ntest behavior::test_read_with_dir_path                        ... ok\r\ntest behavior::test_stat_dir                                  ... ok\r\ntest behavior::test_list_nested_dir                           ... ok\r\ntest behavior::test_list_dir_with_recursive_no_trailing_slash ... ok\r\ntest behavior::test_list_dir_with_recursive                   ... ok\r\ntest behavior::test_stat_not_exist                            ... ok\r\ntest behavior::test_stat_with_if_match                        ... ok\r\ntest behavior::test_stat_with_if_none_match                   ... ok\r\ntest behavior::test_stat_with_override_cache_control          ... ok\r\ntest behavior::test_stat_with_override_content_disposition    ... ok\r\ntest behavior::test_stat_with_override_content_type           ... ok\r\ntest behavior::test_stat_root                                 ... ok\r\ntest behavior::test_stat_with_version                         ... ok\r\ntest behavior::stat_with_not_existing_version                 ... ok\r\ntest behavior::test_remove_all                                ... ok\r\ntest behavior::test_write_only                                ... ok\r\ntest behavior::test_write_with_dir_path                       ... ok\r\ntest behavior::test_write_with_empty_content                  ... ok\r\ntest behavior::test_write_with_cache_control                  ... ok\r\ntest behavior::test_write_with_content_type                   ... ok\r\ntest behavior::test_write_with_content_disposition            ... ok\r\ntest behavior::test_write_with_user_metadata                  ... ok\r\ntest behavior::test_writer_write                              ... ok\r\ntest behavior::test_stat_nested_parent_dir                    ... ok\r\ntest behavior::test_writer_write_with_concurrent              ... ok\r\ntest behavior::test_writer_sink                               ... ok\r\ntest behavior::test_writer_sink_with_concurrent               ... ok\r\ntest behavior::test_list_rich_dir                             ... ok\r\ntest behavior::test_writer_abort                              ... ok\r\ntest behavior::test_writer_futures_copy                       ... ok\r\ntest behavior::test_writer_futures_copy_with_concurrent       ... ok\r\ntest behavior::test_blocking_create_dir                       ... ok\r\ntest behavior::test_write_with_special_chars                  ... ok\r\ntest behavior::test_blocking_create_dir_existing              ... ok\r\ntest behavior::test_blocking_delete_file                      ... ok\r\ntest behavior::test_reader                                    ... ok\r\ntest behavior::test_writer_abort_with_concurrent              ... ok\r\ntest behavior::test_read_range                                ... ok\r\ntest behavior::test_blocking_read_not_exist                   ... ok\r\ntest behavior::test_read_with_special_chars                   ... ok\r\ntest behavior::test_blocking_stat_dir                         ... ok\r\ntest behavior::test_list_dir_with_file_path                   ... ok\r\ntest behavior::test_blocking_stat_not_exist                   ... ok\r\ntest behavior::test_blocking_stat_with_special_chars          ... ok\r\ntest behavior::test_list_prefix                               ... ok\r\ntest behavior::test_blocking_write_with_dir_path              ... ok\r\ntest behavior::test_blocking_stat_file                        ... ok\r\ntest behavior::test_stat_file                                 ... ok\r\ntest behavior::test_remove_one_file                           ... ok\r\ntest behavior::test_blocking_write_file                       ... ok\r\ntest behavior::test_blocking_remove_all_basic                 ... ok\r\ntest behavior::test_stat_not_cleaned_path                     ... ok\r\ntest behavior::test_delete_with_special_chars                 ... ok\r\ntest behavior::test_delete_file                               ... ok\r\ntest behavior::test_read_full                                 ... ok\r\ntest behavior::test_list_dir_with_metakey                     ... ok\r\ntest behavior::test_stat_with_special_chars                   ... ok\r\ntest behavior::test_blocking_read_full                        ... ok\r\ntest behavior::test_blocking_remove_one_file                  ... ok\r\ntest behavior::test_blocking_read_range                       ... ok\r\ntest behavior::test_list_dir_with_metakey_complete            ... ok\r\ntest behavior::test_delete_stream                             ... ok\r\ntest behavior::test_blocking_write_with_special_chars         ... ok\r\ntest behavior::test_remove_all_basic                          ... ok\r\ntest behavior::test_writer_write_with_overwrite               ... ok\r\n\r\ntest result: ok. 90 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 1.56s\r\n```

Hi, @GG2002. It might take us a while to complete the communication. Would you like to split this PR into parts so we can merge some of them first? I believe we can add the builder, config first without introduce the client impl in.

@Xuanwo PTAL

Thank you @dqhl76 for the quick review, love you!

Thanks a lot for the quick review @oowl!

Thank you @George-Miao for the quick review!

2. Because `list` and `list with version` use different APIs in S3, should we add new Github actions for S3, such as `aws_s3_with_version` Ôºü if we only use a bucket with object versioning enabled to test all cases, we might unintentionally skip the tests for `ListObjectsV2`

> [tracker.ceph.com/issues/68055](https://tracker.ceph.com/issues/68055) (The Issues of Ceph repository is not enabled)\r\n\r\nWe can create an issue on the OpenDAL side to keep track of it.

> > [tracker.ceph.com/issues/68055](https://tracker.ceph.com/issues/68055) (The Issues of Ceph repository is not enabled)\r\n> \r\n> We can create an issue on the OpenDAL side to keep track of it.\r\n\r\nOk, Let me do it later

Thank you @oowl for the review!

The fail CI should be addressed by https://github.com/apache/opendal/pull/5102

Because of the design of the [metrics](https://docs.rs/metrics/latest/metrics/), we cannot do following things at the API level of the metrics library\r\n1. specify the buckets of the histogram metrics\r\n3. specify labels while modifying the metrics

Thank you very much for your work! I have noticed that Monoio performs well on single reads but not as effectively on concurrent ones. Could this be related to our thread-per-core design? Are there any plans to improve it?

Also, PositionWrite is not implemented for monoiofs.

#5073

@Xuanwo PTAL

> Thanks! Overall, this PR looks good to me. Here are a few minor suggestions for improvement.\r\n\r\nPTAL

Thank you very much for your PR! Before we start reviewing it, could you please fix the code formatting and run a Clippy check? These issues can be resolved by:\r\n\r\n```\r\ncargo fmt\r\ncargo clippy --features=services-lakefs\r\n```

@Xuanwo maybe you can also take a look at this PR?

> @Xuanwo maybe you can also take a look at this PR?\r\n\r\nThis PR appears to include many changes from https://github.com/apache/opendal/pull/5072. Perhaps we should merge https://github.com/apache/opendal/pull/5072 first?

> > @Xuanwo maybe you can also take a look at this PR?\r\n> \r\n> This PR appears to include many changes from #5072. Perhaps we should merge #5072 first?\r\n\r\nYeah, I just want to give you more information about why I wrote this to provide similar APIs.

There are some weird errors in CI\r\n\r\n```\r\nerror[E0282]: type annotations needed\r\n   --> src/services/icloud/core.rs:530:25\r\n    |\r\n530 |             Some(it) => Ok(Some(it.drivewsid.clone())),\r\n    |                         ^^ cannot infer type of the type parameter `E` declared on the enum `Result`\r\n    |\r\nhelp: consider specifying the generic arguments\r\n    |\r\n530 |             Some(it) => Ok::<std::option::Option<std::string::String>, E>(Some(it.drivewsid.clone())),\r\n    |                           +++++++++++++++++++++++++++++++++++++++++++++++\r\n\r\nerror[E0283]: type annotations needed\r\n   --> src/services/icloud/core.rs:530:25\r\n    |\r\n530 |             Some(it) => Ok(Some(it.drivewsid.clone())),\r\n    |                         ^^ cannot infer type of the type parameter `E` declared on the enum `Result`\r\n531 |             None => Ok(None),\r\n532 |         }?;\r\n    |          - type must be known at this point\r\n    |\r\nnote: multiple `impl`s satisfying `types::error::Error: std::convert::From<_>` found\r\n   --> src/types/error.rs:418:1\r\n    |\r\n418 | impl From<prometheus::Error> for Error {\r\n    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n    = note: and another `impl` found in the `core` crate: `impl<T> std::convert::From<T> for T;`\r\n    = note: required for `std::result::Result<std::option::Option<std::string::String>, types::error::Error>` to implement `std::ops::FromResidual<std::result::Result<std::convert::Infallible, _>>`\r\nhelp: consider specifying the generic arguments\r\n    |\r\n530 |             Some(it) => Ok::<std::option::Option<std::string::String>, E>(Some(it.drivewsid.clone())),\r\n    |                           +++++++++++++++++++++++++++++++++++++++++++++++\r\n```\r\n\r\nBut if I change the icloud code, these errors are gone\r\n\r\n```diff\r\n-        let id = match node.items.iter().find(|it| it.name == name) {\r\n-            Some(it) => Ok(Some(it.drivewsid.clone())),\r\n-            None => Ok(None),\r\n-        }?;\r\n-        Ok(id)\r\n+       Ok(node\r\n+          .items\r\n+          .iter()\r\n+          .find(|it| it.name == name)\r\n+          .map(|it| it.drivewsid.clone()))\r\n```

[`9b5c096` (#5072)](https://github.com/apache/opendal/pull/5072/commits/9b5c0968229d7d35970bf1ff05a303a75b61b49e)\r\n\r\nI apologize for not providing a clear review. I suggest adding a `parse_prometheus_error(err: prometheus::Error) -> Error` as a standalone function in the Prometheus layer module itself, rather than within `Error`.\r\n\r\nIn this way, we keep our public types clean and easy to maintain.

Hi, @yuchanns, would you like to take a review?

While it comes to the step `Build C Binding`, you will need to modify the dynamic suffix too:\r\n```yaml\r\n      - name: Build C Binding\r\n        working-directory: bindings/c\r\n        env:\r\n          VERSION: "latest"\r\n          SERVICE: ${{ matrix.service }}\r\n          TARGET: ${{ matrix.build.target }}\r\n          CC: ${{ matrix.build.cc }}\r\n          OS: ${{ matrix.build.os }}\r\n        run: |\r\n          cargo build --target $TARGET  --release\r\n          DIR=$GITHUB_WORKSPACE/libopendal_c_${VERSION}_${SERVICE}_$TARGET\r\n          mkdir $DIR\r\n          if [ ${OS} == \

@yuchanns Thanks, I will test it in my Windows Computer :)

@yuchanns  Any idea about this? I think I am close.\r\n\r\nIt compiles `opendal_c.dll`, instead of `libopendal_c.dll`\r\n\r\n\r\n\r\n```\r\n   Compiling opendal v0.51.1 (D:\\a\\opendal\\opendal\\core)\r\n    Finished `release` profile [optimized] target(s) in 2m 21s\r\n\r\n    Directory: D:\\a\\opendal\\opendal\r\n\r\nMode                 LastWriteTime         Length Name\r\n----                 -------------         ------ ----\r\nd----           1/13/2025  7:47 AM                libopendal_c_latest_fs_x86_64-pc-windows-msvc\r\nzstd: can\

I think renaming it should just works.

@yuchanns Sorry, can you give me some hint about this error?\r\n\r\n```\r\nError: C:\\Users\\runneradmin\\go\\pkg\\mod\\github.com\\apache\\opendal-go-services\\fs@v0.1.3\\service.go:60:29: undefined: libopendalZst\r\n# github.com/apache/opendal/bindings/go\r\nError: ..\\..\\ffi.go:32:28: undefined: purego.Dlopen\r\nError: ..\\..\\ffi.go:32:48: undefined: purego.RTLD_LAZY\r\nError: ..\\..\\ffi.go:32:65: undefined: purego.RTLD_GLOBAL\r\nError: ..\\..\\ffi.go:44:10: undefined: purego.Dlclose\r\nError: ..\\..\\ffi.go:86:21: undefined: purego.Dlsym\r\nError: ..\\..\\delete.go:58:25: undefined: unix.BytePtrFromString\r\nError: ..\\..\\operator.go:114:24: undefined: unix.BytePtrFromString\r\nError: ..\\..\\operator.go:1[80](https://github.com/apache/opendal/actions/runs/12747104741/job/35524528295?pr=5066#step:18:81):23: undefined: unix.BytePtrFromString\r\nError: ..\\..\\operator.go:184:25: undefined: unix.BytePtrFromString\r\nError: ..\\..\\operator_info.go:328:15: undefined: unix.BytePtrToString\r\nError: ..\\..\\operator_info.go:328:15: too many errors\r\nFAIL\topendal_test [build failed]\r\n```

@yuchanns Could you please give me a chance to try? I would like to try to deep look `opendal-go-services` this week.

Just for remind:\r\n\r\n> Error: ..\\..\\delete.go:58:25: undefined: unix.BytePtrFromString\r\n\r\nThe respective function in Windows is [windows.UTF16PtrFromString](https://pkg.go.dev/golang.org/x/sys/windows#UTF16PtrFromString). FYI: https://pkg.go.dev/golang.org/x/sys/windows\r\n\r\nMaybe you can create a set of `util_$OS.go` files to implement common functions across multiple platforms.\r\n```\r\nutil_windows.go\r\nutil_nix.go\r\n```\r\nAnd export `PtrFromString`.

> Error: C:\\Users\\runneradmin\\go\\pkg\\mod\\github.com\\apache\\opendal-go-services\\fs@v0.1.3\\service.go:60:29: undefined: libopendalZst\r\n> \\# github.com/apache/opendal/bindings/go\r\n\r\nDid you use Go Workspace to develop? Please follow the instructions of https://github.com/apache/opendal/tree/main/bindings/go#development.\r\n\r\nGo Workspace is essential to development across opendal and opendal-go-services.\r\n\r\nDuring the development of the Go binding, we do not rely on artifacts released by opendal-go-services. Instead, we build the latest artifacts from opendal-go-services within the Go Workspace. This is likely why you encountered the error below: there are currently no releases for Windows platform artifacts.\r\n```\r\nError: ..\\..\\ffi.go:32:28: undefined: purego.Dlopen\r\nError: ..\\..\\ffi.go:32:48: undefined: purego.RTLD_LAZY\r\nError: ..\\..\\ffi.go:32:65: undefined: purego.RTLD_GLOBAL\r\nError: ..\\..\\ffi.go:44:10: undefined: purego.Dlclos\r\n```\r\nA positive example is that there are no releases for MacOS artifacts, yet the tests still work because Go Workspace newly generates the artifacts.\r\n\r\n

Hi, @koushiro. Would you like to continue this work and migrate it to the `MetricsLayer` and `PrometheusLayer` as well?\r\n\r\nI believe we can address the existing problems at the same time.

Thanks @WenyXu and @shoothzj for the review!

cc @George-Miao for a review, thanks!

> LGTM\r\n\r\nAs long as we fix it quickly enough, no one will know what happened.

Inviting @yuchanns for another review.

@Xuanwo @tisonkun PTAL, thanks :)

cc @flaneur2020 

Hi, @Koushiro, thanks a lot for the metrics related PRs. I will review them today.

looks good to me, thanks :+1:

Hi, @koushiro, I demonstrated my idea at https://github.com/apache/opendal/pull/5064. Do you like it?

Ok.

@Xuanwo maybe you could review this PR first?

This PR makes think if we can reuse similar code in `prometheus` / `prometheus_client` / `metrics` layer.

Thanks a lot for this PR. I will merge this once we are ready for 0.50 release.

@Xuanwo is there a plan for the next release?

The service failure is not related.

it is just simple optional macro

fine

Maybe should define a helper macro to reduce `root` related code since most of services need to configure `root`.

The docs of `fn root` is not aligned, too. But it seems the behavior is always use `"/"` as default root if possible.

> Overall, this idea looks good to me. However, placing it in `services/mod.rs` might be difficult to maintain.\r\n> \r\n> Do you think it would be better to have `s3_config.rs`?\r\n\r\nI move them to `core/services/config.rs`, not `mod.rs`.\r\n\r\nEach struct is tidy and no more extension can be added. So split to many files (`core/services/config/s3.rs` in this case) seems only extra burden without certain benefits.

cc @tisonkun, please take a look.\r\n\r\nI prefer to have them in separate files for better readability and easier future code generation.

@tisonkun @Xuanwo PTAL, thanks :)

@tisonkun I think I had addressed your comments, PTAL again, thanks :)

We may not randomly mark `fn new` as `const fn` just because it can be. This is a one-way door that revoke the `const` modifier would be a breaking change.\r\n\r\nPlease explain why those `fn` SHOULD BE constant function.

> We may not randomly mark `fn new` as `const fn` just because it can be. This is a one-way door that revoke the `const` modifier would be a breaking change.\r\n> \r\n> Please explain why those `fn` SHOULD BE constant function.\r\n\r\nBut why will change a const function to a non-const function back when there is no breaking change about this function?\r\n\r\nThere is no reason here, just to make it more general, I will close this PR

The main fix is  d4c926270944c83e78773ce121bc2aa6e1141dfc

Inviting @tisonkun to take a look.

> Thanks!\r\n\r\nThanks a lot for your quick review!

> LGTM, see also [blackbeam/mysql_async#304](https://github.com/blackbeam/mysql_async/pull/304)\r\n\r\nThanks!

I think we should avoid congestion, and some services can consider reducing the frequency of tests.\r\n\r\n```\r\nError response from daemon: Head "https://registry-1.docker.io/v2/alluxio/alluxio/manifests/2.9.3": received unexpected HTTP status: 502 Bad Gateway\r\n```

> I think we should avoid congestion, and some services can consider reducing the frequency of tests.\r\n\r\nFeel free to improve if you have a plan.

> Feel free to improve if you have a plan.\r\n\r\nOk, I will put it in my work queue.

cc @Xuanwo and @oowl , PTAL :)

Hi, @adriencaccia, OpenDAL has a benchmark suite that can run tests over different services based on the environment. Does Codspeed support our case? For example, running Cargo Codspeed multiple times can display their performance in groups based on service.

<img width="603" alt="image" src="https://github.com/user-attachments/assets/6f33b536-2258-4a2f-bfd1-7cb68ed08cfb">\r\n

> Hi, @adriencaccia, OpenDAL has a benchmark suite that can run tests over different services based on the environment. Does Codspeed support our case? For example, running Cargo Codspeed multiple times can display their performance in groups based on service.\r\n\r\nHey, at the moment there is no support for grouping benchmarks.\r\nWhat I would recommend in the meantime, if relevant, is to manually change the name of the benchmarks depending on the service.\r\nFor example, for a benchmark `myBench` in the codebase, you could make its name depending on the service, so that multiple benchmarks are tracked on CodSpeed: `service1-myBench`, `service2-myBench`, `service3-myBench`...

Hi, @adriencaccia, there are some concerns from the ASF INFRA, do you have comments?\r\n\r\n![image](https://github.com/user-attachments/assets/898198ac-88cd-4819-a096-2b2c5e3142f7)\r\n

> Hi, @adriencaccia, there are some concerns from the ASF INFRA, do you have comments?\r\n> \r\n> ![image](https://private-user-images.githubusercontent.com/5351546/362716601-898198ac-88cd-4819-a096-2b2c5e3142f7.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjQ5NDAxMzYsIm5iZiI6MTcyNDkzOTgzNiwicGF0aCI6Ii81MzUxNTQ2LzM2MjcxNjYwMS04OTgxOThhYy04OGNkLTQ4MTktYTA5Ni0yYjJjNWUzMTQyZjcucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDgyOSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA4MjlUMTM1NzE2WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MWQzMGExMTgyMDIzMWU2NzIxMjlhMWRlYjllYTBjYTFlZDljOTFlZTdkNGE0Njc1ODZkNzE2ZmZjZjdkN2M4NSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.2Iz3I___v5on43iLLezEu4mMe4u0LbwA2QI-bHYQx3g)\r\n\r\nHey, I just answered in https://github.com/apache/arrow-rs/pull/6150#issuecomment-2317740163 üòâ 

> Hey, I just answered in [apache/arrow-rs#6150 (comment)](https://github.com/apache/arrow-rs/pull/6150#issuecomment-2317740163) üòâ\r\n\r\nThanks!

Hi, @dqhl76, this action has been approved! Please give it a try.\r\n\r\nAlso FYI @adriencaccia and @alamb

It seems we are only permitted to install the Codspeed GitHub app, but the workflow is not being allowed.\r\n\r\nhttps://github.com/apache/opendal/actions/runs/11463180557\n\nI think it still needs to communicate with infra team in jira ticket.

> It seems we are only permitted to install the Codspeed GitHub app, but the workflow is not being allowed.\r\n> \r\n> [apache/opendal/actions/runs/11463180557](https://github.com/apache/opendal/actions/runs/11463180557)\r\n> \r\n> I think it still needs to communicate with infra team in jira ticket.\r\n\r\nThis is where the action can be allowed: https://docs.github.com/en/organizations/managing-organization-settings/disabling-or-limiting-github-actions-for-your-organization#allowing-select-actions-and-reusable-workflows-to-run

ping @Xuanwo @tisonkun 

@PsiACE @tisonkun @Xuanwo PTAL,thanks

> 2\\. As for `opendal-spring-starter` or `opendal-spring-data-starter`, I believe the `data` part is unnecessary. Spring Data is a sub-project of Spring, and we currently do not have that kind of relationship.\r\n\r\nHi, it looks good to me to remove `data`, but `boot` should still be kept? My current understanding is there is no `spring-starter` but `spring-boot-starter`.

Yes. Let me push a follow up and merge this.

@Xuanwo Sorry, It was a typo, `boot` is in the code indeedly.

should we add a test case which checks the root path for all services ? @Xuanwo 

> should we add a test case which checks the root path for all services ? @Xuanwo\r\n\r\nThere is no requirement for all services to support root; I believe we can add it on a case-by-case basis.

Would you like to also add `parquet_opendal` in the `For ANY integrations` section of our README?

This is the last PR I gonna to merge today. `00::39 AM` now :heart: \r\n\r\nI will review your other PR tomorrow.

No problem! Get some sleep :rocket: 

Hi @jdockerty, I believe `GCS_NO_AUTH` should be equivalent to `allow_anonymous` + `disable_vm_metadata` + `disable_config_load`.

Ah! Thank you, that is the piece I was missing üëç 

Hi, https://github.com/apache/opendal/pull/4979 has been merged, we can continue this one now.

Hi @Xuanwo and @oowl , please take a look.

Fixed cc @Xuanwo 

cc @Xuanwo , PTAL

Fixed @Xuanwo 

Perhaps you might be interested in assisting with https://github.com/apache/opendal/issues/4876 :laughing: 

Hi, I plan to include this PR in our upcoming 0.49.0 release. However, if you are currently busy, we can also postpone it to the next release. Which do you prefer?

hi, @Xuanwo I have finished the work for FS and S3, but I‚Äôm not sure if the implementation is elegant, especially for S3. Do you have any advice? If you think it‚Äôs okay, I‚Äôll continue to complete the others.

The HDFS tests seem flaky. In the latest commit, they failed, but the changes aren‚Äôt related to them.

> The HDFS tests seem flaky. In the latest commit, they failed, but the changes aren‚Äôt related to them.\r\n\r\nYes. The ASF download CDN returns 502. Please ignore it. Maybe we can try cache them if you are interested.

> > The HDFS tests seem flaky. In the latest commit, they failed, but the changes aren‚Äôt related to them.\r\n> \r\n> Yes. The ASF download CDN returns 502. Please ignore it. Maybe we can try cache them if you are interested.\r\n\r\nnot this one. https://github.com/apache/opendal/actions/runs/10486150908/job/29043772467, here only `test_list_empty_dir` failed

> not this one. [apache/opendal/actions/runs/10486150908/job/29043772467](https://github.com/apache/opendal/actions/runs/10486150908/job/29043772467), here only `test_list_empty_dir` failed\r\n\r\nNo idea so far. The test and the code seems correct.

Thank you very much for this PR. I will take a review tomorrow.

This PR looks good to me overall. We will merge it after the release of version 0.49.2.

BTW, How can I generate a `DEPENDENCIES.rust.tsv` file, Are there any available docs? üëÄ

> BTW, How can I generate a `DEPENDENCIES.rust.tsv` file, Are there any available docs? üëÄ\r\n\r\nhttps://opendal.apache.org/community/release/#generate-dependencies-list

Thanks for the quick review.

This will break our CI, need more research.

Can we use Github Secrets instead?

> Can we use Github Secrets instead?\r\n\r\nNo differences for that.\r\n\r\n---\r\n\r\nHow about use `schedule` with `cron` in `opendal-go-services` instead? We can pull opendal tags every five mintues, and build if new tags happend.

The part about releasing services has been moved to https://github.com/apache/opendal-go-services/pull/9.

Thanks for your PR! I will review it later this week.

Thanks for this change! Would you like to add `Debug` for `Configurator` to avoid this happen of other services?

sure!

Hello @Xuanwo and @oowl, PTAL.

We need to set up a new Windows action environment to run a Windows test for the new `cloudfilter` fs test. Besides, https://github.com/ho-229/cloud-filter-rs seems does not have any test. Maybe we need to complete integration or unit tests  first.

Hello @oowl, I have been add some tests for <https://github.com/ho-229/cloud-filter-rs>, and I think maybe we can add tests for `integration/cloudfilter` in next PR.

Hi @Xuanwo and @oowl , we have completed the improvements in `integrations/cloudfilter`. Should we proceed?

It seems the `cloudfilter` repo has some basic tests for reading and writing, but we all know the file system test case is so complex, That it is not enough. But can we try to merge the current PR first? what do you think? @Xuanwo 

> It seems the `cloudfilter` repo has some basic tests for reading and writing, but we all know the file system test case is so complex, That it is not enough. But can we try to merge the current PR first? what do you think? @Xuanwo \n\nMakes sense to me. We can move forward.

Hi @oowl , I think `cloudfilter` is not a filesystem, we are currently focusing on reading files from remote.

\r\n\r\n\r\n> Hi @oowl , I think `cloudfilter` is not a filesystem, we are currently focusing on reading files from remote.\r\n\r\nDo we have any limitations for CRUD action implementation?

> > Hi @oowl , I think `cloudfilter` is not a filesystem, we are currently focusing on reading files from remote.\r\n> \r\n> Do we have any limitations for CRUD action implementation?\r\n\r\nWe now support fetching data and the path tree from a remote source and making changes locally. However, these changes cannot be synced to the remote source

> > > Hi @oowl , I think `cloudfilter` is not a filesystem, we are currently focusing on reading files from remote.\r\n> > \r\n> > \r\n> > Do we have any limitations for CRUD action implementation?\r\n> \r\n> We now support fetching data and the path tree from a remote source and making changes locally. However, these changes cannot be synced to the remote source\r\n\r\nSo from our goal, we not only support fetching data and the path tree from a remote source but also need to support delete or update operations. Do I understand correctly?

> > > > Hi @oowl , I think `cloudfilter` is not a filesystem, we are currently focusing on reading files from remote.\r\n> > > \r\n> > > \r\n> > > Do we have any limitations for CRUD action implementation?\r\n> > \r\n> > \r\n> > We now support fetching data and the path tree from a remote source and making changes locally. However, these changes cannot be synced to the remote source\r\n> \r\n> So from our goal, we not only support fetching data and the path tree from a remote source but also need to support delete or update operations. Do I understand correctly?\r\n\r\nYes, but I encounter some problems to implement `dehydration` for `cloudfilter_opendal`, so I prefer to implement the readonly version first.

All failed test are not related.

All unit tests and doc tests are passed locally, I suggest we can merge this PR first.

It seems the swift tests steadily failed. I should not touch the logics around. Perhaps test set up are brittle.\r\n\r\n@Xuanwo do you know who write this service integrations?

Seems the root gets override. This is the code difference. Let me look at the test code.

Cause found. Fixed.

@Xuanwo Actually this is not a breaking change .. What parts are breaking?

> @Xuanwo Actually this is not a breaking change .. What parts are breaking?\n\nBuilder is a public trait. All users implement this API will fail to compile.\n\nAdding a new associated type and required function are breaking changes.

> Please try using go get `github.com/apache/opendal-go-services/aliyun_drive@<hash>`.\r\n\r\nFine. This works.

Thanks for the review. I will go and make the modifications mentioned.

All modifications have been completed! I feel like we can merge now. Or you can also take a look and see if there are any other issues?

Oops... I forgot to update the `Layers` chapter in the README: https://github.com/apache/opendal/blob/main/core/README.md#layers

> Oops... I forgot to update the `Layers` chapter in the README: https://github.com/apache/opendal/blob/main/core/README.md#layers\r\n\r\nWelcome to submit a new PR!

a question I need to confirm about this PR: does this `root` parameter contain the bucket in it?

> does this `root` parameter contain the bucket in it?\r\n\r\nNo. root is the base path for all opendal operations. You might want to include `name` in the metrics.

I\

Should be fixed by https://github.com/apache/opendal/pull/5662

Bindings Go CI failed because the Go version is lower than 1.22.4 (1.20).\r\n\r\nAnd considering 1.20 is out of [maintenance](https://go.dev/doc/devel/release#policy), I think it is time to update to the latest version.\r\n\r\n> Each major Go release is supported until there are two newer major releases. For example, Go 1.5 was supported until the Go 1.7 release, and Go 1.6 was supported until the Go 1.8 release. We fix critical problems, including [critical security problems](https://go.dev/security), in supported releases as needed by issuing minor revisions (for example, Go 1.6.1, Go 1.6.2, and so on).\r\n\r\nIMO we need to update the CI configuration because it is tailored for CGO.\r\n\r\nHere is an [example](https://github.com/yuchanns/opendal/blob/6a2efa5209792194f5b309df393a284f185c8b47/.github/workflows/behavior_test.yaml#L16-L27) from my POC. It is really simple and easy.

> And considering 1.20 is out of [maintenance](https://go.dev/doc/devel/release#policy), I think it is time to update to the latest version.\r\n\r\nGreat, welcome to bump the go version in a new PR.

Ok, seems the ci changes need to go along with this PR.

> seems the ci changes need to go along with this PR.\n\nYes. I closed it.

Benchmark is in absence. I should add one Later.

Hi, @Zheaoli, would you like to leave a final comment?

Hi, @NKID00, thanks for your update. This PR is mostly ready to merge, can you help resolving the conflicts?

> Hi, NKID00, thanks for your update. This PR is mostly ready to merge, can you help resolving the conflicts?\r\n\r\nSure.

One question: using `Arc<T>` will cause heap allocation, we can store the `OperatorInfo` just in the `Operator` without wrapping in `Arc<T>`, but the size of `Operator` will be huge(300B), which is better?

Replied at https://github.com/apache/opendal/issues/4845#issuecomment-2224345006

> part of: #4842\r\n> \r\n> Done:\r\n> \r\n> * [x]  Implement `user_metadata` for metadata\r\n> * [x]  Implement `user_metadata` for oss\r\n> \r\n> Todo:\r\n> \r\n> * [ ]  support blocking operator\r\n\r\nCurrently, none of the services that support blocking operations require user metadata. So, it seems there‚Äôs no need to support user metadata for the blocking operator, right?  @Xuanwo 

Great! That is much cleaner.

Hello @Xuanwo @oowl, PTAL.

Thank you for this PR. I will delay merging it for now since it introduces breaking changes. Perhaps we can also update the reqsign version at the same time.

@Xuanwo would you work on a reqsign fix? Or I may handle it.

> @Xuanwo would you work on a reqsign fix? Or I may handle it.\r\n\r\nI would appreciate it if you could submit a PR to reqsign.

Here it is - https://github.com/Xuanwo/reqsign/pull/452

Hi, I want to address https://github.com/apache/opendal/issues/4850 first before start developing of 0.48. So this PR will be hold until then.

Hi, @George-Miao, all comments have been addressed. PTAL.

Close, we will handle it by hand.

Hi, @Xuanwo. I think this PR may be too old and the updated code may introduce a lot of dead code because there is no clear goal for this PR. This may be a bit strange, so I will resubmit a PR tomorrow.

> Hi, @Xuanwo. I think this PR may be too old and the updated code may introduce a lot of dead code because there is no clear goal for this PR. This may be a bit strange, so I will resubmit a PR tomorrow.\r\n\r\nThanks and sorry for reviewing it so late.

Now the behavior tests can run on PR. I have no idea about what happens to sftp.

Seems sftp does have some issues:\r\n\r\n```shell\r\n---- behavior::test_writer_write_overwrite ----\r\ntest panicked: assertion `left == right` failed: read content_two\r\n  left: "eec0453ded52696abe7e34987d12d89daa382e5d70c0d0271c3ccfd4706e5245"\r\n right: "4e4c5edbadda8d42c622f28de6b643397820abfc37c6e35eeed67a360cb3f65e"\r\n\r\n\r\nfailures:\r\n    behavior::test_writer_write_overwrite\r\n\r\ntest result: FAILED. 84 passed; 1 failed; 0 ignored; 0 measured; 0 filtered out; finished in 21.25s\r\n```\r\n\r\nI will double check there. Feel free to dive in if you are interested too.

Wow, perfect!

@Xuanwo any else problem?

Hi, please take a look over the failed CI: https://github.com/apache/opendal/actions/runs/9682600058/job/26715994968?pr=4814

It seems we can use this API: https://cloud.google.com/storage/docs/multipart-uploads, which allows us to upload parts in parallel.\r\n\r\n> You can upload parts simultaneously, reducing the time it takes to upload the data in its entirety.\r\n

> It seems we can use this API: https://cloud.google.com/storage/docs/multipart-uploads, which allows us to upload parts in parallel.\r\n\r\nI tracked this at https://github.com/apache/opendal/issues/4807, would you like to help implementing it?

> > It seems we can use this API: https://cloud.google.com/storage/docs/multipart-uploads, which allows us to upload parts in parallel.\r\n> \r\n> I tracked this at #4807, would you like to help implementing it?\r\n\r\nYes, let me fix itü§©

> Yes, let me fix itü§©\r\n\r\nThanks a lot!

for the record, I verified this change locally on my branch\r\n\r\n<img width="912" alt="image" src="https://github.com/apache/opendal/assets/2396817/1f805302-20b8-47b2-946c-e1c5e9665bca">\r\n\r\n\r\nend to end\r\n\r\n\r\nI don\

> Thanks!\r\n\r\nthanks for the quick review! ü´°

@Xuanwo hi, have a moment to review?

Thank you for your contribution! But I think these things should be left up to the user to decide. \r\n

hi, @Xuanwo @sundy-li add `devbox`[^1] (nix wrapper) is a good idea or not?\r\n\r\nthe reason I want to add it is that my pc running node@21 and pnpm@9, and it is not convenient to meet the `CONTRIBUTING.md` required version (using pnpm@9 will change `pnpm-lock.yaml`)\r\n\r\n[^1]: https://www.jetify.com/devbox

> hi, @Xuanwo @sundy-li add `devbox`[1](#user-content-fn-1-46f06a479a435747b3ea8b7d5cf8d4ce) (nix wrapper) is a good idea or not?\r\n\r\nThis might be a good idea but how about moving them to a seperate PR?

> > hi, @Xuanwo @sundy-li add `devbox`[1](#user-content-fn-1-46f06a479a435747b3ea8b7d5cf8d4ce) (nix wrapper) is a good idea or not?\r\n> \r\n> This might be a good idea but how about moving them to a seperate PR?\r\n\r\nsure, I will remove it after fixing the CI

remove `writeWith` instead enhance original `write` methods\r\n\r\n```js\r\nawait operator.write(filename, c, {\r\n      contentType,\r\n      contentDisposition,\r\n    })\r\n// or\r\nconst writer = await operator.writer(filename, {\r\n      contentType,\r\n      contentDisposition,\r\n    })\r\n// or\r\noperator.writeSync(filename, c, {\r\n      contentType,\r\n      contentDisposition,\r\n    })\r\n// or\r\nconst writer = operator.writerSync(filename, {\r\n      contentType,\r\n      contentDisposition,\r\n    })\r\n```

hi, @suyanhanx , should I manually update the `package.json` `version`

Hello @Xuanwo, PTAL :)

Thank you for the test!

It looks good on #4767  tests. While AliyunDrive severely restricts concurrency access per account. Core-Test, Binding-Python, and Binding-Java consist of three parallel on one account leads to many retries.

May we note this in the README?

> May we note this in the README?\r\n\r\nTracked in issues.

thanks!

> * Refactor the Writer implementation to support RapidUpload fully.\r\n\r\nHow about moving this part to another PR?

> How about moving this part to another PR?\r\n\r\nMake sense.

Respect ü´° 

Sure

@Xuanwo @waynexia I wonder if we need to release a 0.47.1 for this fix.\r\n\r\n@waynexia Or we can work around this issue temporary in downstream like GreptimeDB?

It seems hard to downstream users to know the actual result, the error in body is discared before this method returns.

The naming issue of folders is fixed in this PR.\r\n\r\nHowever, the path cache issue of folder ids still exist\r\n\r\n<img width="878" alt="image" src="https://github.com/apache/opendal/assets/2396817/b88e314c-dd1c-4dc0-8764-55410e8efbb9">\r\n\r\n\r\nI think it is existing before this PR

correction: it is a regression cause by my change. investigating.

the duplication problem got fixed.\r\n\r\nI ran behavior test locally but found many other issues:\r\n\r\n```\r\n---- behavior::test_list_dir_with_recursive_no_trailing_slash ----\r\ntest panicked: assertion `left == right` failed\r\n  left: []\r\n right: ["x/", "x/x/", "x/x/x/", "x/x/x/x/", "x/x/x/y", "x/x/y", "x/y", "x/yy"]\r\n\r\n---- behavior::test_list_dir_with_recursive ----\r\ntest panicked: assertion `left == right` failed\r\n  left: ["xx/", "xy", "xyy"]\r\n right: ["x/x/", "x/x/x/", "x/x/x/x/", "x/x/x/y", "x/x/y", "x/y", "x/yy"]\r\n\r\n\r\nfailures:\r\n    behavior::test_list_dir_with_metakey_complete\r\n    behavior::test_list_dir\r\n    behavior::test_list_dir_with_metakey\r\n    behavior::test_list_dir_with_file_path\r\n    behavior::test_list_dir_with_recursive_no_trailing_slash\r\n    behavior::test_list_dir_with_recursive\r\n\r\ntest result: FAILED. 0 passed; 6 failed; 0 ignored; 0 measured; 108 filtered out; finished in 27.14s\r\n\r\n  2024-06-20T18:02:54.539017Z DEBUG rustls::common_state: Sending warning alert CloseNotify\r\n    at /Users/[user]/.cargo/registry/src/index.crates.io-6f17d22bba15001f/rustls-0.22.4/src/common_state.rs:492\r\n\r\n  2024-06-20T18:02:54.539110Z DEBUG rustls::common_state: error: test failed, to rerun pass `--test behavior`\r\n```\r\n\r\n\r\nEdit:\r\n\r\nThis seems to be a dir name issue:\r\n\r\n```\r\nrunning 114 tests\r\nquery: parent_id: root, name: tmp/\r\nquery: parent_id: 1e67zzrR4J8Obc9xlJDnN_xHr0AS_4_sN, name: opendal/\r\nquery: parent_id: 11kH-GuOrrUHiTF-12ekw29OAsTi0pkMy, name: d5aa1663-d9ec-42dd-98ba-59cf3c917312/\r\ncreate_dir: parent_id: 11kH-GuOrrUHiTF-12ekw29OAsTi0pkMy, name: d5aa1663-d9ec-42dd-98ba-59cf3c917312/\r\nquery: parent_id: 1m7aES86eZ9q7CL3xyZBnDNXtRjYLLAgG, name: 2c56f109-68b5-4ec3-87d9-6ed29384be1d/\r\ncreate_dir: parent_id: 1m7aES86eZ9q7CL3xyZBnDNXtRjYLLAgG, name: 2c56f109-68b5-4ec3-87d9-6ed29384be1d/\r\nquery: parent_id: 1m7aES86eZ9q7CL3xyZBnDNXtRjYLLAgG, name: 7a52a547-de16-4860-b54f-cc99907c24d5/\r\ncreate_dir: parent_id: 1m7aES86eZ9q7CL3xyZBnDNXtRjYLLAgG, name: 7a52a547-de16-4860-b54f-cc99907c24d5/\r\nquery: parent_id: 1m7aES86eZ9q7CL3xyZBnDNXtRjYLLAgG, name: 160400b3-6ccc-4572-8e67-9bf9227030dc\r\ntest behavior::test_copy_source_dir                                    ... ok\r\nquery: parent_id: 1m7aES86eZ9q7CL3xyZBnDNXtRjYLLAgG, name: c884f2b9-314d-4bd7-9cdf-2fe284a6667a/\r\ntest behavior::test_copy_non_existing_source                           ... ok\r\ncreate_dir: parent_id: 1m7aES86eZ9q7CL3xyZBnDNXtRjYLLAgG, name: c884f2b9-314d-4bd7-9cdf-2fe284a6667a/\r\nquery: parent_id: 1m7aES86eZ9q7CL3xyZBnDNXtRjYLLAgG, name: a8e747ff-14be-4052-9d5b-76ba687a3145\r\nquery: parent_id: 1m7aES86eZ9q7CL3xyZBnDNXtRjYLLAgG, name: üêÇüç∫‰∏≠Êñá.docx\r\nquery: parent_id: 1m7aES86eZ9q7CL3xyZBnDNXtRjYLLAgG, name: 814a03d5-02bf-4041-948f-2ffe88204d20\r\nquery: parent_id: 1m7aES86eZ9q7CL3xyZBnDNXtRjYLLAgG, name: 5fa2c785-b41d-4f17-8315-93dff9f750f0\r\nquery: parent_id: 1m7aES86eZ9q7CL3xyZBnDNXtRjYLLAgG, name: 43e5dda5-1640-4f91-ba58-6b501dc6b52c\r\nquery: parent_id: 1m7aES86eZ9q7CL3xyZBnDNXtRjYLLAgG, name: 499cb189-ba56-43cf-b8c1-6b1d99782755\r\nquery: parent_id: 1m7aES86eZ9q7CL3xyZBnDNXtRjYLLAgG, name: 19ca2904-ade5-48d3-8f30-170b82531ef8\r\ntest behavior::test_create_dir                                         ... ok\r\nquery: parent_id: 1m7aES86eZ9q7CL3xyZBnDNXtRjYLLAgG, name: 13431c5d-ef5c-40c3-b95d-a9530fcd844e/\r\ncreate_dir: parent_id: 1m7aES86eZ9q7CL3xyZBnDNXtRjYLLAgG, name: 13431c5d-ef5c-40c3-b95d-a9530fcd844e/\r\nquery: parent_id: 1m7aES86eZ9q7CL3xyZBnDNXtRjYLLAgG, name: e9458348-a5f9-45f2-9327-a4068e4458de !@#$%^&()_+-=;\

Hi @Xuanwo ,\r\nafter many hours on this PR, I found more issues on the main branch.\r\n\r\nI\

Fixed in: #5631, this PR can be closed.

Would you like to submit a PR to also update `README` and `integrations/README`? Thanks!

The docs CI for the main branch is broken.\r\nhttps://github.com/apache/opendal/actions/workflows/docs.yml?query=branch%3Amain\r\n\r\nI guess the failure of this check is unrelated to this PR.\r\nhttps://github.com/apache/opendal/actions/runs/9419578266/job/25949653713?pr=4710\r\n```\r\n---- behavior::test_rename_nested ----\r\ntest panicked: read must succeed: Unexpected (persistent) at  => reader got too little data\r\n\r\nContext:\r\n   expect: 64912\r\n   actual: 0\r\n```

Thanks for you PR, I will take a review this weekend üôè 

> Would you like to update the comments for `chunk` too\r\n\r\nFixed in https://github.com/apache/opendal/pull/4710/commits/d6a044922612f49293e9b38aa7b7ca45b43991a5

Thank you!

cc v0.47 release manager @tisonkun to take a review

A huge difference is that OpRead initiate a default range, which is previously `0..` but now `0..0`.

Drop for now.

The pr type can be "test".

cc @George-Miao, would you like to submit a PR to bump `socket2` for other bin crates?

> cc @George-Miao, would you like to submit a PR to bump `socket2` for other bin crates?\n\nSure. Will do

> Sure. Will do\r\n\r\nI have updated all `Cargo.lock`, this PR should be able to build now.

I prefer repeating in hand rather than introducing a macro. \n\nThe ideal solution will be using `Range<u64>` or `offset, size` directly in `OpRead`. But this could be another breaking change. May be we can implement this change in next release?\n\n---\n\nOr we could change BytesRange to (offset, size) directly. All usage of BytesRange must have size now.

Good to know. Let me make another PR later.

Most tests failed for:\r\n\r\n```shell\r\nError response from daemon: Head "https://quay.io/v2/ceph/demo/manifests/latest": received unexpected HTTP status: 502 Bad Gateway\r\n```\r\n\r\nNot related.

This should explain the options and GcsBackend configuration better. please review üôèüèΩ 

Have no idea why `test_file_seek` and `test_truncate` failed.\r\n\r\n<details>\r\n<summary>Error log</summary>\r\n\r\n```\r\n\r\nthread \

> Have no idea why `test_file_seek` and `test_truncate` failed.\n> \n> \n> \n> <details>\n> \n> <summary>Error log</summary>\n> \n> \n> \n> ```\n> \n> \n> \n> thread \

Thanks!

Thanks for the efforts!

aliyun drive test failed for \r\n\r\n```\r\nfailures:\r\n\r\n---- behavior::test_list_empty_dir ----\r\nUnexpected (persistent) at List::next, context: { service: aliyun_drive, path: / } => The resource file cannot be found. file not exist\r\n\r\n\r\nfailures:\r\n    behavior::test_list_empty_dir\r\n\r\ntest result: FAILED. 113 passed; 1 failed; 0 ignored; 0 measured; 0 filtered out; finished in 291.46s\r\n```

I feel like the implemention has some bug to address. For example:\r\n\r\n```\r\n---- behavior::test_list_empty_dir ----\r\nUnexpected (persistent) at List::next, context: { service: aliyun_drive, path: / } => The resource file cannot be found. file not exist\r\n```\r\n\r\nList empty dir should return `None` instead of `not found`?

> Based on my testing on my host, `RUST_TEST_THREADS=1` does not behave the same as `--test-threads=1`.\r\n\r\nBut docs said \r\n\r\n> This can also be specified with the `RUST_TEST_THREADS` environment variable.\r\n\r\nhttps://doc.rust-lang.org/rustc/tests/index.html#--test-threads-num_threads\r\n\r\n

<img width="838" alt="image" src="https://github.com/apache/opendal/assets/24221472/0ab68c70-ead2-4f54-90f7-f448b0a69085">\r\n<img width="1028" alt="image" src="https://github.com/apache/opendal/assets/24221472/793f999f-4afd-4f16-9f71-afcfd8a7d38a">\r\n<img width="1220" alt="image" src="https://github.com/apache/opendal/assets/24221472/189c6df9-2caa-45cc-9ca6-a31948ec82bf">\r\n

I rewrite the lister (without getting file details), and LGTM on green. Previously, the `test-check` would list items while other threads delete things, leading to the random 404 files not found.

Wow, so cool! Is this PR ready to go?

The structure of `ofs` are changed, I will open a new PR later.

> The structure of `ofs` are changed, I will open a new PR later.\r\n\r\nThanks a lot!

Hi, @Xuanwo, is there anything else should be added in this PR.

> is there anything else should be added in this PR.\r\n\r\nI prefer to remove code rather than add more... :smile: \r\n\r\nPlease all basic CI config like we do for `oli`: \r\nhttps://github.com/apache/opendal/blob/24ced52aa26f0cff484e1462f5d99357fdd01732/.github/workflows/ci_bin_oli.yml#L18-L51

cc: @Xuanwo  @Zheaoli 

Ok, I see.

failure seems not relevant\r\n<img width="1266" alt="image" src="https://github.com/apache/opendal/assets/37948597/0b040b2b-0bfc-44c3-9c63-c6938e46c5c8">\r\n

Close first. Will reopen a new PR once upstream released.

Thanks for proposing the RFC. This is very useful to our use case.\r\n\r\nI have two questions: \r\n1. When the task fails during execution, will the opendal retry layer (if specified) take effect?\r\n2. When the task takes too long, will the opendal timeout layer (if specified)  take effect?

cc @tisonkun, would you like to take a review of this RFC?

LGTM.

cc @Xuanwo, PTAL

@Xuanwo PTAL again, thanks

> The stubs now pass both `mypy --strict` and `stubtest` checks\r\n\r\nAre you willing to start a new PR to add those checks in our python CI?

> to reduce our release size.\r\n\r\nDo you have some concrete number on the decreasement? 

> Could you link to the PR or commit we remove wasabi service?\r\n\r\nUpdated. @tisonkun 

We should replace this by PMC reports 

> We should replace this by PMC reports\r\n\r\nI will update it today.

cc @Xuanwo, PTAL

Hi, @ho-229 would you like to add some description about this PR?

Merged into #4617 

@hezhizhen may I ask why ignore changelog from `typos` lint?

@Xuanwo \r\n\r\nI have implemented the split fn now. I would like to ask, how can I test if my code is okay? Are there any areas that need to be supplemented with unit tests?\r\n\r\nThank you for taking the time to assist me with this task.\r\n

> I have implemented the split fn now. I would like to ask, how can I test if my code is okay?\r\n\r\nWe can add test cases in the `tests` mod directly.

I can run the tests, once I figure out how to do it correctly\r\n\r\nI created the .env file and set the values for gdrive, but when I ran the test I got the "scheme is not enabled or supported" error\r\n

> I created the .env file and set the values for gdrive, but when I ran the test I got the "scheme is not enabled or supported" error\r\n\r\nHi, please try `OPENDAL_TEST=gdrive cargo test behavior --features tests,services-gdrive`

That worked. But, the tests are running on "My Drive" and not on the shared drive\r\n\r\nI did add a new variable to .env named `OPENDAL_GDRIVE_DRIVE_ID` with the id of a shared drive

Would you like to create a list of unsupported features to help us track them more effectively?

Great work! Thank you!

thank you!

Trying to use this in production but this implementation is too different from that of OneDrive and Google Drive.\r\n\r\nThe major question is that: Why this OpenDAL implement requires refresh_token and client_id?\r\n\r\nThe AliyunDrive API supports OAuth. IMHO, we can just send an access_token to the operator and let the host app handle the auth part.\r\n\r\nNot all users would have the refresh_token. By design, AliyunDrive does not generate refresh_token for non-server applications https://www.yuque.com/aliyundrive/zpfszx/eam8ls1lmawwwksv\r\n\r\nSample token redeem response:\r\n\r\n```json\r\n{\r\n  "token_type": "Bearer",\r\n  "access_token": "ey...",\r\n  "refresh_token": null,\r\n  "expires_in": 2592000\r\n}\r\n```

Effective changes all skip CI. Trust the change once.

After an offline discussion with @Xuanwo, I confirmed that we will use unaligned version number for downstream crates.

Give it a try!

Looks like object_store is up-to-date now, so this is no longer needed.

Hi, it still doesn\

@Xuanwo Plz take a review for this design.

> Thanks! I believe we can replace all current `std::result::Result` changes back to `opendal::Result` now. Would you like to create an issue for this?\r\n\r\nSure

`PutObject` is working but Multipart upload fails with `code: "InvalidRequest", message: "Checksum Type mismatch occurred, expected checksum Type: null, actual checksum Type: crc32c"`.\r\n\r\nThis has me scratching my head a bit... I tried to remove the checksum header from multipart upload requests, but then I get the error `code: "InvalidRequest", message: "Content-MD5 OR x-amz-checksum- HTTP header is required for Put Part requests with Object Lock parameters"` again. \r\n\r\nCould it be that multipartuplaod only supports the `Content-MD5` header? 

> This has me scratching my head a bit... I tried to remove the checksum header from multipart upload requests, but then I get the error `code: "InvalidRequest", message: "Content-MD5 OR x-amz-checksum- HTTP header is required for Put Part requests with Object Lock parameters"` again.\r\n\r\nWe need to specify `x-amz-checksum-algorithm` in `CreateMultipartUpload`: https://docs.aws.amazon.com/AmazonS3/latest/API/API_CreateMultipartUpload.html#API_CreateMultipartUpload_RequestSyntax

Awesome, Thank you too!

Mostly LGTM. The only thing left is runing code formatter.

> Mostly LGTM. The only thing left is runing code formatter.\r\n\r\nfixed

@Xuanwo \r\nImplemented review comments. Please check now.\r\nCould you also please help with the failure in behavior tests? Thank you!

Hi, @shbhmrzd, thank you for your contribution. This PR is quite outdated. Would you prefer to start a new one or resolve the conflicts?

> Hi, @shbhmrzd, thank you for your contribution. This PR is quite outdated. Would you prefer to start a new one or resolve the conflicts?\n\nHi, sorry this got too outdated. I will work on this to wrap it up.

But we do have other dependency on tokio::fs.

Is this still relevant? It seems no dropbox CI failures recently.

> Is this still relevant? It seems no dropbox CI failures recently.\r\n\r\ndropbox CI has been disabled.

Cool. That change makes sense.

Hi, since you are an opendal committer, would you like to submit PRs from `apache` upstream? This can allow our behavior tests that requires secrets to run (like aws, azblob and gcs).

Got this, thank you for your guidance, I will modify the api implementation and related uses in the codes later.

Oops, too many impl should also be changed. Give me a minute üòâ 

> Oops, too many impl should also be changed. Give me a minute üòâ\r\n\r\nThank you!

Most change looks good! We just need to make clippy happy.

OMG it takes me 5 times to browse the CI list to find one failing task among the 200 ü•≤

Sounds great, let me have a try üëç 

Please take another look @Xuanwo \r\n\r\nI use `cargo check --target wasm32-unknown-unknown --features send_wrapper` to verify if it works. Do you think we need to add this in CI?

> I use `cargo check --target wasm32-unknown-unknown --features send_wrapper` to verify if it works. Do you think we need to add this in CI?\r\n\r\nFeel free to do this in a new PR!

Thank you!

@sameer Hi, I have fixed CI failing issue by  https://github.com/apache/opendal/commit/f661165280b2d3b942e07415c550132a17172f9fÔºå Would you mind rebasing your PR to the new master commit?

> What is the expected behavior in general for removing `/`? i.e. for the FS service, should that delete the working dir?\r\n\r\nYep. Just like `rm -rf /`

I ran a benchmark to compare it with the previous version, and the results showed a significant improvement in write performance.\r\n<img width="1034" alt="benchmark" src="https://github.com/apache/opendal/assets/31284445/1ae42b79-3a37-48d1-a513-519079e40b84">\r\n

Thanks a lot for your work! I will merge (and adapt) this PR after refactor.

Hi @xxxuuu, I think we are ready to get this PR merged. Would you like to merge with main first?

> Hi @xxxuuu, I think we are ready to get this PR merged. Would you like to merge with main first?\r\n\r\nOf course, please

> Of course, please\r\n\r\n:laughing: , need you to click `Update branch` and fix possible CI errors if needed. Thanks in advance!

It seems that I need to modify the code again.

This is a refactor to simplify the implementation of this feature. Would you be willing to wait a couple of days?

Hi, @zjregee, sorry for the waiting. Would you like to merge with main and try again?

Updated.

@Xuanwo Can this merge now?

related https://github.com/apache/opendal/issues/4399

Seems something wrong within the github action. Please stop retry and wait for sometime.

Broken.

waiting for https://github.com/Sherlock-Holo/fuse3/pull/90\r\nIf you want to use it in macOS, Just checkout the current PR, and build and run it for fun. 

recreate https://github.com/apache/opendal/pull/5136 due to rebase hell\r\n

Thanks a lot for your work! @oowl 

MacOS build failed, I will try to push MacOS support to upstream.\r\n```\r\n‚ï∞‚îÄ$ cargo build\r\n    Updating crates.io index\r\n  Downloaded cstr v0.2.11\r\n  Downloaded http-body v1.0.0\r\n  Downloaded trait-make v0.1.0\r\n  Downloaded trim-in-place v0.1.7\r\n  Downloaded tower-layer v0.3.2\r\n  Downloaded cfg_aliases v0.1.1\r\n  Downloaded async-notify v0.3.0\r\n  Downloaded memoffset v0.9.0\r\n  Downloaded parking v2.2.0\r\n  Downloaded http-body-util v0.1.1\r\n  Downloaded which v6.0.1\r\n  Downloaded zeroize v1.7.0\r\n  Downloaded rust-ini v0.21.0\r\n  Downloaded bincode v1.3.3\r\n  Downloaded async-trait v0.1.79\r\n  Downloaded rustls-pki-types v1.4.0\r\n  Downloaded concurrent-queue v2.4.0\r\n  Downloaded errno v0.3.8\r\n  Downloaded either v1.9.0\r\n  Downloaded bitflags v2.4.2\r\n  Downloaded tokio-rustls v0.25.0\r\n  Downloaded event-listener v4.0.3\r\n  Downloaded crossbeam-utils v0.8.19\r\n  Downloaded smallvec v1.13.2\r\n  Downloaded hyper-rustls v0.26.0\r\n  Downloaded fuse3 v0.7.1\r\n  Downloaded hyper-util v0.1.3\r\n  Downloaded reqsign v0.15.0\r\n  Downloaded http v1.1.0\r\n  Downloaded base64 v0.22.0\r\n  Downloaded tower v0.4.13\r\n  Downloaded hyper v1.2.0\r\n  Downloaded reqwest v0.12.2\r\n  Downloaded rustls-webpki v0.102.2\r\n  Downloaded webpki-roots v0.26.1\r\n  Downloaded rustls v0.22.3\r\n  Downloaded rustix v0.38.31\r\n  Downloaded nix v0.28.0\r\n  Downloaded nix v0.27.1\r\n  Downloaded chrono v0.4.35\r\n  Downloaded 40 crates (3.2 MB) in 1.97s\r\n   Compiling libc v0.2.153\r\n   Compiling syn v2.0.48\r\n   Compiling rustls-pki-types v1.4.0\r\n   Compiling http v1.1.0\r\n   Compiling rustls v0.22.3\r\n   Compiling zeroize v1.7.0\r\n   Compiling smallvec v1.13.2\r\n   Compiling tower-layer v0.3.2\r\n   Compiling crossbeam-utils v0.8.19\r\n   Compiling bitflags v2.4.2\r\n   Compiling memoffset v0.9.0\r\n   Compiling rustix v0.38.31\r\n   Compiling cfg_aliases v0.1.1\r\n   Compiling async-trait v0.1.79\r\n   Compiling http-body v1.0.0\r\n   Compiling hashbrown v0.14.3\r\n   Compiling http-body-util v0.1.1\r\n   Compiling ordered-multimap v0.7.1\r\n   Compiling nix v0.28.0\r\n   Compiling webpki-roots v0.26.1\r\n   Compiling parking v2.2.0\r\n   Compiling trim-in-place v0.1.7\r\n   Compiling rust-ini v0.21.0\r\n   Compiling chrono v0.4.35\r\n   Compiling concurrent-queue v2.4.0\r\n   Compiling base64 v0.22.0\r\n   Compiling event-listener v4.0.3\r\n   Compiling tokio-macros v2.2.0\r\n   Compiling futures-macro v0.3.30\r\n   Compiling serde_derive v1.0.196\r\n   Compiling tracing-attributes v0.1.27\r\n   Compiling pin-project-internal v1.1.4\r\n   Compiling signal-hook-registry v1.4.1\r\n   Compiling getrandom v0.2.12\r\n   Compiling num_cpus v1.16.0\r\n   Compiling socket2 v0.5.5\r\n   Compiling mio v0.8.10\r\n   Compiling futures-util v0.3.30\r\n   Compiling ring v0.17.7\r\n   Compiling tokio v1.36.0\r\n   Compiling rand_core v0.6.4\r\n   Compiling cpufeatures v0.2.12\r\n   Compiling pin-project v1.1.4\r\n   Compiling rand_chacha v0.3.1\r\n   Compiling errno v0.3.8\r\n   Compiling rand v0.8.5\r\n   Compiling tracing v0.1.40\r\n   Compiling rustls-webpki v0.102.2\r\n   Compiling serde v1.0.196\r\n   Compiling sha1 v0.10.6\r\n   Compiling sha2 v0.10.8\r\n   Compiling either v1.9.0\r\n   Compiling clap_derive v4.5.0\r\n   Compiling futures v0.3.30\r\n   Compiling which v6.0.1\r\n   Compiling trait-make v0.1.0\r\n   Compiling async-notify v0.3.0\r\n   Compiling cstr v0.2.11\r\n   Compiling nix v0.27.1\r\n   Compiling clap v4.5.1\r\n   Compiling hyper v1.2.0\r\n   Compiling tower v0.4.13\r\n   Compiling tokio-rustls v0.25.0\r\n   Compiling tokio-util v0.7.10\r\n   Compiling backon v0.4.3\r\n   Compiling serde_urlencoded v0.7.1\r\n   Compiling quick-xml v0.31.0\r\n   Compiling hyper-util v0.1.3\r\n   Compiling serde_json v1.0.113\r\n   Compiling uuid v1.7.0\r\n   Compiling bincode v1.3.3\r\n   Compiling fuse3 v0.7.1\r\n   Compiling hyper-rustls v0.26.0\r\n   Compiling reqwest v0.12.2\r\n   Compiling reqsign v0.15.0\r\nerror[E0432]: unresolved import `helper::mode_from_kind_and_perm`\r\n  --> /Users/ouyangjun/.cargo/registry/src/index.crates.io-6f17d22bba15001f/fuse3-0.7.1/src/lib.rs:30:18\r\n   |\r\n30 | pub use helper::{mode_from_kind_and_perm, perm_from_mode_and_kind};\r\n   |                  ^^^^^^^^^^^^^^^^^^^^^^^\r\n   |                  |\r\n   |                  no `mode_from_kind_and_perm` in `helper`\r\n   |                  help: a similar name exists in the module: `perm_from_mode_and_kind`\r\n   |\r\nnote: found an item that was configured out\r\n  --> /Users/ouyangjun/.cargo/registry/src/index.crates.io-6f17d22bba15001f/fuse3-0.7.1/src/helper.rs:30:14\r\n   |\r\n30 | pub const fn mode_from_kind_and_perm(kind: FileType, perm: u16) -> u32 {\r\n   |              ^^^^^^^^^^^^^^^^^^^^^^^\r\n   = note: the item is gated behind the `linux` feature\r\nnote: found an item that was configured out\r\n  --> /Users/ouyangjun/.cargo/registry/src/index.crates.io-6f17d22bba15001f/fuse3-0.7.1/src/helper.rs:39:14\r\n   |\r\n39 | pub const fn mode_from_kind_and_perm(kind: FileType, perm: u16) -> u32 {\r\n   |              ^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nerror[E0432]: unresolved import `crate::helper::mode_from_kind_and_perm`\r\n  --> /Users/ouyangjun/.cargo/registry/src/index.crates.io-6f17d22bba15001f/fuse3-0.7.1/src/raw/reply.rs:9:5\r\n   |\r\n9  | use crate::helper::mode_from_kind_and_perm;\r\n   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ no `mode_from_kind_and_perm` in `helper`\r\n   |\r\nnote: found an item that was configured out\r\n  --> /Users/ouyangjun/.cargo/registry/src/index.crates.io-6f17d22bba15001f/fuse3-0.7.1/src/helper.rs:30:14\r\n   |\r\n30 | pub const fn mode_from_kind_and_perm(kind: FileType, perm: u16) -> u32 {\r\n   |              ^^^^^^^^^^^^^^^^^^^^^^^\r\n   = note: the item is gated behind the `linux` feature\r\nnote: found an item that was configured out\r\n  --> /Users/ouyangjun/.cargo/registry/src/index.crates.io-6f17d22bba15001f/fuse3-0.7.1/src/helper.rs:39:14\r\n   |\r\n39 | pub const fn mode_from_kind_and_perm(kind: FileType, perm: u16) -> u32 {\r\n   |              ^^^^^^^^^^^^^^^^^^^^^^^\r\nhelp: a similar name exists in the module\r\n   |\r\n9  | use crate::helper::perm_from_mode_and_kind;\r\n   |                    ~~~~~~~~~~~~~~~~~~~~~~~\r\nhelp: consider importing this unresolved item through its public re-export instead\r\n   |\r\n9  | use crate::mode_from_kind_and_perm;\r\n   |     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n\r\nerror[E0599]: no method named `mount_with_unprivileged` found for struct `raw::session::Session` in the current scope\r\n   --> /Users/ouyangjun/.cargo/registry/src/index.crates.io-6f17d22bba15001f/fuse3-0.7.1/src/path/session.rs:38:14\r\n    |\r\n37  | /         raw::Session::new(self.mount_options)\r\n38  | |             .mount_with_unprivileged(bridge, mount_path)\r\n    | |             -^^^^^^^^^^^^^^^^^^^^^^^ method not found in `Session<_>`\r\n    | |_____________|\r\n    |\r\n    |\r\n   ::: /Users/ouyangjun/.cargo/registry/src/index.crates.io-6f17d22bba15001f/fuse3-0.7.1/src/raw/session.rs:216:1\r\n    |\r\n216 |   pub struct Session<FS> {\r\n    |   ---------------------- method `mount_with_unprivileged` not found for this struct\r\n\r\nerror[E0599]: no method named `mount` found for struct `raw::session::Session` in the current scope\r\n   --> /Users/ouyangjun/.cargo/registry/src/index.crates.io-6f17d22bba15001f/fuse3-0.7.1/src/path/session.rs:52:14\r\n    |\r\n51  | /         raw::Session::new(self.mount_options)\r\n52  | |             .mount(bridge, mount_path)\r\n    | |             -^^^^^ method not found in `Session<_>`\r\n    | |_____________|\r\n    |\r\n    |\r\n   ::: /Users/ouyangjun/.cargo/registry/src/index.crates.io-6f17d22bba15001f/fuse3-0.7.1/src/raw/session.rs:216:1\r\n    |\r\n216 |   pub struct Session<FS> {\r\n    |   ---------------------- method `mount` not found for this struct\r\n\r\nerror[E0004]: non-exhaustive patterns: type `&ConnectionMode` is non-empty\r\n   --> /Users/ouyangjun/.cargo/registry/src/index.crates.io-6f17d22bba15001f/fuse3-0.7.1/src/raw/connection/tokio.rs:127:15\r\n    |\r\n127 |         match &self.mode {\r\n    |               ^^^^^^^^^^\r\n    |\r\nnote: `ConnectionMode` defined here\r\n   --> /Users/ouyangjun/.cargo/registry/src/index.crates.io-6f17d22bba15001f/fuse3-0.7.1/src/raw/connection/tokio.rs:164:6\r\n    |\r\n164 | enum ConnectionMode {\r\n    |      ^^^^^^^^^^^^^^\r\n    = note: the matched value is of type `&ConnectionMode`\r\n    = note: references are always considered inhabited\r\nhelp: ensure that all possible cases are being handled by adding a match arm with a wildcard pattern as shown\r\n    |\r\n127 ~         match &self.mode {\r\n128 +             _ => todo!(),\r\n129 +         }\r\n    |\r\n\r\nerror[E0004]: non-exhaustive patterns: type `&ConnectionMode` is non-empty\r\n   --> /Users/ouyangjun/.cargo/registry/src/index.crates.io-6f17d22bba15001f/fuse3-0.7.1/src/raw/connection/tokio.rs:147:15\r\n    |\r\n147 |         match &self.mode {\r\n    |               ^^^^^^^^^^\r\n    |\r\nnote: `ConnectionMode` defined here\r\n   --> /Users/ouyangjun/.cargo/registry/src/index.crates.io-6f17d22bba15001f/fuse3-0.7.1/src/raw/connection/tokio.rs:164:6\r\n    |\r\n164 | enum ConnectionMode {\r\n    |      ^^^^^^^^^^^^^^\r\n    = note: the matched value is of type `&ConnectionMode`\r\n    = note: references are always considered inhabited\r\nhelp: ensure that all possible cases are being handled by adding a match arm with a wildcard pattern as shown\r\n    |\r\n147 ~         match &self.mode {\r\n148 +             _ => todo!(),\r\n149 +         }\r\n    |\r\n\r\n   Compiling opendal v0.45.1 (/Users/ouyangjun/code/opendal/core)\r\nerror[E0425]: cannot find function `mode_from_kind_and_perm` in this scope\r\n    --> /Users/ouyangjun/.cargo/registry/src/index.crates.io-6f17d22bba15001f/fuse3-0.7.1/src/raw/session.rs:2995:29\r\n     |\r\n2995 |                     r#type: mode_from_kind_and_perm(entry.kind, 0) >> 12,\r\n     |                             ^^^^^^^^^^^^^^^^^^^^^^^ help: a function with a similar name exists: `perm_from_mode_and_kind`\r\n     |\r\n    ::: /Users/ouyangjun/.cargo/registry/src/index.crates.io-6f17d22bba15001f/fuse3-0.7.1/src/helper.rs:45:1\r\n     |\r\n45   | pub const fn perm_from_mode_and_kind(kind: FileType, mode: mode_t) -> u16 {\r\n     | ------------------------------------------------------------------------- similarly named function `perm_from_mode_and_kind` defined here\r\n\r\nerror[E0425]: cannot find function `mode_from_kind_and_perm` in this scope\r\n    --> /Users/ouyangjun/.cargo/registry/src/index.crates.io-6f17d22bba15001f/fuse3-0.7.1/src/raw/session.rs:3912:33\r\n     |\r\n3912 |                         r#type: mode_from_kind_and_perm(entry.kind, 0) >> 12,\r\n     |                                 ^^^^^^^^^^^^^^^^^^^^^^^ help: a function with a similar name exists: `perm_from_mode_and_kind`\r\n     |\r\n    ::: /Users/ouyangjun/.cargo/registry/src/index.crates.io-6f17d22bba15001f/fuse3-0.7.1/src/helper.rs:45:1\r\n     |\r\n45   | pub const fn perm_from_mode_and_kind(kind: FileType, mode: mode_t) -> u16 {\r\n     | ------------------------------------------------------------------------- similarly named function `perm_from_mode_and_kind` defined here\r\n\r\nerror[E0063]: missing fields `crtime` and `flags` in initializer of `raw::reply::FileAttr`\r\n  --> /Users/ouyangjun/.cargo/registry/src/index.crates.io-6f17d22bba15001f/fuse3-0.7.1/src/path/reply.rs:52:9\r\n   |\r\n52 |         crate::raw::reply::FileAttr {\r\n   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^ missing `crtime` and `flags`\r\n\r\nerror[E0308]: mismatched types\r\n  --> /Users/ouyangjun/.cargo/registry/src/index.crates.io-6f17d22bba15001f/fuse3-0.7.1/src/raw/connection/tokio.rs:71:48\r\n   |\r\n71 |     pub fn new(unmount_notify: Arc<Notify>) -> io::Result<Self> {\r\n   |            ---                                 ^^^^^^^^^^^^^^^^ expected `Result<FuseConnection, Error>`, found `()`\r\n   |            |\r\n   |            implicitly returns `()` as its body has no tail or `return` expression\r\n   |\r\n   = note:   expected enum `std::result::Result<FuseConnection, std::io::Error>`\r\n           found unit type `()`\r\n\r\nerror[E0063]: missing fields `crtime`, `crtimensec` and `flags` in initializer of `fuse_attr`\r\n  --> /Users/ouyangjun/.cargo/registry/src/index.crates.io-6f17d22bba15001f/fuse3-0.7.1/src/raw/reply.rs:56:9\r\n   |\r\n56 |         fuse_attr {\r\n   |         ^^^^^^^^^ missing `crtime`, `crtimensec` and `flags`\r\n\r\nSome errors have detailed explanations: E0004, E0063, E0308, E0425, E0432, E0599.\r\nFor more information about an error, try `rustc --explain E0004`.\r\nerror: could not compile `fuse3` (lib) due to 11 previous errors\r\n```

@Xuanwo Let‚Äôs merge it first? We need to wait some times to PR nix and fuse3 repo support Apple target.

I have run all tests by `pjdfstest`, There was a whole bunch of output logs and can not ignore some case tests for particular tests. Maybe we need to reconsider another test case. \r\n\r\n

Also invite @Sherlock-Holo to join the discussion.

Closing!

> Closing!\r\n\r\nThanks a lot for your work!

This partially addresses #4384. It assumes that _all_ readable services support seeking, which may not be valid, but it mirrors the implementation `seek`.

> It assumes that _all_ readable services support seeking\r\n\r\nCan you use https://docs.rs/opendal/latest/opendal/struct.Capability.html#structfield.read_can_seek?

This is an ongoing RFC related to this: https://github.com/apache/opendal/pull/4382

> Or is it just a blocker for this PR?\r\n\r\nAfter this RFC been implemented (which is already going on), we might need to change the way of implement `File` in python.

Hi, @mobiusklein, sorry for the long waiting. I feel like this PR is good to go. Would you like to fix the CI issues so we can get it merged?

> Is it correct to say that `seek` operations are now supported universally since the behavior is no longer described by the `Capability` type?\r\n\r\nYes!

Things appear to be all set now. Thank you.

Can we add the vectored methods like futures api? This will allow also enabling that capability, or do you want to take it as separate trait to implement like `ReadVectored`?

@Xuanwo think of it a typed Python script. Better than untyped toml strings..\r\n\r\nBut maybe I can port all these things into Python with Jinja template or sth.\r\n\r\nJust no untyped toml, we can write the schema in code.\r\n\r\nNewer Python can be typed also.

@Xuanwo finished to Python.

Follow up -\r\n\r\n* Tracking issues to convert other configs in this pattern.\r\n* Work on generate code for Java / Python / ...\r\n\r\ncc @Xuanwo @PsiACE 

Thanks!

cc @Xuanwo , can you rerun the workflows?

Sure, thank you for your contributions to open source 

Most LGTM! I will merge this PR after CI fixed: https://github.com/apache/opendal/pull/4369

> nits: we need update the docs here\r\n\r\nThanks for the notice. Will do.

Ooops, please running `npx license-checker --production --excludePrivatePackages --csv > DEPENDENCIES.node.csv` to update the dep list of our website.

done

Thank you!

Thank you!

Thanks!

Please solve the CI problem (`cargo fmt`) and expose config in `core/src/services/mod.rs` (you can take [this](https://github.com/apache/opendal/pull/4129/files#diff-fc66fc8ad9931e54e355edb5ea24f4cbfbfcaafc856ae66b0ce6d5029608532bR294-R295) as an example)\r\n

You can directly run cargo fmt under the core directory to format all files under it.\r\n\r\nBesides, you need to make clippy happy by fixing the warning emitted by `cargo clippy` üòÄ 

@Ji-Xinyou Done. All checks have passed. I was new to Rust so it took some time for me to understand cargo tool functionalities\r\n

I will add upgrade entries only the refactor is done.

Amazing!

Got this, I had a misunderstanding here before.

Visit https://opendal.apache.org/docs/object-store-opendal/object-store-opendal is not found, would you like to take a look? Thanks.

`object_store_opendal` document has been uploaded in https://opendal.apache.org/docs/object-store-opendal/object_store_opendal/ but does not point to it correctly.

Oops failed again üòÑ

> Oops failed again üòÑ\r\n\r\nOnly one!

Is the r2 failure a flaky test?\r\n\r\n<img width="899" alt="image" src="https://github.com/apache/opendal/assets/37948597/6fa303c8-50b2-4458-9acb-5622c177b5de">\r\n

> Is the r2 failure a flaky test?\r\n> \r\n> <img alt="image" width="899" src="https://private-user-images.githubusercontent.com/37948597/310035155-6fa303c8-50b2-4458-9acb-5622c177b5de.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MDk2MjcwMjQsIm5iZiI6MTcwOTYyNjcyNCwicGF0aCI6Ii8zNzk0ODU5Ny8zMTAwMzUxNTUtNmZhMzAzYzgtNTBiMi00NDU4LTlhY2ItNTYyMmMxNzdiNWRlLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDAzMDUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwMzA1VDA4MTg0NFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPThjNDA5OTNhNmU5Y2Y1OGUwYTU0ZDA3ODFmYmVhNTdjZmJiMjgyZDM2ZDg1NGVkZjZhNzQ0YjFkM2I3ZDQ0NmYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.E5V5UEjrA9yJwBl_9S9bJrCqkyQrORn_YH2iPQc-Ncs">\r\n\r\nYep, please ignore it.

I added `DropboxDeleteBatchFailureResponse` to parse errors during batch deletion.\r\n\r\nWhen dropbox returns the following error.\r\n```json\r\n{\r\n    ".tag": "failure",\r\n    "failure": {\r\n        ".tag": "path_lookup",\r\n        "path_lookup": {\r\n            ".tag": "not_found",\r\n        }\r\n    }\r\n}\r\n```\r\nOpenDAL will return such an error message.\r\n```txt\r\nError: Unexpected (permanent) at delete, context: { service: dropbox, path:  } => delete failed with error path_lookup not_found\r\n```

> OpenDAL will return such an error message.\r\n\r\nThank you for looking into this. This is precisely the situation I wanted to address: we can ignore the "not_found" error when deleting.

Other problems fixed. The only remaining issue is how to enable features for C bindings ü§î\r\n\r\nBTW, does the released bindings contain all features?

> The only remaining issue is how to enable features for C bindings ü§î\r\n\r\nMost of C binding users will write their own `Makefile`. We can define some envs and read them in `build.rs`, but it may need another PR to implement. Do you have interest?

main CI failed. Let me fix it

> main CI failed. Let me fix it\r\n\r\nThanks a lot!

Oh, but memory service has very few code. Sounds better then.

There is a json deserialization error for ListOpResponse, I will try to fix it later.

wait for hyper 1.0

@Xuanwo When disable create_dir, op.create_dir("test/") will report this error\r\n```json\r\n{"message":"path cannot end with a slash","errors":[{"resource":"Commit","field":"path","code":"invalid"}],"documentation_url":"https://docs.github.com/rest/repos/contents#create-or-update-file-contents"}\r\n```

> When disable create_dir, op.create_dir("test/") will report this error\r\n\r\nSad, let\

> .gitkeep\r\n\r\nShould we remove .gitkeep from the list returnÔºü

> Should we remove .gitkeep from the list returnÔºü\r\n\r\nYes, we can ignore `.gitkeep` (not `remove`)

thanks!

Wait for main branch CI to pass.

It looks like running jfrog directly might fail on some tests, I will attempt to reconfigure jfrog later.

> It looks like running jfrog directly might fail on some tests, I will attempt to reconfigure jfrog later.\n\nIt could also be problems of opendal itself.

For example, jfrog returns `200` for rename success:\r\n\r\n```shell\r\nUnexpected (persistent) at rename, context: { uri: http://127.0.0.1:8081/artifactory/example-repo-local/4b4169a6-08ff-40e1-907b-f07deccd5e67/b95cf5c9-e399-40a4-af59-20760ece910d, response: Parts { status: 200, version: HTTP/1.1, headers: {"x-jfrog-version": "Artifactory/7.77.5 77705900", "x-artifactory-id": "e44bf43451c1c186:-1fcda5a9:18de38a6cca:-8000", "x-artifactory-node-id": "062242c5aed1", "transfer-encoding": "chunked", "date": "Mon, 26 Feb 2024 03:53:58 GMT"} }, service: webdav, from: b95cf5c9-e399-40a4-af59-20760ece910d, to: e265191f-bca1-412e-9874-b824789e035a/8b0aa2ba-1d41-4782-9584-8eb83c286629/c819085a-672e-45ff-b426-67d77bd45627 }\r\n```\r\n\r\nWe should allow it.

Ok, I found something really interesting...\r\n\r\nIn XML, content such as `&xxxx;` is considered escaped content and is treated specially. For example, `&` becomes `&amp;` and `"` becomes `&quot;`. The library `quick-xml` converts these escaped characters back into their original form during deserialization.\r\n\r\nHowever, we encountered a test case containing the sequence `&()_+-=;`, which quick-xml fails to recognize.

> Ok, I found something really interesting...\r\n\r\nI created an issue at upstream https://github.com/tafia/quick-xml/issues/719, we can workaround it first.

Thanks a lot for your help, it looks like things are working out!

Wait for secret.

Thanks!

Depends on https://github.com/apache/opendal/pull/4261

Why do we remove these suffixes? it seems the last PR has added these suffixes.  https://github.com/apache/opendal/pull/4246

I remember we have a consensus to add this suffix; when we decided to remove it?

> I remember we have a consensus to add this suffix; when we decided to remove it?\r\n\r\nThose suffix never exists in the releases (just in `Cargo.toml`). We can remove them now.

I mean: we decide to add them, and when we dedide to revert the previous decision?

Would you like to add a test for memcached with password? And do we need sasl at client side?

> Would you like to add a test for memcached with password? And do we need sasl at client side?\r\n\r\nYes, I will add it in another pr, we do not need sasl at client side.

To review the most important things of this PR, please using:\r\n\r\n```shell\r\ngit di main **/Cargo.toml **/package.json **/pom.xml\r\n```\r\n\r\nThis is the first time for us to try our new release pipeline, we will develop more tools to make it easier.

thanks

thanks!

Sharp eyes!

Looks like object_store is up-to-date now, so this is no longer needed.

Hi @Xuanwo thanks for review. I have updated the CI and tested it on my local enviroment. it seems that the set up process works as expected. But it is strange that the GitHub Action did not run this CI. Not sure what the reason is.

Aftering running the last command in CI, the system does not return a result for a very long period of time. I am wondering is there anything wrong in the CI workflow file?

> Aftering running the last command in CI, the system does not return a result for a very long period of time. I am wondering is there anything wrong in the CI workflow file?\r\n\r\nLet me check it out.

Hi, @ZhengLin-Li, thanks a lot for your work, I learnt a lot from this PR! Now I managed to setup the ceph rados services via `ceph/demo`.

ThanksÔºÅ

Hi, @ArmandoZ, thanks for your efforts! Would you like to split them into two PRs for eaiser review and testing?

PR for hdfs test case over minio s3 is ready to review with test passed: #4184 \r\n\r\nFor azurite environment looks like [`hadoop-azure`](https://github.com/apache/hadoop/tree/12498b35bbb754225b0b2ca90d5ad4f5cf628d56/hadoop-tools/hadoop-azure) may not be able to support custom domains (other than *.blob.core.windows.net). Still looking into it

The remaining PR for azurite is also ready - #4185 . Seems to me this PR can be closed if no longer needed

Current behavior of AWS_ROLE_ARN envar for AWS CLI does currently only support WebIdentityToken roles (https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-envvars.html skip to AWS_ROLE_ARN)\r\n\r\nHowever role_arn from a config file does support normal assumable roles, so if we want to mimic AWS CLI behavior, it needs to be different between env and config loading.

But `source_credential` is already supported by reqsign?

Maybe we could handle like this:\r\nhttps://github.com/boto/botocore/blob/7fd4057baac5298fbf594980f618a57dd51b71ad/botocore/credentials.py#L1485

@Xuanwo is this one supported in reqsign and opendal upgrade to that version?

> @Xuanwo is this one supported in reqsign and opendal upgrade to that version?\n\nNot supported yet in reqsign. But anyway, it should be fixed in reqsign.

Please fix the CI.

Seems that the failed CI is not related to this PR, once `seafile`, and this time `webdav`, may be network issue?

> Seems that the failed CI is not related to this PR, once `seafile`, and this time `webdav`, may be network issue?\n\nYep. I think they are unrelated too. I will review this PR tomorrow.

Hi, @ho-229, would you like to share your plan about this PR? The size seems keep growing which makes it much harder for review.

Remove `frontend` folder and cleanup code

Does `jfrog-artifactory-oss` also provides webdav features? Maybe we can setup a new service to test webdav.

@Xuanwo, there is no info about this [here](https://jfrog.com/help/r/jfrog-artifactory-documentation/using-webdav).\r\n\r\nAs I can see, they wrote if feature is available in the JFrog Artifactory Pro and higher, as it was written for S3 backend [here](https://jfrog.com/help/r/jfrog-installation-setup-documentation/s3-object-storage).

Thanks!

Workflow: https://github.com/apache/opendal/actions/runs/7811201570/job/21305944190?pr=4167\r\n\r\n```shell\r\n2024-02-07 07:15:21,938 ERROR conf.Configuration: error parsing conf core-site.xml\r\ncom.ctc.wstx.exc.WstxParsingException: Illegal processing instruction target ("xml"); xml (case insensitive) is reserved by the specs.\r\n at [row,col,system-id]: [21,5,"file:/home/runner/hadoop-3.3.5/etc/hadoop/core-site.xml"]\r\n\tat com.ctc.wstx.sr.StreamScanner.constructWfcException(StreamScanner.java:634)\r\n\tat com.ctc.wstx.sr.StreamScanner.throwParseError(StreamScanner.java:504)\r\n\tat com.ctc.wstx.sr.BasicStreamReader.readPIPrimary(BasicStreamReader.java:4004)\r\n\tat com.ctc.wstx.sr.BasicStreamReader.nextFromProlog(BasicStreamReader.java:2138)\r\n\tat com.ctc.wstx.sr.BasicStreamReader.next(BasicStreamReader.java:1179)\r\n\tat org.apache.hadoop.conf.Configuration$Parser.parseNext(Configuration.java:3405)\r\n\tat org.apache.hadoop.conf.Configuration$Parser.parse(Configuration.java:3191)\r\n\tat org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:3084)\r\n\tat org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:3045)\r\n\tat org.apache.hadoop.conf.Configuration.loadProps(Configuration.java:2923)\r\n\tat org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2905)\r\n\tat org.apache.hadoop.conf.Configuration.get(Configuration.java:1247)\r\n\tat org.apache.hadoop.conf.Configuration.getTrimmed(Configuration.java:1301)\r\n\tat org.apache.hadoop.conf.Configuration.getInt(Configuration.java:1527)\r\n\tat org.apache.hadoop.fs.FileSystem$Cache.<init>(FileSystem.java:3615)\r\n\tat org.apache.hadoop.fs.FileSystem.<clinit>(FileSystem.java:206)\r\ncould not find method getRootCauseMessage from class (null) with signature (Ljava/lang/Throwable;)Ljava/lang/String;\r\ncould not find method getStackTrace from class (null) with signature (Ljava/lang/Throwable;)Ljava/lang/String;\r\n```

Test failed for:\r\n\r\n```shell\r\nhdfsBuilderConnect(forceNewInstance=0, nn=gs://***, port=0, kerbTicketCachePath=(NULL), userName=(NULL)) error:\r\nUnsupportedFileSystemException: No FileSystem for scheme "gs"org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme "gs"\r\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3546)\r\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3569)\r\n\tat org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\r\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3673)\r\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3624)\r\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:557)\r\n\tat org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:278)\r\n\tat org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:275)\r\n\tat java.base/java.security.AccessController.doPrivileged(Native Method)\r\n\tat java.base/javax.security.auth.Subject.doAs(Subject.java:423)\r\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)\r\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:275)\r\n```

Test passed! Thanks a lot for your work!\r\n\r\n![image](https://github.com/apache/opendal/assets/5351546/08a78b3f-aab8-4a7e-a3ed-9e60b460f332)\r\n

Sounds great! Thanks for the support!

> I understand, is there anything wrong with the test I added? Never written this before.\r\n\r\nWe can add\r\n\r\n```yaml\r\nenv:\r\n  RUST_BACKTRACE: 1\r\n```\r\n\r\nbefore `jobs` so we can have backtrace while error triggered.\r\n\r\nAnd our tests failed for close succeed without error which is not expected.

Hi, @hoslo, I reported the issue to tokio instead: https://github.com/tokio-rs/tokio/issues/6325

Hi, @hoslo, could you fixing the HDFS issue first? We have a user facing the exact same problem.\r\n\r\nWe can fix the fs part later.

> Hi, @hoslo, could you fixing the HDFS issue first? We have a user facing the exact same problem.\r\n> \r\n> We can fix the fs part later.\r\n\r\nI created a new PR for hdfs close, plz check it.

Closed as stale, conflict and superseded.\r\n\r\nIf the fs case is yet to be resolved, we should open a new PR instead.

```\r\n[INFO] Running org.apache.opendal.test.behavior.AsyncRenameTest\r\ncould not find method getRootCauseMessage from class org/apache/commons/lang3/exception/ExceptionUtils with signature (Ljava/lang/Throwable;)Ljava/lang/String;\r\nAborted (core dumped)\r\n```\r\n\r\nThis is the root cause. Let me take a closer look.

I read the docs of the service and it writes:\r\n\r\n----\r\n\r\nThe path of `libjvm.so` could be different, please keep an eye on it.\r\n\r\n- If meeting errors like the following:\r\n\r\n```shell\r\n(unable to get stack trace for java.lang.NoClassDefFoundError exception: ExceptionUtils::getStackTrace error.)\r\n```\r\n\r\n`CLASSPATH` is not set correctly or your hadoop installation is incorrect.\r\n\r\nTo set `CLASSPATH`:\r\n```shell\r\nexport CLASSPATH=$(find $HADOOP_HOME -iname "*.jar" | xargs echo | tr \

IIRC we don\

> IIRC we don\

It seems like CI fail in main. I will re-open this PR after the CI passes.

> Do we treat it as the default behavior? Or do we need to add a flag to indicate the use of simulation?\r\n\r\nWe mark this different via [full_capability](https://opendal.apache.org/docs/rust/opendal/struct.OperatorInfo.html#method.full_capability) and [native_capability](https://opendal.apache.org/docs/rust/opendal/struct.OperatorInfo.html#method.native_capability)

Python CI not running for:\r\n\r\n![image](https://github.com/apache/opendal/assets/5351546/72cbaff7-38e6-4f4d-a829-698d702d56df)\r\n

now it break the ci, which means works :)\r\n\r\n```\r\nbenchmark/async_origin_s3_benchmark_with_gevent.py:22:1: E402 Module level import not at top of file\r\nbenchmark/async_origin_s3_benchmark_with_gevent.py:26:1: E402 Module level import not at top of file\r\nbenchmark/async_origin_s3_benchmark_with_gevent.py:28:1: E402 Module level import not at top of file\r\nbenchmark/async_origin_s3_benchmark_with_gevent.py:29:1: E402 Module level import not at top of file\r\nbenchmark/async_origin_s3_benchmark_with_gevent.py:30:1: E402 Module level import not at top of file\r\nbenchmark/async_origin_s3_benchmark_with_gevent.py:31:1: E402 Module level import not at top of file\r\npython/opendal/__init__.py:18:1: F403 `from ._opendal import *` used; unable to detect undefined names\r\npython/opendal/__init__.py:20:11: F405 `_opendal` may be undefined, or defined from star imports\r\npython/opendal/__init__.py:21:11: F405 `_opendal` may be undefined, or defined from star imports\r\n```\r\n\r\nI guess we could ignore these first.\r\n

Thanks for your effort! Now our ruff check is running.\r\n\r\nLint like the following could be ignored:\r\n\r\n```shell\r\npython/opendal/__init__.py:18:1: F403 `from ._opendal import *` used; unable to detect undefined names\r\npython/opendal/__init__.py:20:11: F405 `_opendal` may be undefined, or defined from star imports\r\npython/opendal/__init__.py:21:11: F405 `_opendal` may be undefined, or defined from star imports\r\n```\r\n\r\n`_opendal` is from our rust binding that not in current context.\r\n\r\nAnd the error like\r\n\r\n```\r\nbenchmark/async_origin_s3_benchmark_with_gevent.py:31:1: E402 Module level import not at top of file\r\n```\r\n\r\nCould be fixed easily.\r\n

there are some more lint rules\r\n\r\n- isort https://github.com/astral-sh/ruff/issues/465#issuecomment-1783684428\r\n- format (still under discussion, so leave it be there) https://github.com/astral-sh/ruff/issues/8232\r\n\r\ncould be done in further pr, leave a note here.\r\n

cc @tisonkun TPAL.

I found a new issue that some meta files may not be respected:\r\n\r\n* rust-toolchain.toml\r\n* rustfmt.toml\r\n* deny.toml\r\n\r\n... when run `cargo xxx` for a specific package now; due to the change of folder structure?

clippy is the rust lint that help us write better code, for example:\r\n\r\n```shell\r\nerror: you seem to be trying to use `match` for destructuring a single pattern. Consider using `if let`\r\n   --> bindings/python/src/file.rs:399:13\r\n    |\r\n399 | /             match &mut *state {\r\n400 | |                 AsyncFileState::Writer(w) => {\r\n401 | |                     w.close()\r\n402 | |                         .await\r\n...   |\r\n405 | |                 _ => {}\r\n406 | |             }\r\n    | |_____________^\r\n    |\r\n    = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#single_match\r\nhelp: try\r\n    |\r\n399 ~             if let AsyncFileState::Writer(w) = &mut *state {\r\n400 +                 w.close()\r\n401 +                     .await\r\n402 +                     .map_err(|err| PyIOError::new_err(err.to_string()))?;\r\n403 +             }\r\n```

download-artifact has known issues: https://github.com/actions/download-artifact/issues/276\r\n\r\nclosing..

@Xuanwo Em, sorry but these PRs have been merged now. So can you rebase #4134 to master?

@Xuanwo blob fails to pass the test of test_write_with_special_chars, after debugging, i feel that it is a vercel error. Maybe you can help me check it

> @Xuanwo blob fails to pass the test of test_write_with_special_chars, after debugging, i feel that it is a vercel error. Maybe you can help me check it\r\n\r\nThis test is not mentioned in the documentation. Perhaps we can simply ignore it for the Vercel blob.

Sorry for the mistake operation

Why does seafile container not start?

Seems seafile pushed a new tag serval hours ago:\r\n\r\n![image](https://github.com/apache/opendal/assets/5351546/66ab8f71-fa26-4781-8d4b-29a00a2f41eb)\r\n\r\n\r\nMaybe we can change the tag in docker-compose file to use the old one until they addressed. Would you like to submit a new PR for this?\r\n\r\nref: https://hub.docker.com/r/seafileltd/seafile-mc/tags

Fixed in https://github.com/apache/opendal/pull/4107, please try again after merge with `main`.

> LGTM. I guess some formatters/linters complain that is trivial to fix.\r\n\r\nI hope we can stabilize `format_code_in_doc_comments` soon: https://github.com/rust-lang/rustfmt/issues/3348

@Xuanwo we can somehow use `cargo +nightly fmt --check` for checking.

Since this PR is merge to main, do I need to update branch bump_0.45.0 into main?

> Since this PR is merge to main, do I need to update branch bump_0.45.0 into main?\r\n\r\nYep, we need to update it.

Wait for chainsafe secret.

Credentials have been set up.

Sorry for my misoperationüò•

Hi, @morristai, please only push tags from the `main` branch after the PR has been merged.

> Hi, @morristai, please only push tags from the `main` branch after the PR has been merged.\r\n\r\nSorry, my mistake. Can it be reverted?

> Sorry, my mistake. Can it be reverted?\r\n\r\nNo, we cannot remove a tag that has already been pushed. Fortunately, our build for rc1 failed, so we now need to push an rc.2 tag which will not impact our subsequent steps.

Hi, there are many changes after this PR created. Would you like to re-generate the changelog? Thanks! 

> Hi, there are many changes after this PR created. Would you like to re-generate the changelog? Thanks!\r\n\r\nShould we create a version branch to lock on the feature and bugfix we need

> Should we create a version branch to lock on the feature and bugfix we need\r\n\r\nToo complex for our project, not interested.

Should we also update the Haskell binding version in `Cargo.toml`? (It seems so, but the guide only mentions updating the version and the tag field of the source-repository in `bindings/haskell/opendal.cabal`.)

@Xuanwo  Now I can push `v0.45.0-rc.2` tag, right?

> @Xuanwo  Now I can push `v0.45.0-rc.2` tag, right?\n\nYes! Please push a tag on main branch ü•∞

> After this PR is merged, release OCaml binding requires the following steps:\n\nHow about starting another issue to discuss the ocaml release process? We need to find way to make it integrate well with our ASF release.

Dotnet also needs to be updated?

> Dotnet also needs to be updated?\r\n\r\nNo CI breakage found yet. Seems not setup.

Thanks a lot for the change and the try to package oli on nixos. Would you like run cargo check under those packages to make sure cargo.lock generated?

Or do you want me to help do this?

@Xuanwo done, completely forgot, thank you for reminding me.\r\nThank you for the quick review! Let me know if anything!

@Xuanwo thanks a lot for the prompt review and for the help!

We have a discussion thread at https://discord.com/channels/1081052318650339399/1200638279939260436

Closed as stale and inactive. Any future effort would require a significant rewrite of this patch.

waiting for https://github.com/apache/opendal/pull/4070

https://github.com/apache/opendal/pull/4070 has been merged, please try again.

Please avoid request a large range of reviewers which cause noise.\r\n\r\nIIRC we have a script to randomly pick up reviewers from volunteers already.

> Please avoid request a large range of reviewers which cause noise.\r\n> \r\n> IIRC we have a script to randomly pick up reviewers from volunteers already.\r\n\r\nCode owners are requested for review automatically. Also we have two random reviewer for each PR

> I believe they are bugs to fix instead of throttle.\r\n\r\nThe throttle may come from the pcloud, not ours. Need to dive into the action failure

> The throttle may come from the pcloud, not ours. Need to dive into the action failure\r\n\r\nCould you share the clues that led you to believe it\

And is it a good idea for us to use `file_read` and `file_pread` instead? \r\n\r\nref: https://docs.pcloud.com/methods/fileops/index.html

> And is it a good idea for us to use `file_read` and `file_pread` instead?\r\n> \r\n> ref: https://docs.pcloud.com/methods/fileops/index.html\r\n\r\nThe implementation of upload and download is based on the official javascript sdk \r\nhttps://github.com/pCloud/pcloud-sdk-js

I will take a look into this today.

Hi @hoslo, congratulations on becoming a committer! You can now submit PRs by creating a branch directly in the apache/opendal repository, which will allow all CI checks to run automatically.

We need to make blocking layer under a feature gate instead. This is a breaking change.

@Xuanwo I have an alternative idea.\r\n\r\nI\

> so we may still depends on tokio runtime for running a compatible blocking layer.\r\n\r\nThis is the case. Switching to a feature flag solution.

@Xuanwo @PsiACE seems ready for review now.

What do you mean by `content size` mentioned here? And which `blocking API` are you referring to?

Sorry for the missing and thanks!

Just a small suggestion: perhaps we should add an SOP checklist when a new committer comes on board? I noticed that I am also missing from this doc; not sure if I am the only one.

> Just a small suggestion: perhaps we should add an SOP checklist when a new committer comes on board? I noticed that I am also missing from this doc; not sure if I am the only one.\r\n\r\nSorry for that. This list is copied from our old status without update. Would you like to help fix that?\r\n\r\nAlso we have an onboarding guide for committer: https://opendal.apache.org/community/committers/onboarding, maybe we can also add this task into it.

@hoslo \r\nI found that the copy function may have problems when executing the copy tests in multiple threads.\r\nThe other tests are fine. Only the copy tests only pass when test_threads is 1.\r\n\r\nCould you help me to take a look?

> test_threads\r\n\r\n\r\n\r\n> @hoslo I found that the copy function may have problems when executing the copy tests in multiple threads. The other tests are fine. Only the copy tests only pass when test_threads is 1.\r\n> \r\n> Could you help me to take a look?\r\n\r\nWhen test_threads is not 1, it is possible to create an existing dir, in which case koofr will return 400, which we should consider a success.

Oh, `fixes #xxx` will close a pr directly...

> Oh, `fixes #xxx` will close a pr directly...\r\n\r\nYes, I should just paste it.

Simple is fine, simple is good.

Now the ofs command running information as below\r\n```\r\n‚ï∞‚îÄ$ ./target/debug/ofs --help\r\nOpenDAL File System\r\n\r\nUsage: ofs --mount-path <MOUNT_PATH> --backend <BACKEND>\r\n\r\nOptions:\r\n  -m, --mount-path <MOUNT_PATH>  fuse mount path [env: OFS_MOUNT_PATH=]\r\n  -b, --backend <BACKEND>        location of opendal service format: <scheme>://<host>:<port> example: s3://127.0.0.1:9000?access_key=xxx&secret_key=xxx [env: OFS_BACKEND=]\r\n  -h, --help                     Print help\r\n  -V, --version                  Print version\r\n‚ï≠‚îÄouyang@owl-home ~/code/opendal ‚Äπfeat/fuse‚óè‚Ä∫ \r\n‚ï∞‚îÄ$ RUST_LOG=debug ./target/debug/ofs -b "fs://?root=/tmp" -m ./example  \r\n[2024-01-20T12:22:45Z DEBUG opendal::services::fs::backend] backend build started: FsBuilder { root: Some("/tmp"), atomic_write_dir: None }\r\n[2024-01-20T12:22:45Z DEBUG opendal::services::fs::backend] backend use root /tmp\r\n[2024-01-20T12:22:45Z DEBUG opendal::services::fs::backend] backend build finished: FsBuilder { root: None, atomic_write_dir: None }\r\n[2024-01-20T12:22:48Z DEBUG ofs] getattr(path=Some("/"))\r\n[2024-01-20T12:22:48Z DEBUG ofs] getattr(path=Some("/"))\r\n[2024-01-20T12:22:53Z DEBUG ofs] getattr(path=Some("/"))\r\n[2024-01-20T12:22:53Z DEBUG ofs] getattr(path=Some("/"))\r\n[2024-01-20T12:22:53Z DEBUG ofs] getattr(path=Some("/"))\r\n[2024-01-20T12:22:53Z DEBUG ofs] getattr(path=Some("/"))\r\n[2024-01-20T12:23:09Z DEBUG ofs] getattr(path=Some("/"))\r\n[2024-01-20T12:23:09Z DEBUG ofs] getattr(path=Some("/"))\r\n```

I will do another part about fuse implementation detail in the next PR.

> Now the ofs command running information as below\r\n\r\nComparing\r\n\r\n```shell\r\nofs --mount-path /path/to/mount/path --backend "fs://?root=/tmp"\r\n```\r\n\r\nI prefer to have\r\n\r\n```shell\r\nofs s3://bucket/root/path /mount/path\r\n```\r\n\r\nThe required values are the `backend path` and `mount path`. Using positional arguments makes more sense to me.

Now the ofs command as below\r\n```\r\n‚ï∞‚îÄ$ ./target/debug/ofs --help      \r\nError: parse command line arguments\r\n\r\nCaused by:\r\n    OpenDAL File System\r\n    \r\n    Usage: ofs <MOUNT_PATH> <BACKEND>\r\n    \r\n    Arguments:\r\n      <MOUNT_PATH>  fuse mount path [env: OFS_MOUNT_PATH=]\r\n      <BACKEND>     location of opendal service format: <scheme>://?<key>=<value>&<key>=<value> example: fs://root=/tmp [env: OFS_BACKEND=]\r\n    \r\n    Options:\r\n      -h, --help     Print help\r\n      -V, --version  Print version\r\n\r\n‚ï∞‚îÄ$ RUST_LOG=debug ./target/debug/ofs ./exampless "fs://?root=/tmp"     \r\n[2024-01-20T16:47:07Z DEBUG opendal::services::fs::backend] backend build started: FsBuilder { root: Some("/tmp"), atomic_write_dir: None }\r\n[2024-01-20T16:47:07Z DEBUG opendal::services::fs::backend] backend use root /tmp\r\n[2024-01-20T16:47:07Z DEBUG opendal::services::fs::backend] backend build finished: FsBuilder { root: None, atomic_write_dir: None }\r\n[2024-01-20T16:47:09Z DEBUG ofs] getattr(path=Some("/"))\r\n```\r\n\r\ncc @Xuanwo 

Thank you! I have additional ideas for the UX of ofs, but I believe this PR is ready to be merged as is.

> Thank you! I have additional ideas for the UX of ofs, but I believe this PR is ready to be merged as is.\r\n\r\nWe can talk about this in another issue. 

Thanks!

https://github.com/apache/opendal/blob/6782d561186ca64907ebf68fe51925a19caf6ce2/CHANGELOG.md?plain=1#L3235-L3237\r\n\r\nWe may need to update here, too.

> https://github.com/apache/opendal/blob/6782d561186ca64907ebf68fe51925a19caf6ce2/CHANGELOG.md?plain=1#L3235-L3237\r\n> \r\n> We may need to update here, too.\r\n\r\nDone

cc @bokket to help take a review

Thanks! nice for me.I am also testing whether `X-Apple-Widget-Key`(authServiceKey) can be obtained by [Tunes Connect Endpoint](https://github.com/go-darwin/appleoauth/blob/main/appleoauth.go#L114) 

it failed in \r\n```\r\ncore/src/raw/http_util/client.rs:110:58:\r\ninput request url must be valid: RelativeUrlWithoutBase\r\n```\r\nLet me go back to it

Great, thanks a lot!

Thanks a lot!

Please also update the readme~

My bad, no support for scan at the moment, remove `AccessorCapability::Scan`

Great PR!

cc @imWildCat, can you help to take a review? Thank you in advance.

seems all PR failed at `CI / msrv_check`: `error: package `time-macros v0.2.7` cannot be built because it requires rustc 1.62.0 or newer, while the currently active rustc version is 1.60.0`\r\n@Xuanwo 

Related to https://github.com/time-rs/time/issues/551, please ignore it for now.

please update with main, already fixed.

Seem that currently only s3 and webdav support batch delete?

> Seem that currently only s3 and webdav support batch delete?\r\n\r\nAt the moment only s3 is supported. We will add this later for `oss` and `gcs` (as you requested). And at the same time we need to make sure that `batch` plays well with all our existing ecosystems. All this work will be released in the next version of Opendal.

msrv will not be happy because of https://github.com/time-rs/time/issues/551, please ignore it for now. I am thinking about the solution.

Thanks a lot!

i am not sure how to add a nginx config to support such authentication

> i am not sure how to add a nginx config to support such authentication\n\nNever mind, let me handle this.

**request (blocking)**: Please make CI passed.

Thanks for the contribution!

Thanks for your contribution!

After this PR is merged, we can implement Content-Disposition support for services like S3.

**request(blocking)**: Please fix the tests

request(blocking): Please fix the tests

Simple change, will merge directly.

For example:\r\n\r\nhttps://github.com/datafuselabs/databend/pull/9897/\r\n\r\n![image](https://user-images.githubusercontent.com/5351546/218412987-06e9554e-b5d4-42b7-9c80-ba20390d7749.png)\r\n

> For example:\r\n> \r\n> [datafuselabs/databend#9897](https://github.com/datafuselabs/databend/pull/9897)\r\n\r\nThanks for your example, it makes sense and does not really seem to have an urge to implement so.\r\n\r\n

@jkleinknox, sorry for the delay, list/scan support for sleds has now been added!

Awesome @Xuanwo, thank you very much!

Still seeing this error:\r\n\r\n```\r\nwarning: `opendal-example` (bin "opendal-example") generated 7 warnings\r\n    Finished dev [unoptimized + debuginfo] target(s) in 0.15s\r\n     Running `target/debug/opendal-example`\r\ntest_file_content: "f"\r\nError: Unsupported (permanent) at list, context: { service: webdav } => operation is not supported\r\n```\r\n\r\nNot sure where to fix?

@Xuanwo I have to go to sleep today. Will (probably) refine this PR tomorrow.\r\n\r\nI noticed some logic error of my implementation at this moment.\r\n\r\nVery appreciate your review!

> @Xuanwo I have to go to sleep today. Will (probably) refine this PR tomorrow.\r\n\r\nWish you a beautiful night :heart: ! Thank you so much!

Hi, @imWildCat, I have set up the integration test environment for webdav. Now the tests can be run. Please take a look at it~

@Xuanwo thanks a lot!

Hi @Xuanwo, I spent most of today to debug this issue but haven\

Please always return Ok for dir. Take http service or s3 service as an example.\n\nSorry for the confusion, I will add it in docs.

> Please always return Ok for dir. Take http service or s3 service as an example.\r\n> \r\n> Sorry for the confusion, I will add it in docs.\r\n\r\nThanks! This is super quick reply!

Thank you, @Xuanwo !\r\n\r\nI really appreciate the help from you and @ClSlaid !\r\nI think this is the best way for me to learn Rust programming.\r\n\r\nI will be using OpenDAL for WebDAV/GDrive/Dropbox/OneDrive in the future of client (not cloud) applications.\r\nHappy to chat about its future!

Thanks a lot!

I did some work like this before.\nmostly the same as this PR\n. I think you need to add the auth things in Actions.\n\nwebdav acrions test use nginx as service, and nginx can use basic auth. plug-in\nBut kind of failed when I am trying , you can take a try.

And Actions you can use ftp actions as example

> Does anyone really set an empty password? IMO, even if the user wants to do so, the service provider will not allow it.\r\n\r\nPlease make sure that our implementation is **correct**. Whether or not a service supports basic authentication without a password is a user decision. For example, the user might have configured a webdav service with Nginx this way.

I have verified that `:` is necessary when it comes to empty password. Use [this](https://github.com/OpenMarshal/npm-WebDAV-Server) to build a local webdav server and set empty password, only if format the auth string with `:` can I connect to the local webdav server.

So nice!

I am curious whether `webhdfs` does not depend on hadoop and java environment?

> I am curious whether `webhdfs` does not depend on hadoop and java environment?\r\n\r\nThe service is purely rust implemented and communicates with Hadoop via RESTful APIs.\r\n\r\nhttps://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/WebHDFS.html

Most work of this service is complete, waiting for #1260 and https://github.com/beyondstorage/setup-hdfs/pull/138

#1260 is about to merge, welcome to play with our new framework!

Hi, any updates on this PR?

Just resolved conflicts with the main branch.\r\nNow applying review opinions.

Wow~\r\n\r\n![image](https://user-images.githubusercontent.com/5351546/216958508-a268b9cf-ac5a-44ac-a5e7-bd89b47b39e1.png)\r\n

This PR is good enough to get merged! I will merge it after ALL CI passed.

with packages for --all-features, jdk libssl-dev\r\nwith useful tools like mold\r\nwith out node and maturin

I did not encounter hangs and other strange errors, maybe you can try it again\r\n

I can see the full picture now, but there are still many works to do to make everything work as expected.\r\n\r\nOur `cargo check` errors are down from 3k to 900+ :rofl: 

Great!

Nice catch!

Thanks a lot!

Adding sccache for cache will lead to ghac test failure, because we will out of the rate limit.

> Adding sccache for cache will lead to ghac test failure, because we will out of the rate limit.\r\n\r\nWe need to make sure `ghac` services test work as expected.

> Fantastic! Mostly LGTM. This PR need to wait for a new release of reqsign. I will do this today~\r\n\r\nreqsign v0.7.4 has been releases, please update it in `Cargo.toml`.

Oh, this PR introduces a breaking change under rust 1.60:\r\n\r\n```rust\r\nerror: cannot borrow `builder` as mutable because it is also borrowed as immutable\r\n   --> src/services/azblob/backend.rs:239:13\r\n    |\r\n2[32](https://github.com/datafuselabs/opendal/actions/runs/3827230736/jobs/6511644085#step:8:33) |             let account_name = builder.account_name.as_ref().ok_or_else(|| {\r\n    |                                ----------------------------- immutable borrow occurs here\r\n...\r\n239 |             builder.endpoint(&format!("{protocol}://{account_name}.blob.{v}"));\r\n    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^------------^^^^^^^^^^^^^\r\n    |             |                                        |\r\n    |             |                                        immutable borrow later used here\r\n    |             mutable borrow occurs here\r\n    |\r\n    = note: `-D mutable-borrow-reservation-conflict` implied by `-D warnings`\r\n    = warning: this borrowing pattern was not meant to be accepted, and may become a hard error in the future\r\n    = note: for more information, see issue #59159 <https://github.com/rust-lang/rust/issues/59159>\r\n```\r\n\r\nPlease take a look~\r\n\r\nNOTE: it\

Thanks for your contribution!

Ok, finally, I know what happened:\r\n\r\n- `commit` must use `content_type: application/json`, otherwise, service will return 500.\r\n- 0 bytes file is not supported

amazing

> when no root is specified the `fs` backend was previously by default rooted at `/`.\r\n\r\nOn windows, fs backend must specify a root-like `C:/`. We can implement different test for windows.

Nice @Xuanwo !

Awesome thanks! I will integrate!

I redid the whole thing from scratch. I got all opendal\

This PR looks nice now, please update with main branch and make our CI passed on windows platform (fs local test)

Thanks a lot!

> Mostly LGTM to me, can you also update the usage in `blocking_read`?\r\n\r\nok, done

minio will parse range into int64:\r\n\r\nhttps://github.com/minio/minio/blob/444ff20bc5268d61b329c1d1bc7eb22aeb5f96de/cmd/httprange.go#L106-L164

Okay, let me try.

It seems that tests on hdfs are not stable, fortunately, the minio problem is solved.\r\nCan we restart this test separately, Or just push an empty commit to restart all?

Let me go to sleep first and visit those code tomorrow~

Amazing!

There are still some details that need to be considered and clarified and may require further discussion. 

We plan to introduce a double-level cache logic like `memory + fs`, `memory + redis` which allows users to decide whether to fill cache in memory or fs. Thus we will take a look on this RFC later after the double level implemented.

Thanks!

Thanks a lot!

Hi @messense, can you add docs here to let users know about those features? Many thanks for considering my request.\r\n\r\nhttps://github.com/datafuselabs/opendal/blob/65252c1a00eaacde05adb89be5b14444c7c3f035/src/lib.rs#L78

Thanks!

Thanks!

Is this PR ready for review?

Closed for no response.

Looks like anyhow is up-to-date now, so this is no longer needed.

Looks like clap is up-to-date now, so this is no longer needed.

Looks like anyhow is up-to-date now, so this is no longer needed.

Looks like futures is up-to-date now, so this is no longer needed.

Looks like clap is up-to-date now, so this is no longer needed.

Looks like assert_cmd is up-to-date now, so this is no longer needed.

Thanks!

- Add `content_type` in `OpWrite`.\r\n- Provide API called `object.write_with(op: OpWrite)`\r\n

Thanks a lot!

What happened to ftp tests...

```shell\r\n[2022-10-08T09:49:27Z DEBUG reqsign::services::aliyun::oss] string to sign: DELETE\r\n\r\n\r\n    Sat, 08 Oct 2022 09:49:27 GMT\r\n    /opendal-testing/0be3f60d-958a-4389-8722-ab4531bfdfc0/0be3f60d-958a-4389-8722-ab4531bfdfc0/4c80085b-c08a-4696-b4b6-7a7d402872f8 !@#$%^&*()_+-=;\

Test can pass if we are using s3 service.

> Test can pass if we are using s3 service.\r\n\r\nA bug in delete.

Please use encoding type.

BTW, can you give a reproduce of the problem?

Looks like clap is up-to-date now, so this is no longer needed.

Looks like tokio is up-to-date now, so this is no longer needed.

Looks like tokio is up-to-date now, so this is no longer needed.

Looks like clap is up-to-date now, so this is no longer needed.

Thanks!

Thanks a lot!

Hi @Xuanwo  PTAL :)

Mostly LGTM!\r\n\r\nThe only work left here is to use `cargo fmt` to make `rustfmt` happy~

> Mostly LGTM!\r\n> \r\n> The only work left here is to use `cargo fmt` to make `rustfmt` happy~\r\n\r\nUpdated! PTAL

Test failed for\r\n\r\n```shell\r\n---- layers::retry::tests::test_retry_not_retryable_error stdout ----\r\nthread \

> Test failed for\r\n> \r\n> ```shell\r\n> ---- layers::retry::tests::test_retry_not_retryable_error stdout ----\r\n> thread \

Updated! PTAL! @Xuanwo 

I just forgot to execute `cargo fmt` ü§£\r\n\r\nIs there any way to run `cargo fmt` and `cargo fix` automatically on my local machine?

> Is there any way to run `cargo fmt` and `cargo fix` automatically on my local machine?\r\n\r\nThe easiest way is to enable `auto format` in VSCode or IDEA.\r\n\r\nWe can also add cargo fmt as a git pre-commit check:\r\n\r\n```shell\r\n#!/bin/bash\r\n\r\nset -eu\r\n\r\n# Check fmt\r\nif ! cargo fmt --all -q --check\r\nthen\r\n    cargo fmt --all\r\n    echo "Fmt not happy, please add again."\r\n    exit 1\r\nfi\r\n```\r\n\r\nNOTE: `cargo fmt` is cheap, but `cargo fix` could consume a lot of time so I prefer to run `cargo fix` only when needed.

> > Is there any way to run `cargo fmt` and `cargo fix` automatically on my local machine?\r\n> \r\n> The easiest way is to enable `auto format` in VSCode or IDEA.\r\n> \r\n> We can also add cargo fmt as a git pre-commit check:\r\n> \r\n> ```shell\r\n> #!/bin/bash\r\n> \r\n> set -eu\r\n> \r\n> # Check fmt\r\n> if ! cargo fmt --all -q --check\r\n> then\r\n>     cargo fmt --all\r\n>     echo "Fmt not happy, please add again."\r\n>     exit 1\r\n> fi\r\n> ```\r\n> \r\n> NOTE: `cargo fmt` is cheap, but `cargo fix` could consume a lot of time so I prefer to run `cargo fix` only when needed.\r\n\r\nGreat! Thanks!

Congrats!

Thanks!

Please update to branch before start new PR.

@ClSlaid are there other updates?

> @ClSlaid are there other updates?\r\n\r\nforgot to add test on the error message, resolving git conflicts.\r\n

@xprazak2 Thanks for your contribution!

@Xuanwo PTAL.\r\nsorry for PR on weekends üõåüèª

still not ready for review

Does cli need docs? It is self documenting by `help` command.

> \r\n\r\nFixed. Integration tests should be put into `tests/`.

Please also update our docs.

```rust\r\nerror[E0432]: unresolved import `opendal::services::redis`\r\n  --> examples/redis.rs:21:5\r\n   |\r\n21 | use opendal::services::redis;\r\n   |     ^^^^^^^^^^^^^^^^^^^^^^^^ no `redis` in `services`\r\n\r\nerror[E0432]: unresolved import `opendal::services::redis`\r\n  --> examples/redis.rs:22:24\r\n   |\r\n22 | use opendal::services::redis::Builder;\r\n   |                        ^^^^^ could not find `redis` in `services`\r\n```\r\n\r\nTo use features in `example`, we need:\r\n\r\nhttps://github.com/datafuselabs/opendal/blob/36ebc48bff69347ccdd7a63ff9b39f1be035a09a/Cargo.toml#L62-L64

Sounds good. And how about if we going one step further by totally remove `native-tls` and make `rustls` the default and the only option for TLS? Because `ureq` has no `openssl` support, naming a `native-tls` feature for half of fact is also quite confusing.

Great work!

Thanks!

Hi, @ArberSephirotheca \r\n\r\nI have set up integration tests in this PR in action `Service Test Ftp`. Can you take a look at the failed tests?\r\n\r\nSince you have been granted the `write` permission for this project, you can use `gh pr checkout 648` and push to this branch directly for testing.

All failures are sovled execpt one about `stat` operation. As there is no command in FTP that get information of single file/directory, I use `list` command for `stat` operation. `list` command works fine if we want information of a single file(it just return a vector of size 1). However, it does not work if we want to get information of a directory. For example, If we want to get metadata of a directory `throwawayaa/` it self, the `list`command would try to get metada of any files or subdirectory within that directory rather than itself.\r\nWe could solve it by first `list` its parent directory and then find the information of directory we want from vector of results, but what if user want the metadata of `/`(root directory)?

We can always return ObjectMode::DIR for root dir. Other metadata can leave as empty.

Thanks for your hard-working! We can release FTP support for the next release now!

There still exists a problem with FTP here. The correct way to shutdown a FTP connection is: \r\n1. Close the data stream. \r\n2. Wait for the `226 Transfer Ok` from command stream \r\n3. Send `Quit` command to the server.\r\n\r\nIf we want `read()` to directly return the data stream, we could not close the connection at the end of `Read` operation, and we must keep the connection open until user close data stream. Otherwise, we would receive unexpected response from server.(for example, if we send `Quit` command to server before closing the data stream, we would receive unexpected response such as `226 Transfer Complete` from server).

I created a new issue https://github.com/datafuselabs/opendal/issues/638 for that, maybe you will be interested to contintue.

I think all is done now, @Xuanwo thanks for your patience and instructions!

> rustfmt confirmed that we get the same format (you will find the check didn\

![ÂõæÁâá](https://user-images.githubusercontent.com/44747719/187391392-ce3d5b55-95e8-4dc5-8b8a-dcd8d3008eb1.png)\r\nsolved

So nice!

`Clippy` and `Rustfmt` are your friends. Before commit, you can run `cargo clippy` for checks and advices, and run `cargo fmt` to reformat you code.

@ClSlaid Thanks for the review. I am moving house right now so I may not update too frequent, but I hope I can get all these thing fixed within a week.

This PR is really great and almost done. I left some reviews on this PR. Please take a look when you are free. \r\n\r\n> I am moving house right now so I may not update too frequent\r\n\r\nAnd congrats on your new move. Hoping your new house is nice and comfortable.

Great work!

`build` op is used in fs Builder, but it is not a valid op.\r\n\r\n```rust\r\n        if let Err(e) = std::fs::metadata(&root) {\r\n            if e.kind() == ErrorKind::NotFound {\r\n                std::fs::create_dir_all(&root).map_err(|e| parse_io_error(e, "build", &root))?;\r\n            }\r\n        }\r\n```\r\n\r\nHow to fix this case? I think adding a `build` op in `Operation` is not a good idea.

still working on it

Cc @eastfisher, I have added docs for obs, PTAL.

Hi, @eastfisher \r\n\r\nI have invited you as a collaborator. And I have set up all secrets that obs needed.\r\n\r\nPlease push to this PR directly for testing.\r\n\r\n```shell\r\ngh pr checkout 572\r\n```

OK, thanks!

Please ignore flaky tests for hdfs :cry: 

`reqsign` need to update\r\n\r\nhttps://github.com/Xuanwo/reqsign/pull/112

Great work!

Please wait a moment, local commit has not been pushed due to network error.

Fixed, PTAL

Please update the branch with the latest main before merging.

Still not ready for review

Please also update https://github.com/datafuselabs/opendal/blob/main/docs/SUMMARY.md

ok

GreatÔºÅ

For this PR, we only need to make CI happy.

Thanks for contribution!

Please also add docs in `lib.rs` and gcs mod.\r\n\r\nFor example: https://github.com/datafuselabs/opendal/blob/d6cbd898ae2826d5b2327b90a577b6b33b6680da/src/services/s3/mod.rs#L15

/cc @Xuanwo PTAL

Cc @ClSlaid for reviewing

/cc @Xuanwo PTAL

Great work!

Replaced by https://github.com/datafuselabs/opendal/pull/532 to address credential issues.

Cc @ClSlaid for reviewing

Cc @ClSlaid for reviewing

cc @ClSlaid, PTAL.

This PR is still working in progress, tasks to complete:\r\n\r\n- [ ] Add unit tests for the GCS backend\r\n- [ ] Add unit tests for the GCS directory walker\r\n- [ ] Add integrated tests for the GCS service\r\n- [ ] Test on real-world GCS

> This PR is still working in progress, tasks to complete:\r\n> \r\n> * [ ]  Add unit tests for the GCS backend\r\n> * [ ]  Add unit tests for the GCS directory walker\r\n> * [ ]  Add integrated tests for the GCS service\r\n> * [ ]  Test on real-world GCS\r\n\r\nPlease create a tracking issue for this. I prefer to merge multiple PRs instead of one.

I refactored error parse in #515 and #516, PTAL.

Please mark the conversation as resolved after fixing.

@Xuanwo PTAL! ;)

Please resolve conflicts before reviewing.

> For now, those functions are literally the same. The only difference between them is their visibility.\n\nMakes sense to me.\n\nService can implement their own error kind parser if needed.

I will add blocking APIs in `Accessor` directly after #502 is finished.\r\n\r\n> #502 will allow user to init a services without async.\r\n\r\nI expect users to use API in the way same as async code:\r\n\r\n```rust\r\nlet bs = op.object("path/to/file").blocking_read();\r\n```\r\n\r\nvs\r\n\r\n```rust\r\nlet bs = op.object("path/to/file").read().await;\r\n```\r\n\r\n---\r\n\r\nI don\

Ok. this is just an experiment pr to validate.

@Xuanwo Thanks for merging! Could you please create a release for this?

Addressed in https://github.com/datafuselabs/opendal/pull/497

@xprazak2 Hi, are you still working on this PR?

I am still working on it, apologies it is taking me so long. I think I have addressed all the comments except for using `new_http_channel`, I might need a bit more guidance on it. I was looking at it previously, but I am not sure how to plug it in. I can use `Box::pin` to pass fut into `RequestWriter` and skip `IpfsWriterFuture` but then I get lifetime error:\r\n![io-channel](https://user-images.githubusercontent.com/2664090/184530832-e60246e4-52f0-47c5-a752-4b4f1d60eea2.png)\r\n

We have a refactor in https://github.com/datafuselabs/opendal/pull/556 to make it easier to implement IPFS backend, PTAL.

Having access to the reader made it much easier to implement `write`. I rebased and removed IPFS SDK.

@Xuanwo, all green now.

Great, thanks for your PR!

@PsiACE Can you share the benchmarks after replacing `tokio-fs`?

Bravo!

Let me have a sleep to see will I change my mind tomorrow.

Update with main to fix a CI failure.

> [Rendered](https://github.com/datafuselabs/opendal/blob/rfc-for-cli/docs/rfcs/0423-command-line-interface.md)\r\n\r\n404.

> > [Rendered](https://github.com/datafuselabs/opendal/blob/rfc-for-cli/docs/rfcs/0423-command-line-interface.md)\r\n\r\nFixed!

Thanks for the contribution!\r\n\r\nThis change mostly LGTM except one thing: can we make `serde` a feature so that we only derive those traits while needed?

@Xuanwo  Of course, we can. I have refactor the code and make `serde` as a feature(disabled by default), please take a look, thank you.\r\n\r\n

Replaced by https://github.com/datafuselabs/opendal/pull/392

Superseded by #393.

Thanks for your contribution first!\r\n\r\nBut keeping the hdfs path as-is does not meet the basic requirements of OpenDAL which operates different storage systems at the same time. So I will reject this change.\r\n\r\n---\r\n\r\nFor the differences you mention (thanks first!)\r\n\r\n> 1, hdfs does\

thanks for your quickly reply,  open #329 to keep the hdfs error.   

HDFS test failed\r\n\r\n```shell\r\n[2022-06-02T13:55:38Z DEBUG opendal::services::hdfs::backend] object /8625802f-8271-43a6-9b74-a93466834ce4/ad7e3f9c-efac-4955-bf08-e5103229a49b/ create dir\r\n[2022-06-02T13:55:38Z DEBUG opendal::services::hdfs::backend] object /8625802f-8271-43a6-9b74-a93466834ce4/ad7e3f9c-efac-4955-bf08-e5103229a49b/ list start\r\n[2022-06-02T13:55:38Z ERROR opendal::services::hdfs::backend] object /8625802f-8271-43a6-9b74-a93466834ce4/ad7e3f9c-efac-4955-bf08-e5103229a49b/ list: Custom { kind: NotFound, error: ObjectError { op: "list", path: "/8625802f-8271-43a6-9b74-a93466834ce4/ad7e3f9c-efac-4955-bf08-e5103229a49b/", source: No such file or directory (os error 2) } }\r\nError: object error: (op: list, path: /8625802f-8271-43a6-9b74-a93466834ce4/ad7e3f9c-efac-4955-bf08-e5103229a49b/, source: No such file or directory (os error 2))\r\n\r\nCaused by:\r\n    No such file or directory (os error 2)\r\nthread \

Thank you for a review and hints. The trailing slash turns out to be [surprisingly tricky](https://www.reddit.com/r/rust/comments/ooh5wn/damn_trailing_slash/) as `std::path::Path` seems to be normalizing them away. Also, when there is a trailing `/` and I split by it, I cannot add it back and return `&str` due to ownership, so I return `String`. Is that ok?

Run `cargo fmt` to make our check happy :smile: 

Our test s3 bucket has been moved, waiting for @wubx to fix.

wow, uuid got a 1.0 release!

Unresolved questions that block this PR get merged:\r\n\r\n- [ ] CI check failed\r\n- [ ] https://github.com/datafuselabs/opendal/pull/193#discussion_r837085366\r\n- [ ] https://github.com/datafuselabs/opendal/pull/193#discussion_r837085843

https://github.com/datafuselabs/opendal/pull/193#discussion_r837085843\r\nI have tried removing this blob var but failed. I am not so familiar with XML parsing. Is it possible to remove the Blobs?

> I have tried removing this blob var but failed. I am not so familiar with XML parsing. Is it possible to remove the Blobs?\r\n\r\nOh, there is a misunderstanding here. What I mean is remove the line `#[serde(rename = "Blob", default = "Vec::new")]`.\r\n\r\n- `blob` will be renamed to `Blob` via `PascalCase`, so we don\

Nice work!

![image](https://user-images.githubusercontent.com/100247023/159631083-28188387-5c56-4902-8c98-655296fb1570.png)\r\nI move the collector to tests/behaviour file, and add macro to s3 accessor .`minitrace_jaeger` has been move to dev-dependenices. Should I create anaother tests file for tracing?

I add this to env \r\n`# minitrace\r\nOPENDAL_JAEGER_TRACE=on\r\nOPENDAL_JAEGER_ADDR=127.0.0.1:6831\r\nOPENDAL_JAEGER_SERVICE_NAME=macro_tracing_test`\r\n\r\nCurious where to load this env variables. Is it in the tests/behavior or in  new function like service/s3::new()

> Good, I am interested in this[ issue,](https://github.com/datafuselabs/opendal/issues/106) let me try\r\n\r\nSo nice! Please do it in a new PR so that we can do it in parallel.

I leave tests module unchange and refine the azblob module. After I finish list object func then I will create another PullRequest

Looks so nice! Great work!

AWS S3 and anonymous minio s3 works well, we need to address https://github.com/Xuanwo/reqsign/issues/20

> AWS S3 and anonymous minio s3 works well, we need to address [Xuanwo/reqsign#20](https://github.com/Xuanwo/reqsign/issues/20)\r\n\r\nShould be fixed in https://github.com/Xuanwo/reqsign/pull/22

Cool, I used to think memory backend is test only

Maybe we should use `Vec<Bytes>` to support multiple Bytes?

Nice work!

@mergify update

> update\n\n#### ‚òëÔ∏è Nothing to do\n\n<details>\n\n- [X] `-closed` [:pushpin: update requirement]\n- [ ] `#commits-behind>0` [:pushpin: update requirement]\n\n\n</details>\n\n\n<!--\nDO NOT EDIT\n-*- Mergify Payload -*-\n{"command": "update", "conclusion": "neutral"}\n-*- Mergify Payload End -*-\n-->\n\n\n_Hey, I reacted but my real name is @Mergifyio_

Blocked by https://github.com/datafuselabs/opendal/pull/99

Thank you, @Xuanwo \r\nDo you have the plan to release a new version? Databend need this :)

Databend bumped:\r\nhttps://github.com/datafuselabs/databend/pull/4277/commits/b65fa3cd9f82e1a9d11b6804d5b1649b19d7e012\r\n\r\n@Xuanwo , Please have a look, thank you :)

Here is my PR: https://github.com/datafuselabs/databend/pull/4298

@BohuTANG This PR will make it possible to calculate the read cost inside the reader.\r\n\r\nAnd we are archiving it in a much better way: we can calculate the cost for pending, for reading. We can even calculate the averaging reading speed based on `ReadEvent::Read(n)`.

Oh, the size should take `offset` into consideration, let me fix it and add a test.

Ping @dantengsky @zhang2014 @sundy-li, I refactor this PR, please read RFC [limited-reader](https://github.com/datafuselabs/opendal/blob/fix-reader/docs/rfcs/0090-limited-reader.md) for more details.

Cool, I will bump the latest version in this PR:\r\nhttps://github.com/datafuselabs/databend/pull/4277

The test should be improved in the future, but I think this PR is an excellent start to make `ObjectStream` work on s3.

/lgtm

/lgtm

Great! much better than `GetBucketLocation` :D

/lgtm

Seems we should bump a new release for databend?

/lgtm\r\n\r\nWe should add unit tests for it(assume will be addressed in the later PR).\r\n

> /lgtm\r\n> \r\n> We should add unit tests for it(assume will be addressed in the later PR).\r\n\r\nYep, I have a plan to have them tested today.