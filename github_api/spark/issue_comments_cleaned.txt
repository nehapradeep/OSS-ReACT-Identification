Issue #50289: Labels: SQL
Issue #50288: Labels: SQL
Merging to master. Thank you, @dongjoon-hyun @HyukjinKwon for review.
Issue #50287: Labels: SQL
Issue #50286: Labels: SQL, PYTHON
Issue #50285: Labels: SQL
cc @agubichev
Issue #50284: Labels: SQL
cc @cloud-fan @gengliangwang 
Issue #50283: Labels: SQL
Related Jira : https://issues.apache.org/jira/browse/SPARK-51515
Issue #50282: Labels: SQL
Issue #50281: Labels: SQL
cc @cloud-fan 
Issue #50280: Labels: DOCS
Issue #50279: Labels: SQL
ping @dongjoon-hyun @LuciferYang @HyukjinKwon 
Issue #50278: Labels: ML, MLLIB, BUILD
Issue #50277: Labels: CORE
Could we investigate the reason lead to the null value?
Issue #50276: Labels: BUILD
Issue #50275: Labels: SQL
@pan3793 \r\nWhen setting the [option](https://github.com/apache/spark/blob/master/sql/api/src/main/scala/org/apache/spark/sql/DataFrameWriter.scala#L87), Spark doesn\
Issue #50274: Labels: WEB UI
Could you review this PR, @yaooqinn ? It would be great if we can have your nice feature in `Spark Master` too.
Issue #50273: Labels: SQL
@maryannxue @cloud-fan 
Issue #50272: Labels: SQL, STRUCTURED STREAMING, PYTHON
nits: There seem to be more places that could remove the unnecessary `close()` impl in test file: e.g. https://github.com/apache/spark/blob/ccfc0a9dcea8fa9d6aab4dbb233f8135a3947441/python/pyspark/sql/tests/pandas/test_pandas_transform_with_state.py#L1479
Issue #50271: Labels: SQL
cc @huaxingao 
Issue #50270: Labels: SQL
Issue #50269: Labels: SQL
@MaxGekk this is ready for review
Issue #50268: Labels: SQL
@MaxGekk can you take a look at this when you get the chance?
Issue #50267: Labels: SQL
@cloud-fan please take a look when you get the chance.
Issue #50266: Labels: SQL
late LGTM, Thank you @MaxGekk 
Issue #50265: Labels: SQL
LGTM Thank you @wForget 
Issue #50264: Labels: SQL, BUILD
Merged into branch-4.0. Thanks @pan3793 
Issue #50263: Labels: SQL, BUILD, YARN, CORE
Issue #50262: Labels: BUILD
Issue #50261: Labels: BUILD
I appreciate it. Thank you, @dongjoon-hyun !
Issue #50260: Labels: CORE
Fixed. It was a difference between  Scala 2.12 vs 2.13. \r\nThe `Option#zip` gives back an `Iterable` on Scala 2.12 instead of an `Option`:\r\n```\r\n# scala\r\nWelcome to Scala 2.12.8 (OpenJDK 64-Bit Server VM, Java 1.8.0_442).\r\nType in expressions for evaluation. Or try :help.\r\n\r\nscala> val option = Some(1)\r\noption: Some[Int] = Some(1)\r\n\r\nscala> option.zip(option)\r\nres1: Iterable[(Int, Int)] = List((1,1))\r\n\r\nscala> None.zip(None)\r\nres2: Iterable[(Nothing, Nothing)] = List()\r\n\r\nscala> res1.headOption\r\nres3: Option[(Int, Int)] = Some((1,1))\r\n\r\nscala> res2.headOption\r\nres4: Option[(Nothing, Nothing)] = None\r\n```\r\n\r\nAlthough the documentation does not says differently: https://www.scala-lang.org/api/2.12.8/scala/Option.html#zip[B](that:scala.collection.GenIterable[B]):Option[(A,B)]
Issue #50259: Labels: CORE
Issue #50258: Labels: SQL, PYTHON
merged to master
Issue #50257: Labels: SQL, STRUCTURED STREAMING
Issue #50256: Labels: SQL, WEB UI, CORE
Issue #50255: Labels: BUILD
\r\nWill `dev/create-release/spark-rm/Dockerfile` be fixed in a separate pull request?\r\n\r\n
Issue #50254: Labels: PYTHON
cc @LuciferYang 
Issue #50253: Labels: SQL
Issue #50252: Labels: SQL, PYTHON
Issue #50251: Labels: SQL
![image](https://github.com/user-attachments/assets/c86b11c4-1994-4e66-be06-1481a1419e97)\r\nall passed
Issue #50250: Labels: SQL
Merged to master. Thank you, @MaxGekk .
Issue #50249: Labels: SQL, STRUCTURED STREAMING
Merged to master. Thank you, @LuciferYang and @beliefer .
Issue #50248: Labels: SQL, EXAMPLES
Issue #50247: Labels: DOCS
Issue #50246: Labels: SQL
Issue #50245: Labels: SQL
@viirya @dongjoon-hyun @kazuyukitanimura could you please take a look? 
Issue #50244: Labels: ML, MLLIB
Issue #50243: Labels: PYTHON, PANDAS API ON SPARK
Issue #50242: Labels: SQL, PYTHON
Merged to master.
Issue #50241: Labels: PYTHON
Merged to master.
Issue #50240: Labels: SQL
Issue #50239: Labels: SQL
Thank you @dongjoon-hyun 
Issue #50238: Labels: SQL, STRUCTURED STREAMING
Issue #50237: Labels: INFRA
Thanks @HyukjinKwon 
Issue #50236: Labels: SQL
@yaooqinn @LuciferYang @dongjoon-hyun @HyukjinKwon Could you take a look at the PR when you have time, please.
Issue #50235: Labels: SQL
ping @dongjoon-hyun @yaooqinn @LuciferYang @MaxGekk 
Issue #50234: Labels: SQL, CONNECT
@MaxGekk can you take a look?
Issue #50233: Labels: WEB UI
Let me build and verify manually too~
Issue #50232: Labels: SQL, BUILD
Thank you, @pan3793 and @LuciferYang . Merged to master.\r\n\r\nCould you make a backporting PR to branch-4.0 to pass CI there once more, @pan3793 ?
Issue #50231: Labels: SQL, BUILD, DOCS, CORE, PYTHON, CONNECT
tests files are not in the releasee. Why do we need to remove them?
Issue #50230: Labels: SQL, CORE
Issue #50229: Labels: INFRA
Thank you, @HyukjinKwon .
Issue #50228: Labels: SQL
Merged to master for Apache Spark 4.1.0.
Issue #50227: Labels: SQL
cc: @viirya 
Issue #50226: Labels: SQL
LGTM if CI passes
Issue #50225: Labels: WEB UI
I also built and verified manually this PR.\r\nMerged to master for Apache Spark 4.1.0.
Issue #50224: Labels: SQL
late LGTM
Issue #50223: Labels: CORE
@beliefer - pls take a look
Issue #50222: Labels: BUILD, DOCS
I personally would treat this as a blocker for the 4.0.0 release.\r\ncc @cloud-fan @dongjoon-hyun @LuciferYang @wangyum @yaooqinn
Issue #50221: Labels: SQL
ping @dongjoon-hyun @yaooqinn @LuciferYang 
Issue #50220: Labels: SQL
@itholic @dongjoon-hyun @yaooqinn Could you review this PR, please. 
Issue #50219: Labels: SQL, STRUCTURED STREAMING, PYTHON, CONNECT
> Are these all instances, @LuciferYang ?\r\n\r\nSupplemented the cases in the test code path, these are all instances now
Issue #50218: Labels: CORE
Thanks @dongjoon-hyun and @amoghantarkar 
Issue #50217: Labels: SQL
@cloud-fan could you help review? Thanks!
Issue #50216: Labels: SQL, ML, MLLIB, STRUCTURED STREAMING, KUBERNETES, WEB UI, BUILD, YARN, DOCS, CORE, WINDOWS, INFRA, PYTHON, R, DSTREAM, AVRO, PANDAS API ON SPARK, CONNECT, PROTOBUF
Issue #50215: Labels: SQL
my concern is that this is a breaking change ... We will at least have to update the migration guide
Issue #50214: Labels: SQL, STRUCTURED STREAMING
Thanks! Merging to master.
Issue #50213: Labels: SQL, BUILD
Issue #50212: Labels: SQL, PROTOBUF
Could you further point out where in the current Spark code the `hashCode`/`equals` methods of `CatalystDataToProtobuf ` and `ProtobufDataToCatalyst ` are being used?
Issue #50211: Labels: CORE
ping @srowen @dongjoon-hyun @LuciferYang 
Issue #50210: Labels: CORE
Please config github action.
Issue #50209: Labels: SQL, STRUCTURED STREAMING, KUBERNETES, CORE
ping @srowen @dongjoon-hyun @LuciferYang 
Issue #50208: Labels: SQL
thanks, merging to master/4.0!
Issue #50207: Labels: SQL
Issue #50206: Labels: SQL, INFRA
The PR title and description will be updated after the finalization of the plan.\r\n\r\n
Issue #50205: Labels: PYTHON
Issue #50204: Labels: SQL
Issue #50203: Labels: BUILD, INFRA
Merged to master and branch-4.0.
Issue #50202: Labels: SQL
Issue #50201: Labels: SQL, PYTHON
Oops, I mistakenly removed your comment. Yes, it has to be != and fixed
Issue #50200: Labels: SQL
Merged to master.
Issue #50199: Labels: ML, PYTHON
Issue #50198: Labels: PYTHON
cc @HyukjinKwon @itholic 
Issue #50197: Labels: SQL
Issue #50196: Labels: DOCS, PYTHON
Merged to master and branch-4.0.
Issue #50195: Labels: SQL, STRUCTURED STREAMING
@HeartSaVioR can you take a quick look at this? Thanks ðŸ™‚ \r\n\r\nI understand that you have a lot of other tasks that are more pressing, just wondering if this is on your radar.
Issue #50194: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @calilisantos.
Issue #50193: Labels: SQL, PYTHON, CONNECT
Putting this on hold ATM as some unexpected complications popped up (particularly the interactions with response indices and response caching)
Issue #50192: Labels: SQL
Issue #50191: Labels: SQL, PYTHON, CONNECT
Thanks for the review! CI is green after some lint changes :) 
Issue #50190: Labels: SQL
@LuciferYang @gengliangwang Could you review this PR, please.
Issue #50189: Labels: BUILD
All tests passed.\r\n\r\n<img width="739" alt="Screenshot 2025-03-06 at 11 18 15" src="https://github.com/user-attachments/assets/068e298e-14e0-4b00-83c3-d8c4e2d2733d" />\r\n
Issue #50188: Labels: STRUCTURED STREAMING, PYTHON
Issue #50187: Labels: BUILD, DOCS, INFRA
@HyukjinKwon can you take a look?
Issue #50186: Labels: DOCS
Issue #50185: Labels: DOCS
Issue #50184: Labels: ML, PYTHON
merged to master
Issue #50183: Labels: SQL, PYTHON
Issue #50182: Labels: SQL
Merged to master and 4.0, thank you again @dongjoon-hyun 
Issue #50181: Labels: SQL, CONNECT
Merged to master and branch-4.0.
Issue #50180: Labels: SQL, PYTHON, CONNECT
Merged to master and branch-4.0.
Issue #50179: Labels: SQL
Issue #50178: Labels: SQL, INFRA
Issue #50177: Labels: DOCS
Issue #50176: Labels: SQL, STRUCTURED STREAMING
@HeartSaVioR - PTAL, thanks !
Issue #50175: Labels: DOCS
Thank you! Merged to master/4.0.
Issue #50174: Labels: BUILD
This is a retry of the previous commit. Currently, this PR is a draft status to investigate the CI Python failures.
Issue #50173: Labels: YARN
@pan3793 and @LuciferYang , this relates to code you added/reviewed in #46611 . Would you please review this test fix? Thank you.
Issue #50172: Labels: SQL, DOCS, CONNECT
Thank you, @allisonwang-db .
Issue #50171: Labels: SQL, DOCS, CONNECT
Thank you, @allisonwang-db .
Issue #50170: Labels: SQL
Issue #50169: Labels: SQL
LGTM
Issue #50168: Labels: SQL, STRUCTURED STREAMING
@HeartSaVioR - PTAL, thx !
Issue #50167: Labels: SQL
Merged to master.
Issue #50166: Labels: ML, MLLIB
thanks, merge into master
Issue #50165: Labels: SQL, STRUCTURED STREAMING
Thanks! Merging to 4.0.
Issue #50164: Labels: SQL
Sorry but could you rebase once more because Docker and SparkR CI also failed before, @yaooqinn ?\r\n\r\n<img width="292" alt="Screenshot 2025-03-05 at 18 45 01" src="https://github.com/user-attachments/assets/5e092a64-baea-4e93-9725-b490cbebe2d7" />\r\n
Issue #50163: Labels: SQL, PYTHON, CONNECT
Merged to master and branch-4.0.
Issue #50162: Labels: SQL, PYTHON
Gonna merge to recover the CI,
Issue #50161: Labels: SQL, STRUCTURED STREAMING
Issue #50160: Labels: SQL, PYTHON, CONNECT
Merged to master and branch-4.0.
Issue #50159: Labels: SQL, PYTHON, CONNECT
The comment is addressed, @HyukjinKwon . Thank you.
Issue #50158: Labels: No Labels
Merged to master/4.0, thank you @cnauroth 
Issue #50157: Labels: SQL, STRUCTURED STREAMING
@cloud-fan I was recommended to get your advice on this change, as this is related to https://github.com/apache/spark/pull/49816 and was merged in recently
Issue #50156: Labels: BUILD
Although this is reported as a bug, I believe this as an improvement.\r\n> This may waste time \r\n\r\nIf you need this in other branches, please let me know again~
Issue #50155: Labels: SQL, STRUCTURED STREAMING, CONNECT
Thank you @dongjoon-hyun ~
Issue #50154: Labels: SQL
thanks, merging to master/4.0!
Issue #50153: Labels: SQL, DOCS
Merging to master. Thank you, @yaooqinn @dongjoon-hyun for review.
Issue #50152: Labels: CORE
Thank you @dongjoon-hyun 
Issue #50151: Labels: BUILD
Issue #50150: Labels: BUILD
Thank you, @LuciferYang .
Issue #50149: Labels: SQL, CORE
Merged to master. Thank you, @pan3793 and all.
Issue #50148: Labels: SQL
thanks, merging to master!
Issue #50147: Labels: DOCS
Issue #50146: Labels: No Labels
Issue #50145: Labels: SQL, PYTHON, CONNECT
Actually I have a better approach. Let me push some more changes
Issue #50144: Labels: SQL, WEB UI, CONNECT
Thank you, @HyukjinKwon !
Issue #50143: Labels: SQL
ping @cloud-fan @MaxGekk 
Issue #50142: Labels: ML, MLLIB
merged to master
Issue #50141: Labels: CORE
Merged to master and branch-4.0.
Issue #50140: Labels: SQL, STRUCTURED STREAMING
Issue #50139: Labels: SQL, CONNECT
Thank you, @HyukjinKwon . \r\n\r\nMerged to master/4.0.
Issue #50138: Labels: No Labels
@cnauroth @dongjoon-hyun Thanks for the review.\r\nThe test failure is not relevant.  I am merging this one to master and branch-4.0 
Issue #50137: Labels: SQL
 > I think we just need to have an interface to hold all table information, and let createTable/replaceTable take it instead of many parameters.\r\n\r\nThanks for the feedback. Your suggestion seems simpler. \r\n\r\n@aokolnychyi What do you think?\r\n\r\n> ```\r\n> interface TableInfo {\r\n>   Column[] columns;\r\n>   Transform[] partitions;\r\n>   ...\r\n> }\r\n\r\nThis could just be an inheritable POJO instead?\r\n\r\n> \r\n> interface TableCatalog ... {\r\n>   Table createTable(Identifier ident, TableInfo t);\r\n> }\r\n> ```\r\n\r\nWould we deprecate the existing `create/replace Table()`  methods (In `TableCatalog` and `StagingTableCatalog`) for a new one that takes in `TableInfo` instead?\r\n
Issue #50136: Labels: SQL
@cloud-fan Could you PTAL when you have time? Should we add `(AUTO_GENERATED_ALIAS, "true")` metadata when creating alias because they are implicitly added (or it was intentionally left out)?\r\ncc @srielau
Issue #50135: Labels: SQL
Thanks, merging to master
Issue #50134: Labels: DOCS
Merged to master and 4.0, thank you @tomscut 
Issue #50133: Labels: SQL
cc @yaooqinn @LuciferYang 
Issue #50132: Labels: SQL
cc @cloud-fan @dusantism-db @miland-db 
Issue #50131: Labels: SQL
Issue #50130: Labels: SQL, PYTHON, CONNECT
Merged to master.
Issue #50129: Labels: SQL
ping @cloud-fan @yaooqinn 
Issue #50128: Labels: PYTHON
cc @HeartSaVioR @jingz-db 
Issue #50127: Labels: SQL, BUILD
cc @wayneguow @yaooqinn 
Issue #50126: Labels: SQL
ping @cloud-fan @yaooqinn @MaxGekk 
Issue #50125: Labels: SQL, DOCS
thanks, merging to master/4.0!
Issue #50124: Labels: SQL
Change the description a bit, hope it makes more sense.
Issue #50123: Labels: SQL, STRUCTURED STREAMING
Issue #50122: Labels: CORE
cc @mridulm, @Ngone51
Issue #50121: Labels: SQL
@cloud-fan could you help review? Thanks!
Issue #50120: Labels: SQL, PYTHON, CONNECT
Merged to master and branch-4.0.
Issue #50119: Labels: SQL, STRUCTURED STREAMING
@HeartSaVioR Can you PTAL at this change
Issue #50118: Labels: SQL
@cloud-fan Wenchen, can you please take a look?
Issue #50117: Labels: DOCS, PYTHON
Merged to master/4.0. Thank you, @HyukjinKwon and @allisonwang-db .
Issue #50116: Labels: CORE
Merged to master.
Issue #50115: Labels: BUILD
Thank you @dongjoon-hyun 
Issue #50114: Labels: BUILD
Merged to master/4.0/3.5\r\n\r\nThank you @LuciferYang 
Issue #50113: Labels: KUBERNETES, BUILD, DOCS
cc @dongjoon-hyun @yaooqinn 
Issue #50112: Labels: SQL
ping @cloud-fan 
Issue #50111: Labels: SQL, PYTHON
Merged to master and branch-4.0.
Issue #50110: Labels: SQL, PYTHON
Also updated the PR description to explain how I figured out the issue and how I verified the fix.
Issue #50109: Labels: SQL, DOCS
@cloud-fan @aokolnychyi do you want to look when you have a chance, thanks!
Issue #50108: Labels: SQL
Issue #50107: Labels: WEB UI, CORE
ping @mridulm @dongjoon-hyun  @LuciferYang @srowen  cc @jjayadeep06
Issue #50106: Labels: ML, MLLIB, BUILD
I created a new PR in https://github.com/apache/spark/pull/50278
Issue #50105: Labels: BUILD
LGTM\r\n
Issue #50104: Labels: SQL
thanks, merging to master!
Issue #50103: Labels: SQL, DOCS
@srielau Please, have a look at the PR when you have time.
Issue #50102: Labels: SQL, PYTHON, CONNECT
I think we could add some tests here to verify the change in the response? 
Issue #50101: Labels: SQL
cc @beliefer @MaxGekk 
Issue #50100: Labels: DOCS, PYTHON
LGTM
Issue #50099: Labels: SQL, DOCS, CORE, PYTHON, CONNECT
Let me add a legacy conf ...  to be safer ..
Issue #50098: Labels: SQL, ML, PYTHON, CONNECT
also cc @wbo4958 
Issue #50097: Labels: SQL
ping @cloud-fan @dongjoon-hyun 
Issue #50096: Labels: SQL, DOCS, PYTHON
cc @allisonwang-db 
Issue #50095: Labels: ML, PYTHON
merged to master
Issue #50094: Labels: SQL, PYTHON, CONNECT
The remaining test failures are not related to this PR.
Issue #50093: Labels: SQL, PYTHON, CONNECT
As "Protobuf breaking change detection and Python CodeGen check" failed with:\r\n\r\n```\r\nError: Previously present message "LazyExpression" was deleted from file.\r\nError: Previously present field "22" with name "subquery_expression" on message "Expression" was deleted.\r\nError: Field "21" with name "subquery_expression" on message "Expression" changed option "json_name" from "lazyExpression" to "subqueryExpression".\r\nError: Field "21" with name "subquery_expression" on message "Expression" changed type from "spark.connect.LazyExpression" to "spark.connect.SubqueryExpression".\r\nError: Field "21" on message "Expression" changed name from "lazy_expression" to "subquery_expression".\r\nError: buf found 5 breaking changes.\r\n```\r\n\r\n#50094 should show it\
Issue #50092: Labels: SQL, DOCS, CONNECT
@dongjoon-hyun @vrozov Would a change like this where the source code is included be acceptable in keeping the JAR?
Issue #50091: Labels: SQL, PYTHON, CONNECT
LGTM (barring the builds pass) :) 
Issue #50090: Labels: SQL
thanks, merging to master/4.0!
Issue #50089: Labels: SQL, PYTHON
LGTM (also could you please add a screenshot of the fixed issue as you did in the Jira desc if possible)? 
Issue #50088: Labels: SQL
cc @HeartSaVioR @viirya 
Issue #50087: Labels: SQL
The mentioned JIRA is in "resolved" state. We either ought to reopen it or open a new jira?
Issue #50086: Labels: DOCS, PYTHON
LGTM
Issue #50085: Labels: SQL
Also, cc @yaooqinn and @LuciferYang , too
Issue #50084: Labels: SQL, CORE, PYTHON
Merged to master and branch-4.0.
Issue #50083: Labels: SQL, PYTHON
Merged to master and branch-4.0.
Issue #50082: Labels: SQL
@cloud-fan, @stefankandic, @stevomitric, please take a look when you find some time, thanks!
Issue #50081: Labels: PYTHON
Thanks! merging to master/4.0.
Issue #50080: Labels: SQL, STRUCTURED STREAMING, PYTHON
cc @viirya
Issue #50079: Labels: SQL
@cloud-fan @MaxGekk @HyukjinKwon could you please review this?
Issue #50078: Labels: SQL
Issue #50077: Labels: BUILD
cc @dongjoon-hyun @LuciferYang @cnauroth
Issue #50076: Labels: SQL, BUILD
Related benchmark results:\r\n\r\n- jdk17: https://github.com/wayneguow/spark/actions/runs/13513028574\r\n- jdk21: https://github.com/wayneguow/spark/actions/runs/13513032754
Issue #50075: Labels: SQL, BUILD, CONNECT
cc @HyukjinKwon @hvanhovell FYI
Issue #50074: Labels: SQL
cc @cloud-fan @dongjoon-hyun @HyukjinKwon, thank you
Issue #50073: Labels: SQL
cc @MaxGekk  @allisonwang-db 
Issue #50072: Labels: SQL, CORE, PYTHON
Merged to branch-4.0.
Issue #50071: Labels: SQL, CORE, PYTHON
Merged to master.
Issue #50070: Labels: SQL, CONNECT
https://github.com/LuciferYang/spark/actions/runs/13502647699/job/37724729211
Issue #50069: Labels: SQL
@MaxGekk Could you PTAL when you have time? Thanks
Issue #50068: Labels: SQL
Oh, did you aim to use this as a follow-up, @beliefer ?
Issue #50067: Labels: ML, PYTHON
thanks @LuciferYang \r\nmerged to master/4.0
Issue #50066: Labels: SQL, CONNECT
Merged to master/4.0.
Issue #50065: Labels: SQL
Merged to master/4.0, thank you @dongjoon-hyun @asl3 @HyukjinKwon 
Issue #50064: Labels: PYTHON
Merged to master and brnach-4.0.
Issue #50063: Labels: PYTHON
Merged to master and branch-4.0.
Issue #50062: Labels: DOCS, PYTHON
Merged into master and branch-4.0. Thanks @itholic @HyukjinKwon @beliefer 
Issue #50061: Labels: SQL
Thank you @dongjoon-hyun @LuciferYang, SPARK-51306 is attached.
Issue #50060: Labels: SQL
Please create an issue for track down.
Issue #50059: Labels: SQL, CONNECT
ping @HyukjinKwon @zhengruifeng @LuciferYang 
Issue #50058: Labels: INFRA
cc @dongjoon-hyun This should fix the scheduled build and make it green ðŸ‘ 
Issue #50057: Labels: BUILD, CORE
cc @dongjoon-hyun @LuciferYang 
Issue #50056: Labels: PYTHON, PANDAS API ON SPARK
Merged to master and branch-4.0.
Issue #50055: Labels: SQL, WEB UI, CORE, PYTHON
@dongjoon-hyun @cloud-fan could you let me know your thoughts about this fix? Thanks.
Issue #50054: Labels: DOCS, PYTHON
Merged to master and branch-4.0.
Issue #50053: Labels: SQL
@cloud-fan @dejankrak-db please take a look, thanks!
Issue #50052: Labels: SQL, STRUCTURED STREAMING
Hello @chenhao-db thanks for the changes, could we please get some description in the jira and the response to the PR template quetsions above? Helps a lot with understanding the context for reviewing the PR. Thanks.
Issue #50051: Labels: SQL
Issue #50050: Labels: SQL, CONNECT
ping @zhengruifeng @HyukjinKwon  @LuciferYang 
Issue #50049: Labels: SQL, MLLIB, STRUCTURED STREAMING, CORE
Merged into master. Thanks @dongjoon-hyun and @beliefer 
Issue #50048: Labels: DOCS
Please config your GA.\r\nhttps://github.com/apache/spark/pull/50048/checks?check_run_id=37647515971
Issue #50047: Labels: SQL
ping @LuciferYang cc @cloud-fan 
Issue #50046: Labels: SQL
ping @LuciferYang @MaxGekk  @cloud-fan 
Issue #50045: Labels: SQL, STRUCTURED STREAMING
Issue #50044: Labels: SQL
cc @cloud-fan @szehon-ho @amaliujia @gengliangwang @dongjoon-hyun @viirya @huaxingao 
Issue #50043: Labels: SQL
ping @dongjoon-hyun @LuciferYang 
Issue #50042: Labels: DOCS
Nice. LGTM
Issue #50041: Labels: SQL, ML, PYTHON
thanks, merged to master
Issue #50040: Labels: SQL
@dongjoon-hyun shall we include it in 3.5.5? Also cc @aokolnychyi 
Issue #50039: Labels: SQL, CONNECT
cc @cloud-fan 
Issue #50038: Labels: PYTHON
Merged to master and branch-4.0.\r\nThanks @ueshin @HyukjinKwon for the review!
Issue #50037: Labels: SQL, STRUCTURED STREAMING
thanks for the review, merging to master/4.0!
Issue #50036: Labels: SQL, DOCS, PYTHON, PANDAS API ON SPARK, CONNECT
cc @cloud-fan since this is targeting Apache Spark 4.0.0.
Issue #50035: Labels: ML, PYTHON
thanks, merged to master
Issue #50034: Labels: DOCS, PYTHON
Merged to master and branch-4.0.
Issue #50033: Labels: BUILD, YARN, CORE
I will try to write a unit test which demonstrates race condition, which can be part of the checkin..
Issue #50032: Labels: BUILD, PYTHON
Thanks! merging to master/4.0.
Issue #50031: Labels: SQL, CONNECT
@aokolnychyi @cloud-fan do you guys want to take a look, thanks!
Issue #50030: Labels: SQL, STRUCTURED STREAMING, CONNECT
There is some overlapping logic between the two types of tests that I could see if we can simplify, but HDFS state store do their snapshot upload checks a little bit differently [(see this comment)](https://github.com/apache/spark/pull/50030/files#diff-25907d502d153fb199ac2da9f8138ec0afa8b34721ec116cde0791d119c6b847R328) that makes this more difficult to combine in a clean manner.
Issue #50029: Labels: SQL, CORE
It is unclear to me why the changes to spark core are required - marking the RDD with the appropriate `DeterministicLevel` should be sufficient.
Issue #50028: Labels: SQL
thanks, merging to master/4.0!
Issue #50027: Labels: SQL
thanks, merging to master/4.0!
Issue #50026: Labels: SQL
thanks, merging to master/4.0!
Issue #50025: Labels: SQL
thanks, merging to master/4.0!
Issue #50024: Labels: SQL
cc @cloud-fan @MaxGekk 
Issue #50023: Labels: SQL, CONNECT
replaces https://github.com/apache/spark/pull/48477 with TransformingEncoder fixes.\r\n\r\nThis allows all of Frameless tests to pass when used either with the backwards compat AgnosticExpressionPathEncoder root _and_ all tests to work with the frameless AgnosticEncoder based [encoder derivation branch](https://github.com/chris-twiner/frameless/tree/temp/spark4_agnosticEncoder_reformated).\r\n\r\nOne ExpressionEncoderSuite test "transforming encoders as value class - Frameless value class as parameter use case" does not work when using a TransformingEncoder over the string field.  I\
Issue #50022: Labels: SQL
@shrprasa @wangyum @Madhukar525722 I just made it to work, would be great if you could have a test with your internal cases, I will polish the code according to the GHA result and your feedback
Issue #50021: Labels: SQL
ping @yaooqinn cc @dongjoon-hyun @LuciferYang 
Issue #50020: Labels: CORE
@mridulm / @LuciferYang - Can you please review when you get a chance ? 
Issue #50019: Labels: SQL
cc @JoshRosen and @cloud-fan 
Issue #50018: Labels: DOCS
Issue #50017: Labels: SQL, BUILD, CORE, PYTHON, CONNECT
> spark submit command builder will set some system variables for MASTER/REMOTE url, connect enablement, etc.\r\n\r\nThis is internal thing so they will have to be documented separately .. I will take a look separately.\r\n\r\n> spark session (both python and scala) will start a temp connect server for the connect api molde with local master.\r\n\r\nThis is documented here https://github.com/apache/spark/blob/master/docs/app-dev-spark-connect.md#spark-api-mode-spark-client-and-spark-classic\r\n\r\n
Issue #50016: Labels: WEB UI
Thanks @beliefer  ~
Issue #50015: Labels: SQL, STRUCTURED STREAMING
cc. @cloud-fan @viirya Would you mind taking a look? Thanks!
Issue #50014: Labels: SQL
Issue #50013: Labels: SQL, ML, MLLIB, BUILD, PYTHON, CONNECT
currently, we have a pre-training model size check, if the model to be trained seems larger, the ml server will directly fail the training.\r\n\r\nregarding model loading, it first load the model into memory, then throw error if its size is large. Probably we should also use a pre-loading model size check.
Issue #50012: Labels: SQL, CORE
cc @dongjoon-hyun Could you please take a look at this pr if you have time? Thanks ~\r\n\r\n
Issue #50011: Labels: SQL
Merging to master
Issue #50010: Labels: SQL
thanks, merging to master!
Issue #50009: Labels: SQL
thanks, merging to master!
Issue #50008: Labels: SQL
thanks, merging to 3.5/4.0/master
Issue #50007: Labels: SQL
@MaxGekk PTAL at this PR when you have time. Thanks
Issue #50006: Labels: SQL, PYTHON, CONNECT
nice!
Issue #50005: Labels: SQL, STRUCTURED STREAMING
ping @cloud-fan @MaxGekk @dongjoon-hyun 
Issue #50004: Labels: SQL
cc @sunchao @cloud-fan 
Issue #50003: Labels: ML, MLLIB
Merged to master.
Issue #50002: Labels: SQL, PYTHON
Merged to master and branch-4.0.
Issue #50001: Labels: BUILD, INFRA
Merged to master and branch-4.0.
Issue #50000: Labels: SQL, PYTHON
Merged to master and branch-4.0.
Issue #49999: Labels: SQL, PYTHON, CONNECT
@xupefei PTAL
Issue #49998: Labels: KUBERNETES
Bump :P
Issue #49997: Labels: SQL
This will need an SPIP. Please refer to https://spark.apache.org/improvement-proposals.html
Issue #49996: Labels: SQL, STRUCTURED STREAMING
@HeartSaVioR PTAL when you get a chance!
Issue #49995: Labels: SQL
cc @cloud-fan @dongjoon-hyun 
Issue #49994: Labels: SQL
+1, LGTM. Merging to master/4.0.\r\nThank you, @vladimirg-db.
Issue #49993: Labels: SQL
Please add this PR to the description of the local variables one, and also edit the description there to better explain the new approach.
Issue #49992: Labels: SQL
cc @pan3793 @LuciferYang @dongjoon-hyun \r\n\r\nBTW @dongjoon-hyun do you know how to trigger the CI job to regenerate benchmark results?
Issue #49991: Labels: SQL
+1, LGTM. Merging to master/4.0.\r\nThank you, @vladimirg-db.
Issue #49990: Labels: SQL
+1, LGTM. Merging to master/4.0.\r\nThank you, @beliefer and @cloud-fan for review.
Issue #49989: Labels: DOCS, PYTHON
Merged to master and branch-4.0.
Issue #49988: Labels: INFRA
cc @LuciferYang , because there were more changes on branch 3.5 than the master branch, I used a new jira ID.
Issue #49987: Labels: SQL
ping @MaxGekk @dongjoon-hyun @HyukjinKwon @LuciferYang  cc @yaooqinn 
Issue #49986: Labels: ML, MLLIB, BUILD, YARN, DOCS, CORE
the current approach works with `spark-submit`\r\n```\r\nspark-submit --conf spark.ml.allowNativeBlas=false ...\r\n```\r\n\r\nuser should modify their Java command options for cases that create embedded `SparkContext` in the Java app\r\n```\r\njava -Dnetlib.allowNativeBlas=false ...\r\n```\r\n
Issue #49985: Labels: SQL, STRUCTURED STREAMING
Thank you for making this PR, @HeartSaVioR .\r\n\r\nI sent an email for further discussion.\r\n- https://lists.apache.org/thread/qwxb21g5xjl7xfp4rozqmg1g0ndfw2jd
Issue #49984: Labels: SQL, STRUCTURED STREAMING, DOCS
I sent an email for further discussion\r\n- https://lists.apache.org/thread/qwxb21g5xjl7xfp4rozqmg1g0ndfw2jd
Issue #49983: Labels: SQL, STRUCTURED STREAMING, DOCS
cc. @dongjoon-hyun @HyukjinKwon Please take a look. Thanks!\r\ncc. @cloud-fan for visibility of the fix for blocker issue
Issue #49982: Labels: PYTHON
Merged to master and branch-4.0.
Issue #49981: Labels: SQL, DOCS
ping @MaxGekk @cloud-fan  cc @vitaliili-db 
Issue #49980: Labels: INFRA
If this PR works, it needs to be applied to all active branches.
Issue #49979: Labels: BUILD
Test first
Issue #49978: Labels: SQL, STRUCTURED STREAMING
@HeartSaVioR - PTAL, thx !
Issue #49977: Labels: KUBERNETES, DOCS, INFRA
Thank you, @yaooqinn ! ðŸ˜„ 
Issue #49976: Labels: DOCS
Thank you, @yaooqinn .\r\nMerged to master/4.0.
Issue #49975: Labels: DOCS, PYTHON
LGTM
Issue #49974: Labels: BUILD
Could you review this PR when you have some time, please, @panbingkun ?
Issue #49973: Labels: No Labels
cc @HyukjinKwon 
Issue #49972: Labels: BUILD
All tests passed.\r\n\r\n<img width="894" alt="Screenshot 2025-02-16 at 16 12 45" src="https://github.com/user-attachments/assets/2ce6afcf-279b-4dd7-856f-bdcc01069acc" />\r\n
Issue #49971: Labels: SQL, BUILD, CONNECT
@vicennial please see my response
Issue #49970: Labels: SQL
thanks, merging to master!
Issue #49969: Labels: PYTHON, CONNECT
cc @cloud-fan 
Issue #49968: Labels: PYTHON, CONNECT
cc @cloud-fan 
Issue #49967: Labels: BUILD
Merged into master. Thank you @dongjoon-hyun 
Issue #49966: Labels: BUILD
For the record, `Maven on Java 17` CI passed all tests.\r\n- Java 17: https://github.com/apache/spark/actions/runs/13351893254\r\n\r\n<img width="330" alt="Screenshot 2025-02-15 at 22 44 37" src="https://github.com/user-attachments/assets/cfc41c08-63d6-44d4-8580-72e6d39a362b" />\r\n
Issue #49965: Labels: SQL, PYTHON, CONNECT
and I also think about using Unix Domain Socket instead - I have a draft here: https://github.com/apache/spark/compare/master...HyukjinKwon:spark:SPARK-51156-2?expand=1 but this will likely happen in 4.1
Issue #49964: Labels: SQL, CONNECT
Issue #49963: Labels: SQL
Merged into branch-4.0/master\r\n@szehon-ho @dongjoon-hyun Thank you!
Issue #49962: Labels: SQL
I re-ran the failing test and its green on the build link, but somehow still shows red on the PR.
Issue #49961: Labels: SQL, PYTHON
cc @cloud-fan @allisonwang-db 
Issue #49960: Labels: SQL, CONNECT
@HyukjinKwon Please review
Issue #49959: Labels: SQL
Related issue in Delta: https://github.com/delta-io/delta/issues/2610\r\ncc: @cloud-fan 
Issue #49958: Labels: SQL
thanks, merging to master!
Issue #49957: Labels: SQL
ping @cloud-fan cc @andrej-db 
Issue #49956: Labels: ML, MLLIB
merged to master/4.0
Issue #49955: Labels: SQL
In talks with @cloud-fan we decided to leave the pruning and separate dealing with simple queries for a follow-up PR which will aim to optimize Recursive CTEs.
Issue #49954: Labels: SQL
Issue #49953: Labels: SQL, DOCS, PYTHON, CONNECT
LGTM
Issue #49952: Labels: BUILD
cc @pan3793 @dongjoon-hyun 
Issue #49951: Labels: ML, PYTHON
thanks, merged to master/4.0
Issue #49950: Labels: SQL
Could you re-trigger the failed test pipelines? Both failures look like flaky ones.
Issue #49949: Labels: CORE
cc @yaooqinn 
Issue #49948: Labels: SQL, ML, PYTHON, CONNECT
merged to master/4.0
Issue #49947: Labels: SQL
thanks, merging to master/4.0!
Issue #49946: Labels: SQL, BUILD, DOCS, CORE, INFRA, PYTHON, CONNECT
+1 to put the main implementation idea in the PR description.
Issue #49945: Labels: SQL, STRUCTURED STREAMING, DOCS, PYTHON
We are yet to finalize the discussion, sorry, let me make this draft.
Issue #49944: Labels: SQL, BUILD, CONNECT
Could you review this `Java option` PR when you have some time, @viirya ?
Issue #49943: Labels: CORE
All tests passed.
Issue #49942: Labels: SQL
Thank you @dongjoon-hyun !
Issue #49941: Labels: SQL, PYTHON, CONNECT
cc @HyukjinKwon 
Issue #49940: Labels: BUILD
All tests passed.
Issue #49939: Labels: BUILD
According to the release notes, it is better to go 4.0 too.\r\n\r\n> - Fixes assemblyOutputPath\r\n> - Fixes assemblyExcludedJars\r\n\r\nSpark uses these features, but I am not sure if it is affected, cc @LuciferYang you may have more context.
Issue #49938: Labels: SQL
Benchmark jdk17: https://github.com/wayneguow/spark/actions/runs/13310975547\r\nBenchmark jdk21: https://github.com/wayneguow/spark/actions/runs/13310979208
Issue #49937: Labels: SQL
Nice catch!
Issue #49936: Labels: SQL
Issue #49935: Labels: SQL
@MaxGekk @cloud-fan ptal when you have time. Thanks
Issue #49934: Labels: CORE
Yes, let me close this to prevent accidental merging. We need to discuss from `master` branch as mentioned in the above.
Issue #49933: Labels: SQL
Merged to master and branch-4.0, thank you @dongjoon-hyun 
Issue #49932: Labels: ML, PYTHON
This PR is for master-only (4.1)
Issue #49931: Labels: BUILD, DOCS
cc @HyukjinKwon 
Issue #49930: Labels: SQL, PYTHON
cc @HyukjinKwon 
Issue #49929: Labels: CORE
Merged to master, thank you @dongjoon-hyun 
Issue #49928: Labels: SQL, R
@HeartSaVioR Please review.
Issue #49927: Labels: ML, PYTHON, CONNECT
all tests passed.\r\nmerged to master/4.0
Issue #49926: Labels: PYTHON
LGTM
Issue #49925: Labels: BUILD
All K8s tests passed. Merged to master for Apache Spark 4.1.0.
Issue #49924: Labels: BUILD
cc @LuciferYang 
Issue #49923: Labels: BUILD
Could you review this PR, @LuciferYang ? Technically, there are two CVE patches here.
Issue #49922: Labels: SQL
Issue #49921: Labels: SQL, CONNECT
Issue #49920: Labels: CORE
cc @dongjoon-hyun @cloud-fan
Issue #49919: Labels: SQL, ML, PYTHON, CONNECT
All tests passed. Merged to master/4.0.
Issue #49918: Labels: SQL, ML, CONNECT
merged to master/4.0
Issue #49917: Labels: STRUCTURED STREAMING, DOCS, PYTHON, CONNECT
Merged to master and branch-4.0
Issue #49916: Labels: PYTHON
Merged to master and branch-4.0\r\nThanks @HyukjinKwon @zhengruifeng for the review.
Issue #49915: Labels: SQL
cc @gengliangwang from \r\n- #41632\r\n\r\nAlso, cc @cloud-fan as a release manager of Apache Spark 4.0.0. (Although this PR aims for all live branches, master/branch-4.0/branch-3.5).
Issue #49914: Labels: DOCS
Issue #49913: Labels: CORE
Could you review this PR when you have some time, @viirya ?
Issue #49912: Labels: SQL
Merged to branch-3.5. Thank you, @jonathan-albrecht-ibm and @MaxGekk .
Issue #49911: Labels: SQL
Probably not needed to go to 3.5..
Issue #49910: Labels: SQL, DOCS
cc @cloud-fan , @pan3793, @gene-db 
Issue #49909: Labels: BUILD
For some reason, the workflow gets forbidden (403) when uploading the image.
Issue #49908: Labels: SQL
ping @cloud-fan cc @mikhailnik-db 
Issue #49907: Labels: SQL
Merged into branch-4.0/master\r\n@cloud-fan @dongjoon-hyun @mikhailnik-db Thanks!
Issue #49906: Labels: SQL, CONNECT
cc @dongjoon-hyun, and thanks for reminding 
Issue #49905: Labels: SQL
What do we get from that deprecation procedural when we no longer have that config in very next (technically) minor release? If you think we need to follow that deprecation, this has to be there for a couple minor releases, otherwise it sounds to me just adding more work without outcome. Users do not upgrade every single version release.
Issue #49904: Labels: BUILD
Is this ready, @LuciferYang ?
Issue #49903: Labels: CORE
Merged to master.
Issue #49902: Labels: DOCS, PYTHON
Merged to master/4.0. Thank you, @zhengruifeng and @HyukjinKwon .
Issue #49901: Labels: INFRA
thanks, merged to master/4.0
Issue #49900: Labels: BUILD
cc @HyukjinKwon and @LuciferYang 
Issue #49899: Labels: BUILD
Merged to master. Thank you, @wayneguow and all!
Issue #49898: Labels: BUILD
Merged to master/4.0/3.5.
Issue #49897: Labels: SQL
Could you file a new JIRA issue for this because this should have a fix version `3.5.5`?
Issue #49896: Labels: INFRA
Merged to master and branch-4.0.
Issue #49895: Labels: SQL, CORE
Merged to master. Thank you, @ueshin and @HyukjinKwon .
Issue #49894: Labels: DOCS, CORE
Could you review this PR, @LuciferYang ?
Issue #49893: Labels: BUILD, CORE
Thank you, @cnauroth !
Issue #49892: Labels: SQL, BUILD, CONNECT
cc @HyukjinKwon @LuciferYang 
Issue #49891: Labels: BUILD
What about the Windows scripts? (I may not be able to help with that because I am not familiar with Windows scripts nor have Windows env)
Issue #49890: Labels: CORE, PYTHON
@antban Thanks for contributing. Could you create a JIRA ticket and add it to the PR title?
Issue #49889: Labels: SQL
Merged into master and branch-4.0. Thanks @beliefer and @HyukjinKwon 
Issue #49888: Labels: BUILD
cc @cloud-fan @LuciferYang 
Issue #49887: Labels: SQL
thanks, merging to master!
Issue #49886: Labels: BUILD, INFRA
cc @cloud-fan @HyukjinKwon @dongjoon-hyun @LuciferYang 
Issue #49885: Labels: BUILD, CORE, INFRA
cc @HyukjinKwon @dongjoon-hyun 
Issue #49884: Labels: BUILD, YARN
cc @HyukjinKwon 
Issue #49883: Labels: SQL
Merged to master/4.0.0\r\n\r\nThank you @dongjoon-hyun @beliefer @HyukjinKwon @zhengruifeng 
Issue #49882: Labels: ML, PYTHON, CONNECT
@dongjoon-hyun shall we get this `[ML][CONNECT]` one in 4.0? I should only affect ml connect
Issue #49881: Labels: SQL
cc @cloud-fan 
Issue #49880: Labels: SQL, PYTHON, CONNECT
(and backward compat will be tested in the scheduled build )
Issue #49879: Labels: SQL, PYTHON
cc @cloud-fan and @HyukjinKwon 
Issue #49878: Labels: CORE
Thank you, @yaooqinn .
Issue #49877: Labels: STRUCTURED STREAMING, BUILD, DSTREAM
Merged to master/4.0. Thank you again.
Issue #49876: Labels: BUILD, CORE, DSTREAM
It comes from https://github.com/apache/spark/pull/22081/files#r209707448, but after #49854 , it seems that nowhere depends on this.
Issue #49875: Labels: SQL, PYTHON
Please help review it when you have free time, thanks! @panbingkun 
Issue #49874: Labels: SQL
cc @chenhao-db, @cashmand , @gene-db , @cloud-fan 
Issue #49873: Labels: SQL, STRUCTURED STREAMING
Closing this PR as we found naming of `None` brings in naming collisions and we should keep TimeMode.None() as notime internally.
Issue #49872: Labels: DOCS
thanks, merging to master/4.0/3.5
Issue #49871: Labels: ML, MLLIB
The python side is kind of complicated (mixture of sc, connect session, classic session), I will resolve it in separate PRs
Issue #49870: Labels: CORE
Seems you can use `spark-submit --verbose ...` to rerun the failed cases to know the classpath.\r\n\r\nI think verbose error messages should help administrators diagnose the issue, but they might also scare users. Keeping the default error message clear and short, and providing a `--verbose` might be a good balance.
Issue #49869: Labels: ML, MLLIB
BTW, you also can revert directly from `branch-4.0` and push it in this case, @zhengruifeng ~
Issue #49868: Labels: BUILD
Thank you, @HyukjinKwon !
Issue #49867: Labels: SQL, STRUCTURED STREAMING, PYTHON, CONNECT
Thanks! Merging to master/4.0.
Issue #49866: Labels: SQL
Merged to branch-3.5 for Apache Spark 3.5.5. Thank you again, @jonathan-albrecht-ibm .
Issue #49865: Labels: BUILD, INFRA
cc @dongjoon-hyun @HyukjinKwon 
Issue #49864: Labels: SQL, BUILD
Issue #49863: Labels: BUILD, INFRA
also cc @cloud-fan we probably need to pin `plotly` in the release docker image
Issue #49862: Labels: SQL, ML, PYTHON, CONNECT
cc @grundprinzip and @wbo4958 
Issue #49861: Labels: ML, MLLIB
thanks, merged to master/4.0
Issue #49860: Labels: SQL, ML, CONNECT
thanks, merged to master/4.0
Issue #49859: Labels: PYTHON, PANDAS API ON SPARK, CONNECT
cc @xinrong-meng mind taking a look please? I think the plot tests fail with dependencies with different versions.
Issue #49858: Labels: CORE
If approved, can this also go into branch-3.5 please? The cherry-pick would need a minor merge conflict resolution in `FsHistoryProvider` import statements, or I can send a separate pull request.
Issue #49857: Labels: SQL
thanks, merging to master/4.0!
Issue #49856: Labels: BUILD
Merged into master. Thanks @wayneguow 
Issue #49855: Labels: BUILD, CORE, DSTREAM
It depends on upgrade of JPMML.
Issue #49854: Labels: ML, MLLIB, BUILD, DOCS
Manually exported PMML models([pmml_export_models.zip](https://github.com/user-attachments/files/18716895/pmml_export_models.zip)) between Spark 3.5.4 and the current PR:\r\n\r\n1. Kmeans\r\nSpark 3.5.4 vs Current master branch with this PR:\r\n![image](https://github.com/user-attachments/assets/96d4d196-e12e-404c-8013-52e754b020c4)\r\n\r\n2. LinearRegression\r\nSpark 3.5.4 vs Current master branch with this PR:\r\n![image](https://github.com/user-attachments/assets/2705c8bf-547c-44cf-ae44-f980dbe29b74)\r\n\r\n
Issue #49853: Labels: DOCS
The code tab switching is now working https://spark.apache.org/docs/latest/quick-start.html after the changes of this PR. Merging to master/4.0/3.5
Issue #49852: Labels: SQL
Adding @LuciferYang, @cloud-fan
Issue #49851: Labels: BUILD, INFRA
cc @dongjoon-hyun @HyukjinKwon 
Issue #49850: Labels: SQL
Adding reviewers @cloud-fan, @davidm-db, @dejankrak-db, @milastdbx, @MaxGekk 
Issue #49849: Labels: ML, MLLIB, PYTHON, CONNECT
cc @wbo4958 and @HyukjinKwon 
Issue #49848: Labels: YARN
cc @HyukjinKwon 
Issue #49847: Labels: SQL, ML, MLLIB, PYTHON
cc @HyukjinKwon and @wbo4958 
Issue #49846: Labels: INFRA
Merged to master and branch-4.0.
Issue #49845: Labels: INFRA
This is not the right fix?
Issue #49844: Labels: DOCS
merging to master/4.0/3.5
Issue #49843: Labels: SQL, CORE, PYTHON
The remaining test failures are not related to this PR.
Issue #49842: Labels: SQL, PYTHON, PANDAS API ON SPARK
linter and doc gen passed\r\n\r\nmeregd to master/4.0
Issue #49841: Labels: SQL, DOCS, PYTHON
Issue #49840: Labels: SQL
Had a chat offline with @cloud-fan who suggest simplifying the analyzeExistence to be just the following bare bones code to resolve functions.\r\n\r\n```\r\n  def fromSQL(sql: String): Expression = {\r\n    CatalystSqlParser.parseExpression(sql).transformUp {\r\n      case u: UnresolvedFunction =>\r\n          assert(u.nameParts.length == 1)\r\n          assert(!u.isDistinct)\r\n          FunctionRegistry.builtin.lookupFunction(FunctionIdentifier(u.nameParts.head), u.arguments)\r\n    }\r\n  }\r\n  ```\r\n  \r\n  Thanks for the suggestion, this simplifies it a lot.
Issue #49839: Labels: SQL, DOCS, PYTHON
LGTM thank you!
Issue #49838: Labels: DOCS
@viirya thanks for the reviews. I am merging this one to master/branch-4.0/branch-3.5
Issue #49837: Labels: SQL
Please specify that this is for single-pass Analyzer in the PR description.
Issue #49836: Labels: SQL, CONNECT
Merging to master/branch-4.0
Issue #49835: Labels: SQL
@dtenedor @cloud-fan any ideas why the SQL Parser behaves like that in the first place? I mean, I found a fix (it kinda works the same as what we do for regular queries), but not sure what causes the original problem.
Issue #49834: Labels: SQL, PYTHON, CONNECT
Merged to master and branch-4.0.
Issue #49833: Labels: SQL, CORE
Could you please help me review the code again? @MaxGekk 
Issue #49832: Labels: SQL
Please help review it when you have free time, thanks! @LuciferYang\r\ncc @cloud-fan
Issue #49831: Labels: DSTREAM
It can also reproduce locally (my computer has 12 cores , so I create create 13 DirectStream)\r\ndemo:\r\n[KafkaJobTest.txt](https://github.com/user-attachments/files/18693310/KafkaJobTest.txt)\r\n\r\n
Issue #49830: Labels: SQL, STRUCTURED STREAMING, PYTHON
Issue #49829: Labels: SQL
cc @peter-toth @gengliangwang 
Issue #49828: Labels: ML, BUILD, PYTHON, CONNECT
merged to 4.0
Issue #49827: Labels: INFRA
ohh okay you made a followup here
Issue #49826: Labels: No Labels
Although the failure should not be related to the current pr, could you please retrigger the two failed GA tasks? @RocMarshal  thanks
Issue #49825: Labels: CORE
Thank you @dongjoon-hyun 
Issue #49824: Labels: ML, BUILD, PYTHON, CONNECT
merged to master
Issue #49823: Labels: DOCS
Note: after this PR, there is still one error:\r\n```\r\nRefused to load the script \
Issue #49822: Labels: SQL, DOCS, PYTHON
Merged to master and branch-4.0 thanks!
Issue #49821: Labels: ML, BUILD, PYTHON, CONNECT
cc @HyukjinKwon would you mind taking another look?
Issue #49820: Labels: ML, PYTHON
thank you for the fix! @HyukjinKwon 
Issue #49819: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
cc @wbo4958 @HyukjinKwon 
Issue #49818: Labels: SQL, CORE, PYTHON
Tests seem passed but showing `Error: The operation was canceled.`
Issue #49817: Labels: SQL, PYTHON
Merged to master and branch-4.0.
Issue #49816: Labels: SQL, STRUCTURED STREAMING
I thought we were creating a new metric for the snapshot delta lag, not the last uploaded version? Did I miss something, why did we change this? Now we need to manually compute the lag right?
Issue #49815: Labels: SQL, STRUCTURED STREAMING
@ericm-db \r\nhttps://github.com/ericm-db/spark/actions/runs/13167171290/job/36750002304\r\n\r\nLooks like failure happens from refactored suite?
Issue #49814: Labels: CORE
This must be:\r\nhttps://github.com/sririshindra/spark/actions/runs/13162571866/job/36749883818#step:13:5783\r\n\r\n```\r\n[error] /__w/spark/spark/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClientImpl.scala:53:0: org.apache.spark.internal.config.APP_CALLER_CONTEXT is in wrong order relative to org.apache.spark.internal.config.Tests.IS_TESTING.\r\n```
Issue #49813: Labels: SQL, CONNECT
Hi @dongjoon-hyun, just wanted to check if you have some time to look at my comments above
Issue #49812: Labels: SQL
+1, LGTM. Merging to master/4.0.\r\nThank you, @jonathan-albrecht-ibm.
Issue #49811: Labels: SQL, STRUCTURED STREAMING
@HeartSaVioR, I have updated this PR to just skip the failing v1 tests on big endian platforms
Issue #49810: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
cc @wbo4958 @HyukjinKwon 
Issue #49809: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
Issue #49808: Labels: SQL
LGTM
Issue #49807: Labels: SQL
Merged to master and branch-4.0.
Issue #49806: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
merged to master/4.0
Issue #49805: Labels: DOCS
Merged to master and branch-4.0.
Issue #49804: Labels: SQL, ML, PYTHON, CONNECT
merged to master/4.0
Issue #49803: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
merged to master/4.0
Issue #49802: Labels: ML, MLLIB, PYTHON, CONNECT
merged to master/4.0
Issue #49801: Labels: SQL, CONNECT
Merging to master/4.0
Issue #49800: Labels: SQL, BUILD, DOCS, PYTHON
Merging to 4.0/master.
Issue #49799: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
merged to master/4.0
Issue #49798: Labels: ML, PYTHON, CONNECT
Merged to master and branch-4.0.
Issue #49797: Labels: SQL, PYTHON
Good point, how do you like the current approach? @ueshin 
Issue #49796: Labels: CORE
@neilramaswamy - is the PR status still WIP ? if not - lets remove that from the title ?
Issue #49795: Labels: SQL
@MaxGekk There are some cases in `column-resolution-aggregate.sql` related to group by alias but I feel uncomfortable with deleting them as they are also `column resolution` related. Should we just copy them (without deleting) to the `group-by-alias.sql` as there are not many of them?
Issue #49794: Labels: SQL
thanks, merging to master/4.0!
Issue #49793: Labels: SQL, AVRO
Issue #49792: Labels: ML, MLLIB, PYTHON
merged to master/4.0\r\n\r\nwe can fix the save/load later
Issue #49791: Labels: ML, MLLIB, PYTHON
thanks, merged to master/4.0
Issue #49790: Labels: SQL, CORE, PYTHON, R, PANDAS API ON SPARK, CONNECT
@Kimahriman FYI
Issue #49789: Labels: ML, PYTHON, CONNECT
merged to master/4.0
Issue #49788: Labels: ML, PYTHON, CONNECT
Merged to master and branch-4.0.
Issue #49787: Labels: ML, MLLIB, PYTHON
cc @wbo4958 @HyukjinKwon 
Issue #49786: Labels: SQL, PYTHON
@HyukjinKwon @ueshin would you please review? Thank you!
Issue #49785: Labels: SQL, PYTHON, CONNECT
Merging to master/4.0
Issue #49784: Labels: SQL, CORE, PYTHON
Merged to master.
Issue #49783: Labels: SQL, STRUCTURED STREAMING, CORE, PYTHON, CONNECT
Issue #49782: Labels: SQL, PYTHON, CONNECT
Thanks! merging to master/4.0.
Issue #49781: Labels: STRUCTURED STREAMING, CORE, PYTHON, CONNECT
Issue #49780: Labels: SQL
Hi, @yaooqinn . WDYT about this?
Issue #49779: Labels: CORE
@cnauroth well, you should -if you can get it anywhere into your logs, possibly as a new http header. s3afs attaches as an http referrer as it is the sole entry other than UA which goes into the standard S3 logs -and other things like to set that UA field.
Issue #49778: Labels: SQL
thanks, merging to master
Issue #49777: Labels: INFRA
Could you review this PR, @viirya , when you have some time ?
Issue #49776: Labels: SQL
cc @LuciferYang , too
Issue #49775: Labels: SQL, PYTHON
Requesting feedback from @maropu  @HyukjinKwon @imback82 @Ngone51 \r\nI will appreciate your thoughts and feedback.\r\n
Issue #49774: Labels: SQL, PYTHON, CONNECT
cc @cloud-fan as a release manager.
Issue #49773: Labels: SQL
Issue #49772: Labels: SQL, AVRO
@cloud-fan, @stefankandic, please take a look - this is just a revert of PR https://github.com/apache/spark/pull/48962, as we decided not to proceed with session level collations for now, and will do a follow up to apply object level collations for queries.
Issue #49771: Labels: ML, MLLIB, BUILD, PYTHON, CONNECT
Overall, LGTM.
Issue #49770: Labels: ML, PYTHON
merged to master/4.0
Issue #49769: Labels: SQL, STRUCTURED STREAMING, PYTHON
@neilramaswamy @HeartSaVioR - any thoughts on this before we finalize for 4.0 ?
Issue #49768: Labels: ML, PYTHON, CONNECT
merged to master/4.0
Issue #49767: Labels: SQL, ML, PYTHON, CONNECT
merged to master/4.0
Issue #49766: Labels: SQL, DOCS
What do you think about this change, @sunchao and @szehon-ho ?
Issue #49765: Labels: BUILD
Merged to master and branch-4.0.
Issue #49764: Labels: SQL, ML, PYTHON, CONNECT
merged to master/4.0
Issue #49763: Labels: ML, MLLIB, PYTHON
cc @wbo4958 @grundprinzip @HyukjinKwon 
Issue #49762: Labels: CORE
Could you review this when you have some time, @LuciferYang , please?
Issue #49761: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
@grundprinzip @wbo4958 @HyukjinKwon 
Issue #49760: Labels: SQL, ML, PYTHON, CONNECT
Let me merge this and see how it goes. The test failure should be not the real one.
Issue #49759: Labels: SQL, CONNECT
Merging to master/4.0.
Issue #49758: Labels: SQL, PYTHON
The remaining tests are not related to this PR.
Issue #49757: Labels: STRUCTURED STREAMING, PYTHON, CONNECT
@WweiL Would you mind looking at the CI build? The failure seems to be relevant.
Issue #49756: Labels: BUILD
Could you review this PR when you have some time, @LuciferYang ?
Issue #49755: Labels: SQL, CORE, PYTHON, CONNECT
@zhengruifeng : Tagging you for review as the original author of this change. \r\n@HyukjinKwon : Tagging you for review as the reviewer of the original PR. ðŸ™‚
Issue #49754: Labels: SQL, STRUCTURED STREAMING, CORE, PYTHON, CONNECT
@hvanhovell, @HyukjinKwon, and @EnricoMi, I am looking for possible reviewers for this PR. Thank you all for your time!
Issue #49753: Labels: SQL
Could you review this PR when you have some time, @viirya ?
Issue #49752: Labels: SQL
Could you review this PR, too, @huaxingao ?
Issue #49751: Labels: SQL, STRUCTURED STREAMING, PYTHON
@ericm-db - can u add the SPARK ticket in the PR title ?
Issue #49750: Labels: SQL
Why you add these test cases here?
Issue #49749: Labels: SQL, PYTHON, CONNECT
cc @zhengruifeng 
Issue #49748: Labels: CORE
Thank you, @cnauroth .
Issue #49747: Labels: SQL, STRUCTURED STREAMING
cc - @HeartSaVioR - PTAL, thx !
Issue #49746: Labels: CORE
Hi @dongjoon-hyun could you please take a look, thank you !
Issue #49745: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
Hi @zhengruifeng , Please take a look at this PR. Thx
Issue #49744: Labels: SQL, MLLIB, CORE, AVRO
This PR is ready.
Issue #49743: Labels: ML, PYTHON
Hey @zhengruifeng, Could you help review this PR, thx very much.
Issue #49742: Labels: SQL, STRUCTURED STREAMING
cc - @HeartSaVioR - PTAL, thx !
Issue #49741: Labels: SQL, MLLIB, CORE, AVRO
There are a few places to spot, but in general, when we cross check both Java 17/21. There seems to be no regression in Scala 2.13.16.
Issue #49740: Labels: SQL, BUILD
test
Issue #49739: Labels: SQL, BUILD
test
Issue #49738: Labels: SQL, STRUCTURED STREAMING, CORE, PYTHON, CONNECT
@HyukjinKwon mind merging it : ) 
Issue #49737: Labels: SQL
+1, LGTM. Merging to master/4.0.\r\nThank you, @jonathan-albrecht-ibm.
Issue #49736: Labels: SQL, BUILD
Thank you so much, @LuciferYang . I also looking at those failure.
Issue #49735: Labels: SQL
Issue #49734: Labels: SQL, PYTHON, CONNECT
Issue #49733: Labels: BUILD
Thank you, @LuciferYang !
Issue #49732: Labels: INFRA
Merged into master. Thanks @dongjoon-hyun 
Issue #49731: Labels: SQL, CONNECT
@dongjoon-hyun Here is the `branch-4.0` PR that you requested. PTAL.
Issue #49730: Labels: BUILD
Could you review this test dependency update PR when you have some time, @huaxingao ?
Issue #49729: Labels: BUILD, dependencies, java
@dependabot ignore this dependency
Issue #49728: Labels: SQL
thanks, merging to master/4.0!
Issue #49727: Labels: CORE
Thank you, @LuciferYang !
Issue #49726: Labels: SQL, DOCS
Adding reviewers: @cloud-fan, @davidm-db, @dejankrak-db, @dusantism-db, @MaxGekk
Issue #49725: Labels: BUILD, DOCS
Thank you so much, @LuciferYang .
Issue #49724: Labels: SQL
I was expecting your first point since it\
Issue #49723: Labels: CORE
Merged to master/4.0. Thank you, @LuciferYang .
Issue #49722: Labels: SQL
Could you review this PR when you have some time, @LuciferYang ? This is related to the Spark mailing list discussion about Hive usage.
Issue #49721: Labels: WEB UI
Thank you @dongjoon-hyun 
Issue #49720: Labels: SQL, PYTHON
Merged to master/4.0.
Issue #49719: Labels: BUILD, dependencies, java
@dependabot ignore this dependency
Issue #49718: Labels: CORE
Hey @HyukjinKwon @dongjoon-hyun \r\nwhen you have a moment, could you take a look at the PR?\r\nThank you!
Issue #49717: Labels: KUBERNETES
Could you review this K8s PR when you have some time, @viirya ?
Issue #49716: Labels: BUILD
Could you review this PR when you have some time, @huaxingao ?
Issue #49715: Labels: SQL, WEB UI
@cloud-fan 
Issue #49714: Labels: SQL
cc @beliefer 
Issue #49713: Labels: SQL, ML, MLLIB, STRUCTURED STREAMING, WEB UI, BUILD, SPARK SHELL, CORE, PYTHON, R, CONNECT
cc @dongjoon-hyun @cloud-fan @LuciferYang @HyukjinKwon 
Issue #49712: Labels: No Labels
Issue #49711: Labels: SQL
ping @dongjoon-hyun cc @wayneguow 
Issue #49710: Labels: BUILD, CORE, INFRA
Here is a discussion about republishing to Maven Centralï¼š\r\n- https://github.com/RoaringBitmap/RoaringBitmap/issues/749\r\n\r\nbut it seems unclear when it will be republished to Maven Central instead of just JitPack and GitHub packages. \r\n\r\nWe also have the option to wait for the republish of `RoaringBitmap` on Maven Central before proceeding with the upgrade.
Issue #49709: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
@wbo4958 @grundprinzip 
Issue #49708: Labels: SQL, CORE, PYTHON, PANDAS API ON SPARK
Issue #49707: Labels: INFRA
Let me merge this because CI result is irrelevant to this PR.\r\nMerged to master.
Issue #49706: Labels: ML, PYTHON, CONNECT
Hi @zhengruifeng please help review, thx very much.
Issue #49705: Labels: SQL
@cloud-fan could you take a look at this?
Issue #49704: Labels: ML, BUILD, PYTHON, CONNECT
The last commit just revert the previous one, and CI passed in https://github.com/zhengruifeng/spark/actions/runs/13002433261\r\n\r\nMerging to master/4.0
Issue #49703: Labels: ML, MLLIB, PYTHON, CONNECT
LGTM.
Issue #49702: Labels: ML, MLLIB, PYTHON
merged to master/4.0
Issue #49701: Labels: SQL, CONNECT
cc @dongjoon-hyun @LuciferYang @HyukjinKwon 
Issue #49700: Labels: DOCS
Thank you, @wayneguow .
Issue #49699: Labels: CORE
Merged to master and branch-4.0.
Issue #49698: Labels: INFRA
Thank you, @HyukjinKwon . Merged to master.
Issue #49697: Labels: BUILD
Could you review this PR when you have some time, @huaxingao ?
Issue #49696: Labels: SQL, ML, MLLIB, STRUCTURED STREAMING, WEB UI, BUILD, SPARK SHELL, CORE, PYTHON, R, CONNECT
cc @hvanhovell , @cloud-fan , @LuciferYang , @viirya 
Issue #49695: Labels: SQL, STRUCTURED STREAMING, BUILD, DOCS, INFRA, CONNECT
https://github.com/apache/spark/blob/aa24a9a235b1e33adf39f67b661852298b3d3bdf/.github/workflows/maven_test.yml#L197\r\n\r\n![image](https://github.com/user-attachments/assets/452d7ac9-a313-4541-b21e-00f02186a9ee)\r\n\r\n\r\nWe need to correct some parts of the maven_test.yml file, and at the same time, consider how to ensure compatibility if there are differences in code structure between the master and branch-4.0 now, as this yml file will also be used for the Maven daily test in branch-4.0.
Issue #49694: Labels: SQL, DOCS
Adding @cloud-fan @MaxGekk @srielau 
Issue #49693: Labels: ML, BUILD, PYTHON, CONNECT
Merged to master and branch-4.0.
Issue #49692: Labels: ML, MLLIB, PYTHON, CONNECT
Merged to master and branch-4.0.
Issue #49691: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
Merged to master and branch-4.0.
Issue #49690: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
merged to master/4.0
Issue #49689: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
merged to master/4.0
Issue #49688: Labels: ML, PYTHON, CONNECT
merged to master/4.0
Issue #49687: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
merged to master/4.0
Issue #49686: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
merged to master/4.0
Issue #49685: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
Merged to master/4.0
Issue #49684: Labels: DOCS
Thank you, @HyukjinKwon ! Merged to master/4.0.
Issue #49683: Labels: DOCS
Thank you, @HyukjinKwon . Merged to master/4.0/3.5.
Issue #49682: Labels: DOCS
Thank you, @HyukjinKwon . Merged to master/4.0.
Issue #49681: Labels: KUBERNETES, DOCS
Thank you, @HyukjinKwon !  Merged to master/4.0.
Issue #49680: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
thanks, merged to master/4.0
Issue #49679: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
thanks, merged to master/4.0
Issue #49678: Labels: SQL
Marking WIP, this would require some more work around event listeners and observable  due to exposure of RDD stages.
Issue #49677: Labels: SQL
ping @MaxGekk cc @dongjoon-hyun 
Issue #49676: Labels: BUILD
Issue #49675: Labels: BUILD, INFRA
Issue #49674: Labels: ML, PYTHON
Hi @zhengruifeng, Please help review it. Thx very much.
Issue #49673: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
merged to master/4.0
Issue #49672: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
thanks @LuciferYang \r\n\r\nmerged to master/4.0
Issue #49671: Labels: SQL
Issue #49670: Labels: SQL
@the-sakthi just linking the PR that addresses some issues around this error https://github.com/apache/spark/pull/48242. Due to long time it being open, github closed it. We need to make sure suggestions are aligned with this.
Issue #49669: Labels: SQL
+1, LGTM. Merging to master/4.0.\r\nThank you, @vladimirg-db.
Issue #49668: Labels: ML, MLLIB, PYTHON, CONNECT
merged to master/4.0
Issue #49667: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
merged to master/4.0
Issue #49666: Labels: ML, PYTHON, CONNECT
thanks, merged to master/4.0\r\n\r\nhas manually test locally
Issue #49665: Labels: DOCS
Thank you, @HyukjinKwon . Merged to master/4.0/3.5.
Issue #49664: Labels: ML, PYTHON, CONNECT
@zhengruifeng I guess my repo is hitting [SPARK-50864](https://issues.apache.org/jira/browse/SPARK-50864)?\r\nWhen I disabled `TorchDistributorDataLoaderUnitTests` and `TorchDistributorBaselineUnitTestsOnConnect`, tests passed.
Issue #49663: Labels: SQL
Issue #49662: Labels: SQL, STRUCTURED STREAMING, DSTREAM
https://github.com/micheal-o/spark/actions/runs/13127546346/job/36626660666\r\n\r\nCI failure is unrelated.
Issue #49661: Labels: SQL
Could you review this PR when you have some time, @huaxingao ?
Issue #49660: Labels: SQL
cc: @agubichev for review
Issue #49659: Labels: CORE
Closing, will open a new PR with logic for cogroup.
Issue #49658: Labels: SQL
Thanks @mihailotim-db and @mihailoale-db for working on this!
Issue #49657: Labels: SQL, CONNECT
Based on failed test, there may be user facing change as plan changes.
Issue #49656: Labels: STRUCTURED STREAMING, PYTHON
Thanks! Merging to master/4.0.
Issue #49655: Labels: SQL
Let me know if we could suggest something else in the error message.
Issue #49654: Labels: SQL, STRUCTURED STREAMING, DOCS
@dongjoon-hyun @HeartSaVioR Please review
Issue #49653: Labels: CORE
No problem at all~ Thank you for update, @ChenMichael .
Issue #49652: Labels: CORE
Issue #49651: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
merged to master/4.0
Issue #49650: Labels: SQL
cc @MaxGekk 
Issue #49649: Labels: ML, MLLIB, PYTHON
cc @srowen and @rebo16v
Issue #49648: Labels: ML, MLLIB, PYTHON, CONNECT
```\r\nfrom pyspark.ml.feature import *\r\n\r\ndf = spark.createDataFrame(\r\n[\r\n      (0, 3, 5.0, 0.0),\r\n      (1, 4, 5.0, 1.0),\r\n      (2, 3, 5.0, 0.0),\r\n      (0, 4, 6.0, 1.0),\r\n      (1, 3, 6.0, 0.0),\r\n      (2, 4, 6.0, 1.0),\r\n      (0, 3, 7.0, 0.0),\r\n      (1, 4, 8.0, 1.0),\r\n      (2, 3, 9.0, 0.0),\r\n],\r\nschema="input1 short, input2 int, input3 double, label double",\r\n)\r\nencoder = TargetEncoder(\r\ninputCols=["input1", "input2", "input3"],\r\noutputCols=["output", "output2", "output3"],\r\nlabelCol="label",\r\ntargetType="binary",\r\n)\r\nmodel = encoder.fit(df)\r\nmodel.write().overwrite().save("/tmp/ta")\r\nTargetEncoderModel.load("/tmp/ta")\r\n```\r\n\r\n`TargetEncoderModel.load("/tmp/ta")` fails with\r\n```\r\njava.lang.NullPointerException\r\n\tat org.apache.spark.connect.proto.FetchErrorDetailsResponse$Error$Builder.setMessage(FetchErrorDetailsResponse.java:5654)\r\n\tat org.apache.spark.sql.connect.utils.ErrorUtils$.throwableToFetchErrorDetailsResponse(ErrorUtils.scala:89)\r\n\tat org.apache.spark.sql.connect.service.SparkConnectFetchErrorDetailsHandler.$anonfun$handle$1(SparkConnectFetchErrorDetailsHandler.scala:51)\r\n\tat scala.Option.map(Option.scala:242)\r\n\tat org.apache.spark.sql.connect.service.SparkConnectFetchErrorDetailsHandler.handle(SparkConnectFetchErrorDetailsHandler.scala:44)\r\n\tat org.apache.spark.sql.connect.service.SparkConnectService.fetchErrorDetails(SparkConnectService.scala:224)\r\n\tat org.apache.spark.connect.proto.SparkConnectServiceGrpc$MethodHandlers.invoke(SparkConnectServiceGrpc.java:935)\r\n\tat org.sparkproject.connect.grpc.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)\r\n\tat org.sparkproject.connect.grpc.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:356)\r\n\tat org.sparkproject.connect.grpc.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:861)\r\n\tat org.sparkproject.connect.grpc.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\r\n\tat org.sparkproject.connect.grpc.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\n\r\n```
Issue #49647: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
merged to master/4.0
Issue #49646: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
merged to master and 4.0
Issue #49645: Labels: SQL
Thanks for the review @LuciferYang ! Will check and do the needful.
Issue #49644: Labels: ML, BUILD, PYTHON, CONNECT
Hi @zhengruifeng, Please help review it again. Thx very much\r\n
Issue #49643: Labels: SQL, ML, PYTHON, CONNECT
cc @wbo4958 
Issue #49642: Labels: ML, PYTHON, CONNECT
merged to master/4.0
Issue #49641: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
merged to master/4.0
Issue #49640: Labels: SQL, AVRO
cc @dongjoon-hyun 
Issue #49639: Labels: BUILD
Thanks @dongjoon-hyun 
Issue #49638: Labels: CORE
Thanks @dongjoon-hyun 
Issue #49637: Labels: ML, MLLIB, PYTHON, CONNECT
merged to master/4.0
Issue #49636: Labels: SQL, STRUCTURED STREAMING, PYTHON
https://github.com/bogao007/spark/actions/runs/12942132674/job/36099374376\r\nIt seems to be failing on linter.
Issue #49635: Labels: SQL, CORE, PYTHON
Oh, according to the log, `pyspark.ml.tests.connect.test_parity_torch_data_loader` seems to hang consequtively twice on this change. Is there any difference from `master` branch?\r\n- https://github.com/ueshin/apache-spark/actions/runs/12941687725/job/36098223383\r\n- https://github.com/ueshin/apache-spark/actions/runs/12943954553/job/36134941177\r\n```\r\nFinished test(python3.11): pyspark.ml.tests.connect.test_parity_regression (26s)\r\nStarting test(python3.11): pyspark.ml.tests.connect.test_parity_torch_data_loader (temp output: /__w/apache-spark/apache-spark/python/target/f869134c-ed13-471f-aa7e-37562cf80415/python3.11__pyspark.ml.tests.connect.test_parity_torch_data_loader__nrhuie5k.log)\r\nError: The operation was canceled.\r\n```
Issue #49634: Labels: SQL, PYTHON
Okay we can skip it for now
Issue #49633: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
@HyukjinKwon @wbo4958 
Issue #49632: Labels: SQL, STRUCTURED STREAMING, PYTHON
cc - @HeartSaVioR - PTAL, thx !
Issue #49631: Labels: SQL, PYTHON, PANDAS API ON SPARK, CONNECT
The remaining test failures are not related to this PR.
Issue #49630: Labels: DOCS
Discussed offline and we will close this in favor of this PR - https://github.com/apache/spark/pull/49632 Thx
Issue #49629: Labels: SQL, WEB UI, CORE, PYTHON
Issue #49628: Labels: SQL, CONNECT
@vladimirg-db Can you take a look?
Issue #49627: Labels: SQL, CONNECT
cc @cloud-fan @chenhao-db @harshmotw-db @HyukjinKwon 
Issue #49626: Labels: ML, MLLIB, PYTHON
thanks\r\nmerged to master/4.0
Issue #49625: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
cc @HyukjinKwon and @wbo4958 
Issue #49624: Labels: ML, MLLIB, PYTHON
thanks. merged to master/4.0
Issue #49623: Labels: SQL
The pyspark failure is unrelated, thanks, merging to master/4.0!
Issue #49622: Labels: SQL
LGTM
Issue #49621: Labels: SQL
thx!
Issue #49620: Labels: ML, PYTHON
merged to master/4.0
Issue #49619: Labels: SQL, CONNECT
Issue #49618: Labels: SQL, WEB UI, CORE, PYTHON
Merged to master and branch-4.0.
Issue #49617: Labels: SQL, EXAMPLES
cc @cloud-fan @dongjoon-hyun @HyukjinKwon, thank you!
Issue #49616: Labels: SQL, PYTHON, CONNECT
Merged to master and branch-4.0.
Issue #49615: Labels: ML, PYTHON
Hi @HyukjinKwon , @zhengruifeng @WeichenXu123 , please help review it. Thx a lot.
Issue #49614: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
@HyukjinKwon @wbo4958 
Issue #49613: Labels: SQL, PROTOBUF
Thanks! Merging to master/4.0.
Issue #49612: Labels: SQL, CONNECT
Merged to master and branch-4.0
Issue #49611: Labels: ML, PYTHON, CONNECT
merged to master/4.0
Issue #49610: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
Thanks, merged to master/4.0
Issue #49609: Labels: SQL, PYTHON, CONNECT
@HyukjinKwon Did you get a chance to look at the Spark Connect issue?
Issue #49608: Labels: BUILD, DOCS, CORE
Could you review this when you have some time, @viirya ?
Issue #49607: Labels: SQL
Issue #49606: Labels: CORE
cc @LuciferYang and @MaxGekk 
Issue #49605: Labels: SQL, DOCS, INFRA
Thank you @dongjoon-hyun 
Issue #49604: Labels: BUILD, DOCS
Merging master/4.0
Issue #49603: Labels: SQL
Since the failure looks like a flaky one, could you simply re-trigger the failed test pipeline, @stefankandic ?\r\n```\r\n[info] SparkSessionE2ESuite:\r\n[info] - interrupt all - background queries, foreground interrupt (219 milliseconds)\r\n[info] - interrupt all - foreground queries, background interrupt (311 milliseconds)\r\n[info] - interrupt all - streaming queries (390 milliseconds)\r\n[info] - interrupt tag !!! IGNORED !!!\r\n[info] - interrupt tag - streaming query (714 milliseconds)\r\n[info] - progress is available for the spark result (3 seconds, 866 milliseconds)\r\n[info] *** Test still running after 5 minutes, 49 seconds: suite name: SparkSessionE2ESuite, test name: interrupt operation. \r\n[info] *** Test still running after 10 minutes, 49 seconds: suite name: SparkSessionE2ESuite, test name: interrupt operation. \r\n[info] *** Test still running after 15 minutes, 49 seconds: suite name: SparkSessionE2ESuite, test name: interrupt operation. \r\n[info] *** Test still running after 20 minutes, 49 seconds: suite name: SparkSessionE2ESuite, test name: interrupt operation. \r\n[info] *** Test still running after 25 minutes, 49 seconds: suite name: SparkSessionE2ESuite, test name: interrupt operation. \r\n[info] *** Test still running after 30 minutes, 49 seconds: suite name: SparkSessionE2ESuite, test name: interrupt operation. \r\n[info] *** Test still running after 35 minutes, 49 seconds: suite name: SparkSessionE2ESuite, test name: interrupt operation. \r\n[info] *** Test still running after 40 minutes, 49 seconds: suite name: SparkSessionE2ESuite, test name: interrupt operation. \r\n[info] *** Test still running after 45 minutes, 49 seconds: suite name: SparkSessionE2ESuite, test name: interrupt operation. \r\n[info] *** Test still running after 50 minutes, 49 seconds: suite name: SparkSessionE2ESuite, test name: interrupt operation. \r\n[info] *** Test still running after 55 minutes, 49 seconds: suite name: SparkSessionE2ESuite, test name: interrupt operation. \r\n[info] *** Test still running after 1 hour, 49 seconds: suite name: SparkSessionE2ESuite, test name: interrupt operation. \r\n[info] *** Test still running after 1 hour, 5 minutes, 49 seconds: suite name: SparkSessionE2ESuite, test name: interrupt operation. \r\n[info] *** Test still running after 1 hour, 10 minutes, 49 seconds: suite name: SparkSessionE2ESuite, test name: interrupt operation. \r\n[info] *** Test still running after 1 hour, 15 minutes, 49 seconds: suite name: SparkSessionE2ESuite, test name: interrupt operation. \r\n[info] *** Test still running after 1 hour, 20 minutes, 49 seconds: suite name: SparkSessionE2ESuite, test name: interrupt operation. \r\n```
Issue #49602: Labels: SQL
I used a little bit diff approach :-). Thanks for comments.
Issue #49601: Labels: SQL, ML, MLLIB, CONNECT
will add more tests if this approach is in general fine
Issue #49600: Labels: ML, MLLIB, PYTHON
merged to master/4.0
Issue #49599: Labels: CORE
cc @HyukjinKwon @dongjoon-hyun FYI\r\n
Issue #49598: Labels: SQL, PYTHON, CONNECT
Also cc @MaxGekk fyi
Issue #49597: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
merged to master/4.0
Issue #49596: Labels: ML, BUILD, PYTHON, CONNECT
thanks. merged to master/4.0
Issue #49595: Labels: ML, PYTHON, CONNECT
Merged to master and branch-4.0.
Issue #49594: Labels: SQL, DOCS, PYTHON, CONNECT
Merged to master and branch-4.0.\r\n\r\nThanks @HyukjinKwon for the review!
Issue #49593: Labels: PYTHON, PANDAS API ON SPARK, CONNECT
Merged to master and branch-4.0.
Issue #49592: Labels: SQL, CORE, PYTHON
@LuciferYang Thanks for the fix! Let me merge it and rerun tests.
Issue #49591: Labels: SQL, PYTHON, CONNECT
Merged to master and branch-4.0.
Issue #49590: Labels: SQL, AVRO
Thanks, merging to master!
Issue #49589: Labels: CORE
I hope to backport this fix to branch-3.5, as I encountered similar test failures in the daily tests of branch-3.5:\r\n- https://github.com/apache/spark/actions/runs/12885594112/job/35924424737\r\n\r\n![image](https://github.com/user-attachments/assets/87eb8337-b848-4baf-ab95-a0de196772c1)\r\n\r\n\r\ncc @dongjoon-hyun @yaooqinn 
Issue #49588: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
merged to master/4.0
Issue #49587: Labels: SQL
Could you review this PR, @LuciferYang ?
Issue #49586: Labels: SQL
+1, LGTM. Merging to master/4.0.\r\nThank you, @stefankandic.
Issue #49585: Labels: SQL
thanks, merging to master/4.0!
Issue #49584: Labels: SQL, CONNECT
@xi-db FYI\r\n@hvanhovell\r\nHi, can you review this PR when you have time?\r\n* Plans are *not* cached during transformation.\r\n* Plans are cached once after data frames are created (after analysis).\r\n* The number of cache get/put calls stays the same; only the timing was adjusted.\r\nThanks!
Issue #49583: Labels: SQL, DOCS, PYTHON
cc @HyukjinKwon 
Issue #49582: Labels: KUBERNETES, CORE
Could you review this PR, @yaooqinn ?
Issue #49581: Labels: SQL, ML, MLLIB, BUILD, PYTHON, CONNECT
cc @wbo4958 @HyukjinKwon 
Issue #49580: Labels: SQL, CONNECT
thanks, merged to master/4.0
Issue #49579: Labels: SQL, ML, MLLIB, BUILD, PYTHON, CONNECT
cc @wbo4958 
Issue #49578: Labels: INFRA
Thank you, @zhengruifeng . Merged to master.
Issue #49577: Labels: SQL, ML, CONNECT
Hi @grundprinzip, I created a jira for this PR, https://issues.apache.org/jira/browse/SPARK-50897, if possible, please change the title  to [SPARK-50897]
Issue #49576: Labels: SQL
@MaxGekk I have created a separate PR to unblock the test that is failing in the collation expression walker suite #49586.
Issue #49575: Labels: BUILD
The failed yarn test is unrelated, merging to master/4.0!
Issue #49574: Labels: SQL, PYTHON, CONNECT
Merged to master and branch-4.0.
Issue #49573: Labels: SQL
- A bad case\r\nhttps://github.com/apache/spark/blob/620f55262cab75485f4e1ee5d85dd24ab8a4c1aa/sql/core/src/test/scala/org/apache/spark/sql/DataFrameTimeWindowingSuite.scala#L165-L196\r\n\r\n- codegen code (when it triggers the `split` expression)\r\n```scala\r\n/* 001 */ public Object generate(Object[] references) {\r\n/* 002 */   return new GeneratedIteratorForCodegenStage1(references);\r\n/* 003 */ }\r\n/* 004 */\r\n/* 005 */ // codegenStageId=1\r\n/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\r\n/* 007 */   private Object[] references;\r\n/* 008 */   private scala.collection.Iterator[] inputs;\r\n/* 009 */   private boolean hashAgg_initAgg_0;\r\n/* 010 */   private org.apache.spark.unsafe.KVIterator hashAgg_mapIter_0;\r\n/* 011 */   private org.apache.spark.sql.execution.UnsafeFixedWidthAggregationMap hashAgg_hashMap_0;\r\n/* 012 */   private org.apache.spark.sql.execution.UnsafeKVExternalSorter hashAgg_sorter_0;\r\n/* 013 */   private scala.collection.Iterator localtablescan_input_0;\r\n/* 014 */   private boolean expand_resultIsNull_0;\r\n/* 015 */   private long filter_subExprValue_0;\r\n/* 016 */   private boolean filter_subExprIsNull_0;\r\n/* 017 */   private long filter_subExprValue_1;\r\n/* 018 */   private boolean filter_subExprIsNull_1;\r\n/* 019 */   private long filter_subExprValue_2;\r\n/* 020 */   private boolean filter_subExprIsNull_2;\r\n/* 021 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[15];\r\n/* 022 */   private InternalRow[] expand_mutableStateArray_0 = new InternalRow[1];\r\n/* 023 */\r\n/* 024 */   public GeneratedIteratorForCodegenStage1(Object[] references) {\r\n/* 025 */     this.references = references;\r\n/* 026 */   }\r\n/* 027 */\r\n/* 028 */   public void init(int index, scala.collection.Iterator[] inputs) {\r\n/* 029 */     partitionIndex = index;\r\n/* 030 */     this.inputs = inputs;\r\n/* 031 */     wholestagecodegen_init_0_0();\r\n/* 032 */     wholestagecodegen_init_0_1();\r\n/* 033 */\r\n/* 034 */   }\r\n/* 035 */\r\n/* 036 */   private void wholestagecodegen_init_0_1() {\r\n/* 037 */     filter_mutableStateArray_0[8] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(filter_mutableStateArray_0[7], 2);\r\n/* 038 */     filter_mutableStateArray_0[9] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);\r\n/* 039 */     filter_mutableStateArray_0[10] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(filter_mutableStateArray_0[9], 2);\r\n/* 040 */     filter_mutableStateArray_0[11] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);\r\n/* 041 */     filter_mutableStateArray_0[12] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(filter_mutableStateArray_0[11], 2);\r\n/* 042 */     filter_mutableStateArray_0[13] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);\r\n/* 043 */     filter_mutableStateArray_0[14] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(filter_mutableStateArray_0[13], 2);\r\n/* 044 */\r\n/* 045 */   }\r\n/* 046 */\r\n/* 047 */   private void wholestagecodegen_init_0_0() {\r\n/* 048 */     localtablescan_input_0 = inputs[0];\r\n/* 049 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 64);\r\n/* 050 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);\r\n/* 051 */     filter_mutableStateArray_0[2] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);\r\n/* 052 */     expand_resultIsNull_0 = true;\r\n/* 053 */     expand_mutableStateArray_0[0] = null;\r\n/* 054 */     filter_mutableStateArray_0[3] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 64);\r\n/* 055 */     filter_mutableStateArray_0[4] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(filter_mutableStateArray_0[3], 2);\r\n/* 056 */     filter_mutableStateArray_0[5] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 64);\r\n/* 057 */     filter_mutableStateArray_0[6] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(filter_mutableStateArray_0[5], 2);\r\n/* 058 */     filter_mutableStateArray_0[7] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);\r\n/* 059 */\r\n/* 060 */   }\r\n/* 061 */\r\n/* 062 */   private void filter_subExpr_0(boolean expand_resultIsNull_0, org.apache.spark.sql.catalyst.InternalRow expand_mutableStateArray_0[0]) {\r\n/* 063 */     // 1...\r\n/* 064 */     boolean filter_isNull_11 = expand_resultIsNull_0;\r\n/* 065 */     long filter_value_12 = -1L;\r\n/* 066 */\r\n/* 067 */     if (!expand_resultIsNull_0) {\r\n/* 068 */       if (expand_mutableStateArray_0[0].isNullAt(0)) {\r\n/* 069 */         filter_isNull_11 = true;\r\n/* 070 */       } else {\r\n/* 071 */         filter_value_12 = expand_mutableStateArray_0[0].getLong(0);\r\n/* 072 */       }\r\n/* 073 */\r\n/* 074 */     }\r\n/* 075 */     // 2...\r\n/* 076 */     filter_subExprIsNull_0 = filter_isNull_11;\r\n/* 077 */     // 3...\r\n/* 078 */     filter_subExprValue_0 = filter_value_12;\r\n/* 079 */   }\r\n/* 080 */\r\n/* 081 */   protected void processNext() throws java.io.IOException {\r\n/* 082 */     if (!hashAgg_initAgg_0) {\r\n/* 083 */       hashAgg_initAgg_0 = true;\r\n\r\n```\r\n\r\n- CodeGenerator##getLocalInputVariableValues\r\n(It seems that there is no good support for array type variables.)\r\n<img width="910" alt="image" src="https://github.com/user-attachments/assets/e5d54cfe-9c55-4340-aa7d-111ee6c91e54" />\r\n\r\n- If I adjust the `spark.sql.codegen.methodSplitThreshold` value to be larger, this case can pass (I understand that it directly uses `global variables` instead of `splitting multiple functions`)\r\nval needSplit = nonSplitCode.map(_.eval.code.length).sum > SQLConf.get.methodSplitThreshold\r\n\r\n
Issue #49572: Labels: SQL, DOCS, PYTHON
Merged to master and created separate PR for branch-4.0: https://github.com/apache/spark/pull/49583.\r\n\r\nThanks @HyukjinKwon for the review.
Issue #49571: Labels: SQL
I went through the outputs of all golden files tests and compared them with the outputs of the same (or syntactically slightly adapted) queries in Snowflake and PostgreSQL engines. All the outputs match.
Issue #49570: Labels: SQL, ML, MLLIB, BUILD, PYTHON, CONNECT
merged to master/4.0
Issue #49569: Labels: SQL, ML, MLLIB, CONNECT
Hi @grundprinzip, Could you help review this PR, so with PR, all the spark ml operators will be "loaded" by ServiceLoader.
Issue #49568: Labels: SQL
LGTM
Issue #49567: Labels: SQL, ML, MLLIB, BUILD, PYTHON, CONNECT
thanks\r\n\r\nmerged to master/4.0
Issue #49566: Labels: ML, MLLIB, PYTHON
cc @wbo4958 @HyukjinKwon 
Issue #49565: Labels: PYTHON, PANDAS API ON SPARK, CONNECT
Merged to master and branch-4.0.
Issue #49564: Labels: SQL, BUILD, DOCS
cc @wangyum 
Issue #49563: Labels: SQL, BUILD, DOCS, AVRO
cc @LuciferYang 
Issue #49562: Labels: BUILD
Issue #49561: Labels: DOCS
+1, LGTM. Merging to master/4.0.\r\nThank you, @camilesing and @HyukjinKwon for review.
Issue #49560: Labels: SQL, STRUCTURED STREAMING, BUILD, PYTHON, CONNECT
@hvanhovell Please take a look at this PR if you have time. I think this is simpler than Scala PR and many things are following the existing practice with applyInPandasWithState. Thanks in advance!
Issue #49559: Labels: SQL
@MaxGekk I updated the PR
Issue #49558: Labels: SQL
Hi, @nikolamand-db , @cloud-fan . \r\nAlthough I know that this is a valuable test suite for Collation feature, can we exclude this long-running query (14+ minutes) from the CIs?
Issue #49557: Labels: SQL
cc @nemanjapetr-db  @MaxGekk 
Issue #49556: Labels: SQL
ping @cloud-fan cc @sunxiaoguang 
Issue #49555: Labels: SQL
ping @cloud-fan cc @sunxiaoguang 
Issue #49554: Labels: SQL, PYTHON
cc @stefankandic and @dejankrak-db to take a look.
Issue #49553: Labels: SQL, ML, MLLIB, BUILD, PYTHON, CONNECT
@wbo4958 @HyukjinKwon @WeichenXu123 
Issue #49552: Labels: SQL, BUILD, DOCS
Merged to master/4.0. Thank you, @LuciferYang .
Issue #49551: Labels: SQL
Merged to master/4.0. Thank you, @yaooqinn .
Issue #49550: Labels: BUILD
Merged to master and branch-4.0.
Issue #49549: Labels: SQL
@cloud-fan FYI
Issue #49548: Labels: BUILD
Test first
Issue #49547: Labels: SQL, ML, MLLIB, BUILD, PYTHON, CONNECT
Merged to master/4.0
Issue #49546: Labels: CORE
Merged into master for Spark 4.1.0. Thanks @dongjoon-hyun and @MaxGekk 
Issue #49545: Labels: SQL, BUILD, CONNECT
I have checked locally and it is safe to merge this PR at the moment.\r\n\r\n
Issue #49544: Labels: INFRA
I wonder if 2 hours is too short ....
Issue #49543: Labels: SQL, ML, CORE, PYTHON, AVRO, CONNECT, PROTOBUF
merged to master/4.0
Issue #49542: Labels: BUILD, INFRA
Issue #49541: Labels: INFRA
cc @dongjoon-hyun 
Issue #49540: Labels: INFRA
Issue #49539: Labels: ML, PYTHON, CONNECT
I disable two tests based on my local test, if the remaining ones are still slow in GA, I will disable more
Issue #49538: Labels: SQL, BUILD
Thank you!
Issue #49537: Labels: BUILD
Issue #49536: Labels: SQL
cc: @agubichev 
Issue #49535: Labels: SQL, CORE, PYTHON
@HyukjinKwon I agree, and this PR is just to make it configurable (with the default value set to **false** - show stack trace by default). There are many user-friendly errors on the Python side, but they are often buried in a long Python-side stack trace. This change is intended to optionally hide these stack traces to improve the user experience.
Issue #49534: Labels: INFRA
Merged to master and branch-4.0.
Issue #49533: Labels: BUILD
Hi, @huaxingao . Could you review this PR?
Issue #49532: Labels: SQL, STRUCTURED STREAMING, PYTHON
cc @HyukjinKwon 
Issue #49531: Labels: CORE
cc @mridulm 
Issue #49530: Labels: INFRA
Could you review this PR to help Apache Spark 4.0 Java 21 test coverage, @huaxingao ?
Issue #49529: Labels: SQL, ML, MLLIB, PYTHON, CONNECT
cc @wbo4958 @HyukjinKwon @WeichenXu123 
Issue #49528: Labels: SQL, DOCS
@MaxGekk thanks for the comments, all addressed in [a03345c0](https://github.com/G-Research/spark/commit/a03345c001f3e58ae80e21abd85b3806e251017d).
Issue #49527: Labels: INFRA
Contrast to https://github.com/apache/spark/pull/49507, it is a relatively clean PR.
Issue #49526: Labels: SQL
CIs finished. @MaxGekk @cloud-fan could we merge it?
Issue #49525: Labels: SQL, ML, MLLIB, BUILD, PYTHON, CONNECT
cc @wbo4958 
Issue #49524: Labels: ML, PYTHON, CONNECT
Merged to master and branch-4.0
Issue #49523: Labels: SQL, STRUCTURED STREAMING
cc @HeartSaVioR @WweiL @dongjoon-hyun @HyukjinKwon 
Issue #49522: Labels: ML, PYTHON, CONNECT
It didn\
Issue #49521: Labels: SQL
Issue #49520: Labels: SQL, CONNECT, PROTOBUF
Merged to master and branch-4.0.
Issue #49519: Labels: PYTHON, CONNECT
Merged to master and branch-4.0.
Issue #49518: Labels: SQL
The whole checkRecursion logic is now rewritten and placed in ResolveWithCTE as discussed offline. \r\nOne note here: I am still not sure if we should keep datatype check since it throws an error already before coming to this part of the code in case data types of anchor and recursive part are different. Also, still not sure which equality check between data types should be used
Issue #49517: Labels: INFRA
Thank you, @LuciferYang . Merged to master.
Issue #49516: Labels: INFRA
Could you review this follow-up, @huaxingao , please?
Issue #49515: Labels: INFRA
Thank you, @huaxingao .\r\n\r\nMerged to master.
Issue #49514: Labels: INFRA
Thank you, @huaxingao !
Issue #49513: Labels: SQL
thanks, merging to master/4.0!
Issue #49512: Labels: INFRA
Thank you, @LuciferYang .\r\n\r\nMerged to master.
Issue #49511: Labels: INFRA
Thank you, @huaxingao !\r\n\r\nMerged to branch-4.0
Issue #49510: Labels: SQL
cc @stefankandic and @dejankrak-db 
Issue #49509: Labels: SQL
LGTM.
Issue #49508: Labels: SQL, ML, MLLIB, CORE
Merged to master/4.0. Thank you, @Ngone51 and all.
Issue #49507: Labels: INFRA
cc @dongjoon-hyun @HyukjinKwon @zhengruifeng @LuciferYang \r\nCould you take a look? I want to try this approach.\r\nThanks!
Issue #49506: Labels: SQL
cc @cloud-fan 
Issue #49505: Labels: SQL
@MaxGekk please take a look when you get the chance
Issue #49504: Labels: ML, DOCS, PYTHON, CONNECT
merged to master
Issue #49503: Labels: SQL, ML, CONNECT
Will merge as soon as the CI passed.
Issue #49502: Labels: INFRA
cc @dongjoon-hyun and @LuciferYang, sorry for missing that.
Issue #49501: Labels: SQL
@Ngone51 the new test failed
Issue #49500: Labels: PYTHON
let me trigger the core test ..
Issue #49499: Labels: BUILD, INFRA
hardcode + empty file: https://github.com/panbingkun/spark/actions/runs/12782585262/job/35632373115\r\nhardcode(success): https://github.com/panbingkun/spark/runs/35636937617\r\nenv(fail): https://github.com/panbingkun/spark/runs/35636874980
Issue #49498: Labels: BUILD, CORE
Issue #49497: Labels: SQL, PYTHON, CONNECT
Thank you, @LuciferYang .
Issue #49496: Labels: PYTHON
Merged to master.
Issue #49495: Labels: SQL, MLLIB, STRUCTURED STREAMING, KUBERNETES, GRAPHX, BUILD, SPARK SHELL, YARN, EXAMPLES, DOCS, CORE, INFRA, PYTHON, R, DSTREAM, AVRO, CONNECT, PROTOBUF
cc @cloud-fan and @HyukjinKwon 
Issue #49494: Labels: DEPLOY, BUILD, DOCS, CORE, WINDOWS, INFRA, PYTHON
Merged to master.
Issue #49493: Labels: SQL
cc @viirya @huaxingao @cloud-fan @allisonwang-db @rdblue @dongjoon-hyun
Issue #49492: Labels: DOCS
@dongjoon-hyun @parthchandra @LuciferYang would you please take a look at this PR?
Issue #49491: Labels: CORE
This is a follow-up for https://github.com/apache/spark/pull/49399.
Issue #49490: Labels: SQL, STRUCTURED STREAMING, PYTHON
thanks, merged to master
Issue #49489: Labels: SQL, STRUCTURED STREAMING
Issue #49488: Labels: SQL, STRUCTURED STREAMING, CONNECT
Is the CI failure related - https://github.com/jingz-db/spark/actions/runs/12837471455/job/35801692179 ?
Issue #49487: Labels: SQL, PYTHON, CONNECT
@HyukjinKwon @cloud-fan Can you look at this?
Issue #49486: Labels: DOCS
cc @MaxGekk as I believe you have recently reviewed similar doc PRs.
Issue #49485: Labels: SQL
Adding @cloud-fan @srielau @davidm-db @dusantism-db 
Issue #49484: Labels: SQL, CONNECT
Merged to master.
Issue #49483: Labels: DOCS
SPARK-46094 added the JVM profiler but limited the scope to executor-only, and all classes and configurations are located under the "executor" namespace, it looks a little bit weird if we accept this PR to extend the scope also cover the driver.\r\n\r\nAdditionally, Spark already has the following configurations for profiling Python process\r\n\r\n- `spark.python.profile`\r\n- `spark.python.profile.memory`\r\n- `spark.python.profile.dump`\r\n\r\nGiven that, I propose the following changes:\r\n\r\n- rename `ExecutorProfilerPlugin` to `ProfilerPlugin`(or `JVMProfilerPlugin`)\r\n- move classes to `org.apache.spark.profile`(`profile` or `profiler`) package\r\n- move configuration to `spark.profile.`(or `spark.jvm.profile.`) namespace\r\n\r\nthen the configurations might like\r\n\r\n```\r\nspark.profile.driver.enabled\r\nspark.profile.executor.enabled\r\nspark.profile.executor.fraction\r\nspark.profile.dfsDir\r\nspark.profile.local\r\nspark.profile.options\r\nspark.profile.writeInterval\r\n```\r\n\r\nsome thoughts:\r\n\r\n- `spark.profile.` vs `spark.jvm.profile.`, I prefer the former because 1) JVM is the main process of Spark that we don\
Issue #49482: Labels: SQL, ML, DOCS, PYTHON, CONNECT
Gentle ping, @xinrong-meng .\r\n\r\nIf this is targeting Apache Spark 4.0, we had better have this before February 1st.\r\n- https://spark.apache.org/versioning-policy.html
Issue #49481: Labels: SQL
same with SPARK-50793, closed
Issue #49480: Labels: BUILD, DOCS, INFRA
maybe I should convert the purpose of this PR to "Enable SBT CI for profiler module"
Issue #49479: Labels: CORE
+CC @HeartSaVioR (who reviewed #29149), thanks !
Issue #49478: Labels: BUILD, DOCS
FYI, @LuciferYang and @panbingkun 
Issue #49477: Labels: INFRA
@zhengruifeng @LuciferYang @dongjoon-hyun @HyukjinKwon \r\nCould you take a quick look? I want to merge it quickly and verify that this approach is feasible.\r\nThanks!
Issue #49476: Labels: CORE
Merged to master for Apache Spark 4.0.0.\r\nI manually tested. \r\n\r\n```\r\n$ build/sbt "core/testOnly org.apache.spark.deploy.history.*"\r\n...\r\n[info] RollingEventLogFilesWriterSuite:\r\n[info] - create EventLogFileWriter with enable/disable rolling (184 milliseconds)\r\n[info] - initialize, write, stop - with codec None (73 milliseconds)\r\n[info] - initialize, write, stop - with codec Some(lz4) (176 milliseconds)\r\n[info] - initialize, write, stop - with codec Some(lzf) (39 milliseconds)\r\n[info] - initialize, write, stop - with codec Some(snappy) (157 milliseconds)\r\n[info] - initialize, write, stop - with codec Some(zstd) (44 milliseconds)\r\n[info] - Use the default value of spark.eventLog.compression.codec (5 milliseconds)\r\n[info] - Event log names (1 millisecond)\r\n[info] - Log overwriting (38 milliseconds)\r\n[info] - rolling event log files - codec None (177 milliseconds)\r\n[info] - rolling event log files - codec Some(lz4) (95 milliseconds)\r\n[info] - rolling event log files - codec Some(lzf) (92 milliseconds)\r\n[info] - rolling event log files - codec Some(snappy) (87 milliseconds)\r\n[info] - rolling event log files - codec Some(zstd) (91 milliseconds)\r\n[info] - rolling event log files - the max size of event log file size less than lower limit (6 milliseconds)\r\n[info] RocksDBBackendChromeUIHistoryServerSuite:\r\n[info] LevelDBBackendChromeUIHistoryServerSuite:\r\n[info] LevelDBBackendFsHistoryProviderSuite:\r\n[info] RocksDBBackendWithProtobufSerializerSuite:\r\n[info] - Parse application logs (inMemory = true) (196 milliseconds)\r\n[info] - Parse application logs (inMemory = false) (779 milliseconds)\r\n[info] - SPARK-31608: parse application logs with HybridStore (297 milliseconds)\r\n[info] - SPARK-41685: Verify the configurable serializer for history server (2 milliseconds)\r\n[info] - SPARK-3697: ignore files that cannot be read. (79 milliseconds)\r\n[info] - history file is renamed from inprogress to completed (70 milliseconds)\r\n[info] - SPARK-39439: Check final file if in-progress event log file does not exist (62 milliseconds)\r\n[info] - Parse logs that application is not started (57 milliseconds)\r\n[info] - SPARK-5582: empty log directory (59 milliseconds)\r\n[info] - apps with multiple attempts with order (426 milliseconds)\r\n[info] - log urls without customization (225 milliseconds)\r\n[info] - custom log urls, including FILE_NAME (151 milliseconds)\r\n[info] - custom log urls, excluding FILE_NAME (157 milliseconds)\r\n[info] - custom log urls with invalid attribute (161 milliseconds)\r\n[info] - custom log urls, LOG_FILES not available while FILE_NAME is specified (164 milliseconds)\r\n[info] - custom log urls, app not finished, applyIncompleteApplication: true (176 milliseconds)\r\n[info] - custom log urls, app not finished, applyIncompleteApplication: false (188 milliseconds)\r\n[info] - log cleaner (73 milliseconds)\r\n[info] - should not clean inprogress application with lastUpdated time less than maxTime (69 milliseconds)\r\n[info] - log cleaner for inProgress files (62 milliseconds)\r\n[info] - Event log copy (67 milliseconds)\r\n[info] - driver log cleaner (9 milliseconds)\r\n[info] - SPARK-8372: new logs with no app ID are ignored (56 milliseconds)\r\nOpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended\r\n[info] - provider correctly checks whether fs is in safe mode (724 milliseconds)\r\n[info] - provider waits for safe mode to finish before initializing (88 milliseconds)\r\n[info] - provider reports error after FS leaves safe mode (106 milliseconds)\r\n[info] - ignore hidden files (89 milliseconds)\r\n[info] - support history server ui admin acls (482 milliseconds)\r\n[info] - mismatched version discards old listing (149 milliseconds)\r\n[info] - invalidate cached UI (245 milliseconds)\r\n[info] - clean up stale app information (181 milliseconds)\r\n[info] - SPARK-21571: clean up removes invalid history files (63 milliseconds)\r\n[info] - always find end event for finished apps (66 milliseconds)\r\n[info] - parse event logs with optimizations off (60 milliseconds)\r\n[info] - SPARK-24948: ignore files we don\
Issue #49475: Labels: SQL, PYTHON
`sql` module passed. Merged to master.
Issue #49474: Labels: SQL, CONNECT
Merged to master.
Issue #49473: Labels: SQL, PROTOBUF
@HyukjinKwon I change the way the bug is fixed based on your comment.
Issue #49472: Labels: SQL, PYTHON
Merged to master. Thank you!
Issue #49471: Labels: SQL
cc @cloud-fan @srielau 
Issue #49470: Labels: SQL
Issue #49469: Labels: SQL
The last similar change was made on SPARK-37256 | https://issues.apache.org/jira/browse/SPARK-37256
Issue #49468: Labels: SQL
CIs passed. We can merge it.
Issue #49467: Labels: KUBERNETES
gentle ping @yaooqinn @wangyum 
Issue #49466: Labels: SQL
@asl3 @dongjoon-hyun 
Issue #49465: Labels: INFRA
thanks @panbingkun so much!
Issue #49464: Labels: BUILD
I think we should spend some time to pick which versions to use in the CI.
Issue #49463: Labels: SQL, PYTHON
thanks, merged to master
Issue #49462: Labels: INFRA
closing in favor of https://github.com/apache/spark/pull/49527
Issue #49461: Labels: SQL
Could you review this too, @LuciferYang ?
Issue #49460: Labels: SQL
The test failure is unrelated, thanks, merging to master!
Issue #49459: Labels: SQL
Thank you, @LuciferYang . Merged to master.
Issue #49458: Labels: SQL
cc @jovanm-db and @cloud-fan 
Issue #49457: Labels: SQL
cc @ostronaut and @cloud-fan 
Issue #49456: Labels: BUILD
Merged into master for Spark 4.0. Thanks @dongjoon-hyun 
Issue #49455: Labels: SQL, DOCS
thanks, merging to master!
Issue #49454: Labels: BUILD
All maven test passed: https://github.com/LuciferYang/spark/runs/35474430380\r\n\r\n![image](https://github.com/user-attachments/assets/079eed98-82c3-4bfe-b42f-358182b7551d)\r\n
Issue #49453: Labels: SQL
cc @yaooqinn 
Issue #49452: Labels: SQL
Can you provide your take on this:\r\n> My understanding is that this never produced any kind of results that customers could have adapted to - hence flag is not required. Is this your understanding as well ?
Issue #49451: Labels: SQL, STRUCTURED STREAMING
```\r\n[info] - get, put, remove, commit, and all data iterator - with codec lz4 - with colFamiliesEnabled=true *** FAILED *** (157 milliseconds)\r\n[info]   "[CANNOT_LOAD_STATE_STORE.UNCATEGORIZED] An error occurred during loading state.  SQLSTATE: 58030" did not contain "does not exist" (StateStoreSuite.scala:1124)\r\n[info]   org.scalatest.exceptions.TestFailedException:\r\n[info]   at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:472)\r\n[info]   at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:471)\r\n[info]   at org.scalatest.Assertions$.newAssertionFailedException(Assertions.scala:1231)\r\n[info]   at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:1295)\r\n[info]   at org.apache.spark.sql.execution.streaming.state.StateStoreSuiteBase.$anonfun$new$100(StateStoreSuite.scala:1124)\r\n[info]   at org.apache.spark.sql.execution.streaming.state.StateStoreSuiteBase.tryWithProviderResource(StateStoreSuite.scala:1764)\r\n[info]   at org.apache.spark.sql.execution.streaming.state.StateStoreSuiteBase.$anonfun$new$99(StateStoreSuite.scala:1092)\r\n[info]   at org.apache.spark.sql.execution.streaming.state.StateStoreSuiteBase.$anonfun$new$99$adapted(StateStoreSuite.scala:1091)\r\n[info]   at org.apache.spark.sql.execution.streaming.state.StateStoreCodecsTest.$anonfun$testWithAllCodec$4(StateStoreCompatibilitySuite.scala:72)\r\n[info]   at org.apache.spark.sql.catalyst.SQLConfHelper.withSQLConf(SQLConfHelper.scala:56)\r\n[info]   at org.apache.spark.sql.catalyst.SQLConfHelper.withSQLConf$(SQLConfHelper.scala:38)\r\n[info]   at org.apache.spark.sql.execution.streaming.state.StateStoreSuiteBase.withSQLConf(StateStoreSuite.scala:1082)\r\n[info]   at org.apache.spark.sql.execution.streaming.state.StateStoreCodecsTest.$anonfun$testWithAllCodec$3(StateStoreCompatibilitySuite.scala:72)\r\n[info]   at org.scalatest.enablers.Timed$$anon$1.timeoutAfter(Timed.scala:127)\r\n[info]   at org.scalatest.concurrent.TimeLimits$.failAfterImpl(TimeLimits.scala:282)\r\n[info]   at org.scalatest.concurrent.TimeLimits.failAfter(TimeLimits.scala:231)\r\n[info]   at org.scalatest.concurrent.TimeLimits.failAfter$(TimeLimits.scala:230)\r\n[info]   at org.apache.spark.SparkFunSuite.failAfter(SparkFunSuite.scala:69)\r\n[info]   at org.apache.spark.SparkFunSuite.$anonfun$test$2(SparkFunSuite.scala:155)\r\n```\r\n\r\nIt seems that the failed case is related to this pr?
Issue #49450: Labels: SQL, DOCS, PYTHON
Merged to master.
Issue #49449: Labels: SQL, CONNECT
The remaining test failures are not related to this PR.
Issue #49448: Labels: DOCS
Ahh gotcha @dongjoon-hyun \r\nThanks for the information. Will keep in mind for the future. \r\nAppreciate the approval ! 
Issue #49447: Labels: SQL
@gengliangwang
Issue #49446: Labels: DOCS
Closing to fix the build workflow not running issue.
Issue #49445: Labels: SQL
@cloud-fan @MaxGekk I resolved all comments, could you take a look?
Issue #49444: Labels: KUBERNETES
cc @cnauroth @dongjoon-hyun 
Issue #49443: Labels: BUILD
cc @grundprinzip, @HyukjinKwon 
Issue #49442: Labels: SQL
@srielau @cloud-fan Could you take a look at the PR, please.
Issue #49441: Labels: BUILD, INFRA
cc @zhengruifeng @HyukjinKwon 
Issue #49440: Labels: DOCS
cc @dongjoon-hyun @parthchandra @mridulm @LuciferYang 
Issue #49439: Labels: SQL, DOCS, PYTHON
thanks @MaxGekk \r\nmerged to master
Issue #49438: Labels: INFRA
cc @HyukjinKwon  @dongjoon-hyun @LuciferYang @zhengruifeng 
Issue #49437: Labels: SQL
@cloud-fan could you take a look please?
Issue #49436: Labels: SQL
cc @dongjoon-hyun Could you help review this pr if you have time? Thank you ~\r\n\r\n
Issue #49435: Labels: SQL
thanks, merged to master
Issue #49434: Labels: SQL
Merged to master for Apache Spark 4.0.0.
Issue #49433: Labels: SQL
Thank you @dongjoon-hyun! Yes, the PR should be ready -- it restores the golden file to its state before this PR: https://github.com/apache/spark/pull/49139/files#diff-b6f30759017988fd0963ce840918f541caf610a1793fa73f17e61b03a2acb797
Issue #49432: Labels: SQL, ML, MLLIB, BUILD, PYTHON, CONNECT
Issue #49431: Labels: SQL
@cloud-fan , please take a look and help merge this PR, to add a feature flag for disabling object-level collations while the feature is still in development, thanks!\r\nCC @stefankandic, with whom I agreed on adding this earlier today.
Issue #49430: Labels: SQL, PYTHON, CONNECT
the test failure should be unrelated.\r\nmerged to master
Issue #49429: Labels: WEB UI, CORE
Merged into master for Spark 4.0. Thanks @dongjoon-hyun 
Issue #49428: Labels: KUBERNETES
Thank you for making a PR, @cnauroth !
Issue #49427: Labels: SQL, DOCS
Adding @davidm-db @dejankrak-db @dusantism-db @cloud-fan @srielau  
Issue #49426: Labels: KUBERNETES
Issue #49425: Labels: SQL
> +1, the proposal sounds reasonable and this PR handles all instances in non-test code.\r\n> \r\n> > To be able to have this centralized and not have to create new string literals with "UTF8_BINARY" over and over again.\r\n> \r\n> BTW, I\
Issue #49424: Labels: SQL, PYTHON, CONNECT
how is it going?
Issue #49423: Labels: SQL, DOCS, PYTHON
merged to master
Issue #49422: Labels: SQL, PYTHON
Merged to master.
Issue #49421: Labels: SQL, DOCS, CORE
Oh, yeah +1 for vote.
Issue #49420: Labels: SQL, DOCS
cc @cloud-fan @gengliangwang here is one last PR to improve behavior for SQL pipe syntax.
Issue #49419: Labels: SQL
Issue #49418: Labels: SQL
cc @cloud-fan 
Issue #49417: Labels: SQL, STRUCTURED STREAMING
Gentle ping, @ericm-db . Please address the above review comments.
Issue #49416: Labels: SQL
cc @JoshRosen @viirya @dongjoon-hyun @peter-toth 
Issue #49415: Labels: SQL, CONNECT
Issue #49414: Labels: SQL
thanks, merging to master!
Issue #49413: Labels: BUILD, CORE
@Ngone51 Does branch-3.5 also need this bug fix?
Issue #49412: Labels: SQL, ML, PYTHON, AVRO, PROTOBUF
To further optimize Py4J calls, does it make sense to cache the result? e.g.\r\n\r\n```\r\n@functools.lru_cache(maxsize=128)\r\ndef get_jvm_attr(jvm: "JVMView", name: str) -> Any:\r\n    return getattr(jvm, name)\r\n```
Issue #49411: Labels: SQL
Could you update the test results for `SubExprEliminationBenchmark` in this pr to ensure that the changes are as expected? @panbingkun 
Issue #49410: Labels: SQL, STRUCTURED STREAMING, BUILD, INFRA
Issue #49409: Labels: SQL, MLLIB, CORE, AVRO
cc @LuciferYang and @panbingkun 
Issue #49408: Labels: SQL, PYTHON
Issue #49407: Labels: BUILD, INFRA
Issue #49406: Labels: SQL
Issue #49405: Labels: SQL
Issue #49404: Labels: INFRA
Merged to master.
Issue #49403: Labels: SQL
Thank you, @HyukjinKwon . Merged to master.
Issue #49402: Labels: CORE
Thank you, @HyukjinKwon . Merged to master.
Issue #49401: Labels: SQL
cc @asl3 and @cloud-fan 
Issue #49400: Labels: SQL
cc @LuciferYang @ulysses-you 
Issue #49399: Labels: CORE
Merged to master.
Issue #49398: Labels: BUILD
LGTM. Thanks @panbingkun 
Issue #49397: Labels: SQL, CORE, PYTHON
cc. @HyukjinKwon Please take a look, thanks!
Issue #49396: Labels: SQL
Issue #49395: Labels: SQL
+1, LGTM. Merging to master/4.0.\r\nThank you, @itholic.
Issue #49394: Labels: SQL, PYTHON, CONNECT
Issue #49393: Labels: SQL, DSTREAM
Could you review this a minor comment fix, @yaooqinn ?
Issue #49392: Labels: SQL
Issue #49391: Labels: SQL, STRUCTURED STREAMING, INFRA
Issue #49390: Labels: SQL
Could you review this PR, @yaooqinn ?
Issue #49389: Labels: SQL
thanks, merging to master!
Issue #49388: Labels: SQL, PYTHON
merged to master
Issue #49387: Labels: SQL, STRUCTURED STREAMING, CORE, DSTREAM
@michaelzhan-db could you re-run the failed tests?
Issue #49386: Labels: SQL, PYTHON, CONNECT
cc @cloud-fan too
Issue #49385: Labels: SQL
The test failure is unrelated, thanks, merging to master!
Issue #49384: Labels: SQL
Thank you, Hyukjin. Merged to master.
Issue #49383: Labels: SQL, CONNECT
thanks, merging to master!
Issue #49382: Labels: SQL
Thank you, Hyukjin. Merged to master.
Issue #49381: Labels: SQL
Issue #49380: Labels: SQL
Thank you, Hyukjin. Merged to master.
Issue #49379: Labels: SQL
Yea, this is a simpler approach. Although it still unnecessarily tracks the `outgoingRefs` for the "contains" relationship if `WithCTE` is not duplicated, but it\
Issue #49378: Labels: SQL
thanks, merging to master!
Issue #49377: Labels: SQL
@cloud-fan great idea. Done.
Issue #49376: Labels: CORE
Thank you, Hyukjin. Merged to master.
Issue #49375: Labels: BUILD
Thank you, @HyukjinKwon . Merged to master.
Issue #49374: Labels: SQL
cc @xupefei and @HyukjinKwon 
Issue #49373: Labels: SQL, PYTHON, CONNECT
Merged to master and branch-4.0.
Issue #49372: Labels: SQL
Adding @cloud-fan @davidm-db @dusantism-db  @dejankrak-db @MaxGekk 
Issue #49371: Labels: BUILD
Spooky...
Issue #49370: Labels: SQL, CONNECT
@HyukjinKwon Hi, can you please merge this PR? Thanks!
Issue #49369: Labels: BUILD, INFRA
Merged to master.
Issue #49368: Labels: BUILD
Merged to master.
Issue #49367: Labels: BUILD, INFRA
thanks, merged to master
Issue #49366: Labels: CORE
Issue #49365: Labels: PYTHON
cc @HyukjinKwon 
Issue #49364: Labels: INFRA
Thank you, @HyukjinKwon !
Issue #49363: Labels: SQL
Thank you, @LuciferYang .
Issue #49362: Labels: SQL, INFRA
```\r\n[info] org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormatV1Suite *** ABORTED *** (11 seconds, 911 milliseconds)\r\n[info]   The code passed to eventually never returned normally. Attempted 15 times over 10.007530677999998 seconds. Last failure message: There are 1 possibly leaked file streams.. (SharedSparkSession.scala:167)\r\n[info]   org.scalatest.exceptions.TestFailedDueToTimeoutException:\r\n[info]   at org.scalatest.enablers.Retrying$$anon$4.tryTryAgain$2(Retrying.scala:219)\r\n[info]   at org.scalatest.enablers.Retrying$$anon$4.retry(Retrying.scala:226)\r\n[info]   at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:313)\r\n[info]   at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:312)\r\n[info]   at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormatSuite.eventually(ParquetFileFormatSuite.scala:31)\r\n[info]   at org.apache.spark.sql.test.SharedSparkSessionBase.afterEach(SharedSparkSession.scala:167)\r\n[info]   at org.apache.spark.sql.test.SharedSparkSessionBase.afterEach$(SharedSparkSession.scala:161)\r\n[info]   at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormatSuite.afterEach(ParquetFileFormatSuite.scala:31)\r\n[info]   at org.scalatest.BeforeAndAfterEach.$anonfun$runTest$1(BeforeAndAfterEach.scala:247)\r\n[info]   at org.scalatest.Status.$anonfun$withAfterEffect$1(Status.scala:377)\r\n[info]   at org.scalatest.Status.$anonfun$withAfterEffect$1$adapted(Status.scala:373)\r\n[info]   at org.scalatest.SucceededStatus$.whenCompleted(Status.scala:462)\r\n[info]   at org.scalatest.Status.withAfterEffect(Status.scala:373)\r\n[info]   at org.scalatest.Status.withAfterEffect$(Status.scala:371)\r\n[info]   at org.scalatest.SucceededStatus$.withAfterEffect(Status.scala:434)\r\n[info]   at org.scalatest.BeforeAndAfterEach.runTest(BeforeAndAfterEach.scala:246)\r\n[info]   at org.scalatest.BeforeAndAfterEach.runTest$(BeforeAndAfterEach.scala:227)\r\n[info]   at org.apache.spark.SparkFunSuite.runTest(SparkFunSuite.scala:69)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:269)\r\n[info]   at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\r\n[info]   at scala.collection.immutable.List.foreach(List.scala:334)\r\n[info]   at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\r\n[info]   at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\r\n[info]   at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:269)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:268)\r\n[info]   at org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1564)\r\n[info]   at org.scalatest.Suite.run(Suite.scala:1114)\r\n[info]   at org.scalatest.Suite.run$(Suite.scala:1096)\r\n[info]   at org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1564)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:273)\r\n[info]   at org.scalatest.SuperEngine.runImpl(Engine.scala:535)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:273)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:272)\r\n[info]   at org.apache.spark.SparkFunSuite.org$scalatest$BeforeAndAfterAll$$super$run(SparkFunSuite.scala:69)\r\n[info]   at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)\r\n[info]   at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)\r\n[info]   at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)\r\n[info]   at org.apache.spark.SparkFunSuite.run(SparkFunSuite.scala:69)\r\n[info]   at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:321)\r\n[info]   at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:517)\r\n[info]   at sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:414)\r\n[info]   at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\r\n[info]   at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n[info]   at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n[info]   at java.base/java.lang.Thread.run(Thread.java:1583)\r\n[info]   Cause: java.lang.IllegalStateException: There are 1 possibly leaked file streams.\r\n[info]   at org.apache.spark.DebugFilesystem$.assertNoOpenStreams(DebugFilesystem.scala:54)\r\n[info]   at org.apache.spark.sql.test.SharedSparkSessionBase.$anonfun$afterEach$1(SharedSparkSession.scala:168)\r\n[info]   at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\r\n[info]   at org.scalatest.enablers.Retrying$$anon$4.makeAValiantAttempt$1(Retrying.scala:184)\r\n[info]   at org.scalatest.enablers.Retrying$$anon$4.tryTryAgain$2(Retrying.scala:196)\r\n[info]   at org.scalatest.enablers.Retrying$$anon$4.retry(Retrying.scala:226)\r\n[info]   at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:313)\r\n[info]   at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:312)\r\n[info]   at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormatSuite.eventually(ParquetFileFormatSuite.scala:31)\r\n[info]   at org.apache.spark.sql.test.SharedSparkSessionBase.afterEach(SharedSparkSession.scala:167)\r\n[info]   at org.apache.spark.sql.test.SharedSparkSessionBase.afterEach$(SharedSparkSession.scala:161)\r\n[info]   at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormatSuite.afterEach(ParquetFileFormatSuite.scala:31)\r\n[info]   at org.scalatest.BeforeAndAfterEach.$anonfun$runTest$1(BeforeAndAfterEach.scala:247)\r\n[info]   at org.scalatest.Status.$anonfun$withAfterEffect$1(Status.scala:377)\r\n[info]   at org.scalatest.Status.$anonfun$withAfterEffect$1$adapted(Status.scala:373)\r\n[info]   at org.scalatest.SucceededStatus$.whenCompleted(Status.scala:462)\r\n[info]   at org.scalatest.Status.withAfterEffect(Status.scala:373)\r\n[info]   at org.scalatest.Status.withAfterEffect$(Status.scala:371)\r\n[info]   at org.scalatest.SucceededStatus$.withAfterEffect(Status.scala:434)\r\n[info]   at org.scalatest.BeforeAndAfterEach.runTest(BeforeAndAfterEach.scala:246)\r\n[info]   at org.scalatest.BeforeAndAfterEach.runTest$(BeforeAndAfterEach.scala:227)\r\n[info]   at org.apache.spark.SparkFunSuite.runTest(SparkFunSuite.scala:69)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:269)\r\n[info]   at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\r\n[info]   at scala.collection.immutable.List.foreach(List.scala:334)\r\n[info]   at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\r\n[info]   at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\r\n[info]   at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:269)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:268)\r\n[info]   at org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1564)\r\n[info]   at org.scalatest.Suite.run(Suite.scala:1114)\r\n[info]   at org.scalatest.Suite.run$(Suite.scala:1096)\r\n[info]   at org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1564)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:273)\r\n[info]   at org.scalatest.SuperEngine.runImpl(Engine.scala:535)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:273)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:272)\r\n[info]   at org.apache.spark.SparkFunSuite.org$scalatest$BeforeAndAfterAll$$super$run(SparkFunSuite.scala:69)\r\n[info]   at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)\r\n[info]   at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)\r\n[info]   at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)\r\n[info]   at org.apache.spark.SparkFunSuite.run(SparkFunSuite.scala:69)\r\n[info]   at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:321)\r\n[info]   at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:517)\r\n[info]   at sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:414)\r\n[info]   at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\r\n[info]   at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n[info]   at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n[info]   at java.base/java.lang.Thread.run(Thread.java:1583)\r\n[info]   Cause: java.lang.Throwable:\r\n[info]   at org.apache.spark.DebugFilesystem$.addOpenStream(DebugFilesystem.scala:35)\r\n[info]   at org.apache.spark.DebugFilesystem.open(DebugFilesystem.scala:75)\r\n[info]   at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:997)\r\n[info]   at org.apache.parquet.hadoop.util.HadoopInputFile.newStream(HadoopInputFile.java:75)\r\n[info]   at org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:925)\r\n[info]   at org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:710)\r\n[info]   at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:85)\r\n[info]   at org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:76)\r\n[info]   at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readParquetFootersInParallel$1(ParquetFileFormat.scala:451)\r\n[info]   at org.apache.spark.util.ThreadUtils$.$anonfun$parmap$2(ThreadUtils.scala:416)\r\n[info]   at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)\r\n[info]   at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)\r\n[info]   at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1423)\r\n[info]   at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)\r\n[info]   at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1312)\r\n[info]   at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1843)\r\n[info]   at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1808)\r\n[info]   at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)\r\n```
Issue #49361: Labels: SQL, STRUCTURED STREAMING
Merged to master, thank you @dongjoon-hyun @HyukjinKwon 
Issue #49360: Labels: INFRA
Merged to master for Apache Spark 4.0.0.
Issue #49359: Labels: SQL
Thank you, @HyukjinKwon , @zhengruifeng , @yaooqinn .
Issue #49358: Labels: BUILD
Thank you, @williamhyun .
Issue #49357: Labels: No Labels
Thank you for taking a look at this. Please take a rest first and your time, @LuciferYang !
Issue #49356: Labels: SQL, PYTHON
cc @LuciferYang 
Issue #49355: Labels: CORE, DSTREAM
Thanks @dongjoon-hyun. I changed this to draft as some test failures in the CI. I will add a JIRA issue once this is ready.
Issue #49354: Labels: SQL, PYTHON
Java 21 test passed, revert to Java 17, will update pr description later
Issue #49353: Labels: SQL
thanks, merging to master!
Issue #49352: Labels: SQL
@peter-toth I find this "reference lineage" is a clearer design, because\r\n1. When we optimize out a CTE relation, and the nested `WithCTE` inside it is self-contained, we don\
Issue #49351: Labels: SQL
Please take another look.\r\n\r\nCTERelationDef does not contain anchor any longer -- when needed it is fetched from its child via pattern matching. Code is greatly simplified and all previous convoluted questions on recursionAnchor are now moot.\r\n\r\nI added several exceptions for the unsupported cases of Union under the CTE Definition.\r\n\r\nSubstitution rules for UnionLoop/Ref are added for 4 cases of Union under CTE Definition.\r\n\r\nCTERelationDef change has broken some tests, will work on those now.
Issue #49350: Labels: CORE
@mridulm @JoshRosen @dongjoon-hyun Could you help take a look? Thanks!
Issue #49349: Labels: PYTHON, PANDAS API ON SPARK
Merged to master. Thanks @HyukjinKwon for the review
Issue #49348: Labels: SQL, PYTHON
cc @zhengruifeng 
Issue #49347: Labels: CORE
cc @dongjoon-hyun FYI
Issue #49346: Labels: SQL, PYTHON, CONNECT
LGTM thank you
Issue #49345: Labels: SQL
thanks, merging to master!
Issue #49344: Labels: BUILD, DOCS, PYTHON
thanks, merged to master
Issue #49343: Labels: BUILD, INFRA, PYTHON, PANDAS API ON SPARK
thanks, merged to master
Issue #49342: Labels: SQL, PYTHON, CONNECT
PTAL @hvanhovell / @HyukjinKwon / @xupefei 
Issue #49341: Labels: SQL, CONNECT
@xupefei PTAL!
Issue #49340: Labels: SQL
thanks, merging to master!
Issue #49339: Labels: SQL
Issue #49338: Labels: SQL, PYTHON
cc @zhengruifeng 
Issue #49337: Labels: SQL, PYTHON
I am going to merge this to recoevr the CI.
Issue #49336: Labels: SQL, PYTHON, CONNECT
BTW, do we have a list that which dataframe operations are allowed in subqueries?
Issue #49335: Labels: SQL
cc @beliefer 
Issue #49334: Labels: SQL
Merged to master.
Issue #49333: Labels: SQL, PYTHON
thanks, merged to master
Issue #49332: Labels: SQL
@cloud-fan @yaooqinn @huaxingao please let me know if this approach makes sense, or do you have any other suggestions to allow users to set `spark_catalog` to the built-in `V2SessionCatalog` explicitly? thanks in advance.
Issue #49331: Labels: SQL, PYTHON, PANDAS API ON SPARK, CONNECT
Merged to master.
Issue #49330: Labels: SQL
Merged to master.
Issue #49329: Labels: SQL
@yaooqinn PTAL if have free time, Thanks
Issue #49328: Labels: SQL
Issue #49327: Labels: SQL, CONNECT
The remaining test failures are not related to this PR.
Issue #49326: Labels: SQL, PYTHON, CONNECT
Issue #49325: Labels: SQL
cc @beliefer 
Issue #49324: Labels: SQL, CONNECT
Merged to master.
Issue #49323: Labels: SQL, STRUCTURED STREAMING, CONNECT
Thank you for the fix!\r\n\r\nThe change LGTM, for test complexity, can you add a custom class test case like here?\r\nhttps://github.com/apache/spark/blob/master/connector/connect/client/jvm/src/test/scala/org/apache/spark/sql/streaming/ClientStreamingQuerySuite.scala#L426-L448
Issue #49322: Labels: SQL
The docker test failure is unrelated, thanks, merging to master!
Issue #49321: Labels: SQL
Merged to master.
Issue #49320: Labels: SQL, PYTHON
thanks, merged to master
Issue #49319: Labels: SQL
thanks, merging to master!
Issue #49318: Labels: SQL, PYTHON, CONNECT
Issue #49317: Labels: SQL, DOCS
Issue #49316: Labels: DOCS
LGTM.
Issue #49315: Labels: PYTHON
Merged to master.
Issue #49314: Labels: SQL, CORE
Issue #49313: Labels: SQL, ML, STRUCTURED STREAMING, PYTHON, CONNECT
Merged to master.
Issue #49312: Labels: PYTHON
Merged to master.
Issue #49311: Labels: PYTHON
cc @itholic @zhengruifeng 
Issue #49310: Labels: SQL
cc @cloud-fan Thank you.
Issue #49309: Labels: SQL
Merged to master.
Issue #49308: Labels: SQL, PYTHON
Merged to master.
Issue #49307: Labels: ML, PYTHON
Merged to master.
Issue #49306: Labels: SQL, PYTHON, CONNECT
Merged to master.
Issue #49305: Labels: SQL, PYTHON, CONNECT
merged to master
Issue #49304: Labels: SQL, STRUCTURED STREAMING
cc - @ericm-db @jingz-db - PTAL, thx !
Issue #49303: Labels: SQL
\r\nIs it convenient to support the judgment of how many times a common expression has been used?
Issue #49302: Labels: BUILD
Test first
Issue #49301: Labels: BUILD
Merged to master.
Issue #49300: Labels: SQL
Merged into master. Thanks @HyukjinKwon 
Issue #49299: Labels: SQL, CORE, PYTHON
should we add a simple test?
Issue #49298: Labels: MLLIB
thanks, merged to master
Issue #49297: Labels: SQL, PYTHON
let me close this for now
Issue #49296: Labels: BUILD, PROTOBUF
Hi @LuciferYang @zhengruifeng, could you please help to reivew this when you have time? Many thanks.
Issue #49295: Labels: SQL
Issue #49294: Labels: PYTHON, PANDAS API ON SPARK
merged to master
Issue #49293: Labels: SQL
@cloud-fan could you help review? Thanks a lot!
Issue #49292: Labels: CORE
Issue #49291: Labels: SQL, CONNECT
Some tests need to be updated.
Issue #49290: Labels: SQL, CONNECT
@MaxGekk could you take a look at this follow-up?
Issue #49289: Labels: SQL, CORE, PYTHON
Issue #49288: Labels: PYTHON, PANDAS API ON SPARK
Merged to master.
Issue #49287: Labels: SQL
thanks, merging to master!
Issue #49286: Labels: SPARK SUBMIT, CORE, WINDOWS, PYTHON
Issue #49285: Labels: SQL
@MaxGekk This change is not required after #49319 and #49334. Underlying change will be removed here #49460. Closing this PR
Issue #49284: Labels: SQL
LGTM
Issue #49283: Labels: SQL
LGTM
Issue #49282: Labels: SQL, BUILD, DOCS, PYTHON, CONNECT
Merged to master for Apache Spark 4.0.0.
Issue #49281: Labels: INFRA
thanks @LuciferYang \r\n\r\nmerged to master
Issue #49280: Labels: SQL
merged to master
Issue #49279: Labels: INFRA
thanks, merged to master
Issue #49278: Labels: SQL, STRUCTURED STREAMING
Issue #49277: Labels: SQL, STRUCTURED STREAMING, PYTHON
@ericm-db - can you also format the PR description and explain in more detail what functionality this PR adds. Thx\r\n\r\nAlso - this is a user facing change right ?
Issue #49276: Labels: SQL
@hvanhovell please review
Issue #49275: Labels: SQL, STRUCTURED STREAMING
Ended up creating a new error framework because [we have existing tests expecting IllegalStateException](https://github.com/apache/spark/blob/ef37f9a8e202812ea6b710bfb084ce176ff5e63d/connector/kafka-0-10-sql/src/test/scala/org/apache/spark/sql/kafka010/KafkaMicroBatchSourceSuite.scala#L1005). Also there might be some test cases used by downstream projects expecting the same @brkyvz 
Issue #49274: Labels: SQL, PYTHON, CONNECT
Merged to master.
Issue #49273: Labels: DOCS
Merged to master.
Issue #49272: Labels: SQL, STRUCTURED STREAMING
Thanks! Merging to master.
Issue #49271: Labels: SQL
LGTM.\r\n\r\nI think there are no major issues, Wenchen. Could we merge it, please?\r\nOutput formatting could be fixed asynchronously later.
Issue #49270: Labels: CORE
cc @cloud-fan 
Issue #49269: Labels: SQL
@cloud-fan please take a look when you can
Issue #49268: Labels: SQL, PYTHON
Merged to master.
Issue #49267: Labels: BUILD, INFRA
pyarrow 10.0 fails the whole pyspark\r\n\r\nhttps://github.com/zhengruifeng/spark/actions/runs/12464102622/job/34787749014
Issue #49266: Labels: BUILD
thanks, merged to master
Issue #49265: Labels: SQL, PYTHON
merged to master
Issue #49264: Labels: INFRA
This is all of it, right?
Issue #49263: Labels: SQL
@cloud-fan @cashmand @gene-db could you help review? Thanks!
Issue #49262: Labels: SQL, CORE, PYTHON
Encountered an error when pickling the lambda function. Closed this for now.
Issue #49261: Labels: SQL
Can we have a micro benchmark?
Issue #49260: Labels: SQL, STRUCTURED STREAMING, PYTHON, CONNECT
Merged to master.
Issue #49259: Labels: SQL
cc @cloud-fan 
Issue #49258: Labels: CORE
cc @yaooqinn and @viirya 
Issue #49257: Labels: SQL
Issue #49256: Labels: DOCS
cc @cloud-fan
Issue #49255: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @vladimirg-db.
Issue #49254: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @vladimirg-db.
Issue #49253: Labels: SQL, CONNECT
Merged to master.
Issue #49252: Labels: DOCS
cc @cloud-fan @wangyum 
Issue #49251: Labels: INFRA
Need to wait for the admin to configure `secrets.CODECOV_TOKEN`\r\nThe relevant PR is here: https://github.com/apache/spark/pull/49228
Issue #49250: Labels: BUILD
@LuciferYang Thanks for the review, merging to master!
Issue #49249: Labels: SQL, PYTHON, CONNECT
Issue #49248: Labels: SQL
cc @cloud-fan @gengliangwang this PR fixes `|> AGGREGATE` `GROUP BY` ordinal support :)
Issue #49247: Labels: CORE
Issue #49246: Labels: KUBERNETES, BUILD
Issue #49245: Labels: SQL
cc @cloud-fan @gengliangwang 
Issue #49244: Labels: SQL
Closing this as it has been merged to 3.5 by https://github.com/apache/spark/commit/51fb84a54982719209c19136b1d72d2ef44726ee
Issue #49243: Labels: SQL
Issue #49242: Labels: SQL, STRUCTURED STREAMING
Thanks! Merging to master.
Issue #49241: Labels: PYTHON
Merged to master.
Issue #49240: Labels: SQL
close it as it does not exist in 3.5.1 
Issue #49239: Labels: SQL
@cashmand @cloud-fan could you help review? Thanks!
Issue #49238: Labels: SQL, STRUCTURED STREAMING
Thanks for the feedback @cloud-fan! Addressed 
Issue #49237: Labels: SQL
cc @MaxGekk @HyukjinKwon @cloud-fan Greetings, this small PR is ready for a review at your convenience :)
Issue #49236: Labels: SQL
Issue #49235: Labels: SQL
@cloud-fan @gene-db @cashmand Please help review, thanks!
Issue #49234: Labels: SQL
thanks, merging to master!
Issue #49233: Labels: SQL, DOCS
Congratulations for your first commit.\r\n\r\nI added you, `James Baug`, to the Apache Spark contributor group and assigned SPARK-50616 to you.\r\n\r\nWelcome to the Apache Spark community, @jabbaugh !
Issue #49232: Labels: SQL, DOCS
The JIRA ticket number will be changed to a subtask as soon as I get my account on JIRA created.
Issue #49231: Labels: SQL, DOCS, PYTHON, CONNECT
please also add new function into `python/pyspark/sql/functions/__init__.py`
Issue #49230: Labels: SQL
@MaxGekk I addressed all comments. Failures seem unrelated, can you please take a look?
Issue #49229: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @mihailoale-db and @cloud-fan for review.
Issue #49228: Labels: INFRA
LGTM
Issue #49227: Labels: SQL
Merged to master.
Issue #49226: Labels: SQL, STRUCTURED STREAMING
Issue #49225: Labels: SQL
@cloud-fan Can you please help review this
Issue #49224: Labels: BUILD, INFRA
+1, LGTM. Merging to master.\r\nThank you, @panbingkun and @HyukjinKwon for review.
Issue #49223: Labels: SQL
cc @cloud-fan @dongjoon-hyun, thank you in advance.
Issue #49222: Labels: SQL, CONNECT
cc @cloud-fan 
Issue #49221: Labels: DOCS, PYTHON
Issue #49220: Labels: SQL, STRUCTURED STREAMING
@viirya since this was your original bug fix (although 8 years ago)
Issue #49219: Labels: SQL, PYTHON
LGTM, thank you for the fix!\r\n
Issue #49218: Labels: SQL, STRUCTURED STREAMING, PYTHON
Issue #49217: Labels: SQL, STRUCTURED STREAMING
Issue #49216: Labels: CORE
Issue #49215: Labels: SQL
This is a simplified version made according to the suggestions of the review.\r\nThe first version is here: https://github.com/apache/spark/pull/48908\r\ncc @cloud-fan 
Issue #49214: Labels: DEPLOY, BUILD, DOCS, CORE, WINDOWS, INFRA, PYTHON
Merged to master.
Issue #49213: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @mihailom-db and @srielau for review.
Issue #49212: Labels: SQL, CORE
also cc @utkarsh39
Issue #49211: Labels: SQL
Putting this PR up for discussion about this problem, as I may lack the context.  This PR has one way to support truncate and any future transform in this category (single attribute reference but multi-argument), but wondering if its overkill or is there any better way.  \r\n\r\nOr do we need to add an explicit TruncateTransform, and support it like BucketTransform?  \r\n\r\n@sunchao @aokolnychyi 
Issue #49210: Labels: SQL
cc @srielau @gengliangwang here is a PR to improve the `RANDSTR` function as requested :)
Issue #49209: Labels: SQL, BUILD, CORE, AVRO
Issue #49208: Labels: SQL
do we really need to change them? `::` and `+` are standard operators in scala
Issue #49207: Labels: INFRA
Merged to master.
Issue #49206: Labels: INFRA
thanks @LuciferYang so much for help monitoring the CIs and resolving this failure!
Issue #49205: Labels: BUILD, INFRA
Just Test
Issue #49204: Labels: INFRA
Let me hold on this PR until 3.5 is successfully cut
Issue #49203: Labels: SQL, CONNECT
https://github.com/changgyoopark-db/spark/runs/34523136586\r\nhttps://github.com/changgyoopark-db/spark/runs/34523226244\r\nhttps://github.com/changgyoopark-db/spark/runs/34523275936\r\n-> triggered three jobs.
Issue #49202: Labels: SQL
@cloud-fan Can you help first to see if the overall design is feasible? It involves a lot of UT, so I will modify it step by step.
Issue #49201: Labels: BUILD, INFRA
cc @yaooqinn FYI
Issue #49200: Labels: BUILD
cc @panbingkun 
Issue #49199: Labels: SQL, PYTHON, CONNECT
Although the PR looks correct, could you re-trigger the failed Python test pipeline, @itholic ?
Issue #49198: Labels: BUILD
+1, LGTM. Merging to master.\r\nThank you, @sarutak and @HyukjinKwon for review.
Issue #49197: Labels: SQL, DOCS, PYTHON
Issue #49196: Labels: SQL, STRUCTURED STREAMING, PYTHON, CONNECT
Test first
Issue #49195: Labels: SQL
Issue #49194: Labels: SQL, STRUCTURED STREAMING
I\
Issue #49193: Labels: INFRA
for `the PRs for branch-3.5`, I think it is not affected, because `branch-3.5` still uses the old image and ignores the `PYTHON_TO_TEST`\r\n```\r\n    - name: Run tests\r\n      env: ${{ fromJSON(inputs.envs) }}\r\n      shell: \
Issue #49192: Labels: DOCS
Issue #49191: Labels: SQL, PYTHON, CONNECT
nit: How about adding `[PYTHON]` to the PR title?
Issue #49190: Labels: SQL
@hvanhovell , @cloud-fan - could you please take a look here?
Issue #49189: Labels: BUILD
Is it ready, @panbingkun ?
Issue #49188: Labels: SQL, STRUCTURED STREAMING
Thanks! Merging to master.
Issue #49187: Labels: SQL, CONNECT
Merged to master.
Issue #49186: Labels: SQL
@cloud-fan, @stefankandic, @stevomitric please review this urgently.
Issue #49185: Labels: BUILD
cc @LuciferYang @dongjoon-hyun 
Issue #49184: Labels: SQL, CONNECT
cc @panbingkun 
Issue #49183: Labels: SQL, STRUCTURED STREAMING
Issue #49182: Labels: SQL, PYTHON, CONNECT
@ueshin should we also cover `MergeIntoWriter`, and perhaps other classes that can build Datasets and can use arbitrary Columns?
Issue #49181: Labels: DOCS
cc @yaooqinn 
Issue #49180: Labels: SQL
@peter-toth Please, have a look at the PR.
Issue #49179: Labels: SQL
@cloud-fan since you were involved in https://github.com/apache/spark/pull/21018 where the problematic code was introduced.
Issue #49178: Labels: INFRA
Merged to master. Thank you, @zhengruifeng .
Issue #49177: Labels: SQL
cc @cloud-fan 
Issue #49176: Labels: INFRA
Merged to master. Thank you, @zhengruifeng .
Issue #49175: Labels: SQL, STRUCTURED STREAMING
@siying for both questions the answer is yes it is using v2. This is the trick I have here:\r\nhttps://github.com/apache/spark/blob/053af1a0fbc34debb729a3e86837b4aeaedb11ca/sql/core/src/test/scala/org/apache/spark/sql/execution/streaming/state/RocksDBSuite.scala#L3025-L3040\r\n\r\nThe map will be updated inside commit()\r\n\r\n
Issue #49174: Labels: SQL, STRUCTURED STREAMING
Thanks! Merging to master.
Issue #49173: Labels: SQL, STRUCTURED STREAMING
Thanks! Merging to master.
Issue #49172: Labels: SQL, STRUCTURED STREAMING
@HeartSaVioR The tests now pass : )
Issue #49171: Labels: SQL, STRUCTURED STREAMING
@HeartSaVioR PTAL
Issue #49170: Labels: BUILD, INFRA
Please let me know if this is ready, @LuciferYang .
Issue #49169: Labels: BUILD
Test first
Issue #49168: Labels: INFRA
thank you!\r\nmerged to master
Issue #49167: Labels: SQL, YARN, CORE, DSTREAM, CONNECT
thanks, merging to master!
Issue #49166: Labels: SQL
Added the benchmarks.
Issue #49165: Labels: BUILD, INFRA
thanks @dongjoon-hyun 
Issue #49164: Labels: SQL, STRUCTURED STREAMING
cc @gaborgsomogyi and @viirya too from the following\r\n- https://github.com/apache/spark/pull/38306
Issue #49163: Labels: SQL, ML, MLLIB, STRUCTURED STREAMING, WEB UI, CORE, CONNECT
Thank you for updating. Could you make CI happy, @steven-aerts ?
Issue #49162: Labels: SQL, CORE
cc @dongjoon-hyun @LuciferYang 
Issue #49161: Labels: SQL, CONNECT
Merged to master.
Issue #49160: Labels: BUILD, INFRA
thanks, merged to master
Issue #49159: Labels: KUBERNETES, BUILD
- After more than a `week` of investigation and research, when we upgraded `Kubernetes client` from `6.x` to `7.0` and switched `default` HttpClient implementation from `OkHttp` to `Vert.x`, the issue of `Kubernetes Integration test` failure has been resolved.\r\n- The root cause is that some thread attributes `daemon` of `Vert.x` are set to `false`, so that after using `ProcessBuilder` to start the spark application on `K8S` (based on `spark-submit`), the `main thread` has already ended, but the above threads will not end, resulting in the overall `process` based on `spark-submit` not ending either.
Issue #49158: Labels: PYTHON, CONNECT
This will be the last ..
Issue #49157: Labels: SQL, PYTHON
Issue #49156: Labels: SQL, STRUCTURED STREAMING, CORE, PYTHON
@jingz-db - test failures seem relevant ?
Issue #49155: Labels: SQL
Issue #49154: Labels: SQL
Issue #49153: Labels: SQL
Issue #49152: Labels: SQL
To see the bug, you can do any of the following:\r\n1)  Comment out the implementation of equalsIgnoreRuntimeFilter and hashCodeIgnoreRuntimeFilters from InMemoryV2FilterBatchScan.\r\nor\r\n2) Take the BatchScanExec from master and update the code and run the test
Issue #49151: Labels: SQL
Could you re-trigger once more, @cashmand ?
Issue #49150: Labels: SQL
Previous chain of comments:\r\nFrom @anchovYu \r\nHi @ahshahid , thanks for the proposal and the PR. However, the current Dataframe cache design has a lot of design flaws, I would worry that improving the cache hit rate in this case will make these problems worse:\r\n\r\nstale results\r\nThe current design of Dataframe cache is unable to proactively detect data staleness. Consider the case the table is changed by some other applications - Dataframe cache never knows that and it leads to outdated results. In this case, increasing the hit rate potentially increases the risk of hitting stale data.\r\nunstable performance\r\nSince Dataframe cache is shared across Spark sessions and applied automatically, one session could use the data cached by another session in the same driver, or no longer be able to use the cached data when it is invalidated by another session in the same driver, all without any notice. It results in unpredictable performance for even two consecutive executions on the same query in one session in the same driver. Similarly, increasing the hit rate may make it easier to encounter such unstable performance issues.\r\ncc @cloud-fan\r\n\r\n\r\nFrom @ahshahid \r\n@anchovYu\r\nI see, what you are saying.\r\nActually this PR arose as sub - pr for the issue [spark-45959](https://issues.apache.org/jira/browse/SPARK-45959).\r\nThe PR for the same is https://github.com/apache/spark/pull/49124\r\nThe increase of the cache hit is a by product of the above PR.\r\nFrom my experience and even the current customer use cases, this issue ( [spark-45959](https://github.com/apache/spark/pull/49124)) has caused increased in compile time from say under a minute to anything ranging from 2hrs - 8 hrs +.\r\nWhether the issues of stale cache etc increase or not would very much depend upon the nature of the dataframe cached .\r\nAlso most of the time the user would cache a dataframe and then keep building new data frames from the base. So in that sense, even currently , there is no way to prevent new data frames from not using cached data , if the sub-plan matches.\r\nAnd whatever fix goes in for stale cache resolution issue would automatically apply to this change too.\r\nSo pls consider this PR per se not in the light of increasing the cache hit, but as a requirement to resolve the issue of [spark-45959](https://issues.apache.org/jira/browse/SPARK-45959).
Issue #49149: Labels: DOCS
cc @HyukjinKwon and @LuciferYang 
Issue #49148: Labels: SQL, CONNECT
From my understanding, `toJSON` is a proper API and it was added in Spark 2.0.0.\r\nIt is documented [here](https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/Dataset.html#toJSON--), at the official `DataSet` Spark documentation. On the internet, I see a lot of code examples using this `toJSON` API to construct series of JSON strings from DataSet/DataFrame, and I have not heard one place which says it is not a proper API or it is getting deprecated.\r\nThe workaround that @HyukjinKwon proposed works in my case, so I want to hear your thoughts about whether it is worth extending `DataSet` API with `toJSON(jsonOptions: Map[String, String]` method. These JSON options are also well documented [here](https://spark.apache.org/docs/3.5.1/sql-data-sources-json.html), and I think it would be better for users to have a method `toJSON(options)` for their purpose instead of using the workaround that was proposed above.\r\nPlease share your thoughts @cloud-fan @MaxGekk @HyukjinKwon because this one is critical for timestamp precision in `JSON` converted strings from the `DataSet`.
Issue #49147: Labels: SQL
@stevomitric @mihailom-db please take a look
Issue #49146: Labels: SQL
Issue #49145: Labels: SQL
Issue #49144: Labels: SQL
Hi @harshmotw-db, @hvanhovell, @cloud-fan in continuation to https://github.com/apache/spark/pull/49080 discussion and [SPARK-50525](https://issues.apache.org/jira/browse/SPARK-50525). 
Issue #49143: Labels: SQL, CORE
cc @wangyum 
Issue #49142: Labels: SQL, PYTHON, CONNECT
thanks, merged to master
Issue #49141: Labels: BUILD
cc @zhengruifeng 
Issue #49140: Labels: BUILD, INFRA
thanks @dongjoon-hyun \r\n\r\nmerged to master
Issue #49139: Labels: SQL, DOCS
thanks, merging to master!
Issue #49138: Labels: SQL, STRUCTURED STREAMING, PYTHON
@LuciferYang Do you know why the python codegen test failed [here](https://github.com/bogao007/spark/actions/runs/12268004743/job/34229117566)? I was using the `./dev/streaming-gen-protos.sh` script that you created in [this](https://github.com/apache/spark/pull/48815) PR. Do we need to update the `check-protos.py` to accommodate the changes in `StateMessage_pb2.py` and `StateMessage_pb2.pyi`?
Issue #49137: Labels: PYTHON, CONNECT
Merged to master.
Issue #49136: Labels: SQL
Issue #49135: Labels: SQL
@MaxGekk Can you look at this PR since you implemented the `spark.sql.stableDerivedColumnAlias.enabled` config?
Issue #49134: Labels: SQL
cc @cloud-fan @MaxGekk 
Issue #49133: Labels: SQL, PYTHON, CONNECT
Merged to master.
Issue #49132: Labels: CORE
Could you review this PR, @viirya ?
Issue #49131: Labels: SQL
cc @richardc-db and @viirya , too
Issue #49130: Labels: SQL, BUILD, PYTHON, CONNECT
@MJovan2002 could you please sync with master again, so we can merge this in.
Issue #49129: Labels: SQL
Issue #49128: Labels: SQL
LGTM, please update title to reflect the config name, also give a SQL name in the description, so that spark users can know which config you are adding.
Issue #49127: Labels: SQL, CONNECT
Not a test only issue, but a "rare" data race between the SparkConnect service and ExecuteThreadRunner.\r\n-> The client may get the wrong error code.
Issue #49126: Labels: SQL
cc @cloud-fan 
Issue #49125: Labels: SQL, CONNECT
Nice refactoring, thank you!
Issue #49124: Labels: SQL, CONNECT
Issue #49123: Labels: BUILD
thanks, merged to master
Issue #49122: Labels: BUILD, INFRA
@LuciferYang \r\n> will we simplify the content of dev/infra/Dockerfile?\r\n\r\nI think we can just let it alone and remove it after 3.5 EOL.
Issue #49121: Labels: SQL, STRUCTURED STREAMING
cc - @ericm-db @HeartSaVioR - PTAL, thx !
Issue #49120: Labels: SQL
cc @cloud-fan @dongjoon-hyun here is the PR with test cases fixed.
Issue #49119: Labels: PYTHON, CONNECT
Merged to master.
Issue #49118: Labels: SQL
thanks, merging to master!
Issue #49117: Labels: SQL
Issue #49116: Labels: SQL
Could you review this PR, @viirya ?
Issue #49115: Labels: SQL
In 3.5, JDBCRDD class and InputToSql function are private, which makes this backport difficult.\r\nIn master, these are not private, so I\
Issue #49114: Labels: SQL
@MaxGekk please take a look when you have the time
Issue #49113: Labels: SQL, PYTHON
Thanks! Merging to master.
Issue #49112: Labels: SQL
Issue #49111: Labels: SQL, CONNECT
Merging to master/4.0
Issue #49110: Labels: SQL
@dongjoon-hyun  Could you review this renaming PR
Issue #49109: Labels: KUBERNETES
Could you please take a look? @dongjoon-hyun 
Issue #49108: Labels: BUILD, INFRA
cc @yaooqinn Can we backport this one? It seems to enhance the robustness of the release process.
Issue #49107: Labels: SQL, KUBERNETES, YARN, DOCS, CORE, INFRA, PYTHON, CONNECT
how is it going?
Issue #49106: Labels: PYTHON, CONNECT
Merged to master.
Issue #49105: Labels: SQL, CORE, AVRO
cc @LuciferYang 
Issue #49104: Labels: SQL, BUILD, PYTHON, CONNECT
Issue #49103: Labels: SQL
@dejankrak-db @stevomitric please take a look, thanks!
Issue #49102: Labels: SQL, STRUCTURED STREAMING
@HeartSaVioR - could you PTAL at the small test change ? Thx\r\n\r\n@LuciferYang reported some runs being flaky on the original PR here - https://github.com/apache/spark/pull/48913#discussion_r1862459541
Issue #49101: Labels: SQL, PYTHON, CONNECT
Also, cc @cloud-fan since this is about Apache Spark configuration namespace.
Issue #49100: Labels: MLLIB, GRAPHX, CORE, DSTREAM
I converted this to `Draft` due to the `Conflicting files`. You can convert this back to a normal PR when the PR is ready.\r\n\r\n![Screenshot 2024-12-06 at 13 06 33](https://github.com/user-attachments/assets/8d47000b-ec1b-4223-b319-3e0e471e2b06)\r\n
Issue #49099: Labels: SQL, STRUCTURED STREAMING
cc - @cloud-fan @HeartSaVioR - PTAL, thx !
Issue #49098: Labels: DOCS
cc @yaooqinn and @cloud-fan 
Issue #49097: Labels: DOCS
cc @LuciferYang 
Issue #49096: Labels: DOCS
cc @dtenedor , @cloud-fan , @gengliangwang , @MaxGekk 
Issue #49095: Labels: SQL
How did this work before? Can you give an example?
Issue #49094: Labels: WEB UI, CORE, DSTREAM
cc @attilapiros, @dongjoon-hyun 
Issue #49093: Labels: SQL
thanks for the review, merging to master!
Issue #49092: Labels: SQL, DOCS, PYTHON
Merged to master.
Issue #49091: Labels: SQL, STRUCTURED STREAMING
cc @WweiL @HeartSaVioR 
Issue #49090: Labels: CORE
need to rebase or re-trigger the GA, thank you  @zjuwangg 
Issue #49089: Labels: SQL, CORE
Merged to master.\r\n\r\nCould you make a backporting PR to branch-3.5, @wangyum ?
Issue #49088: Labels: SQL
cc @yaooqinn @dongjoon-hyun @huaxingao 
Issue #49087: Labels: SQL
cc @HeartSaVioR @liviazhu-db 
Issue #49086: Labels: SQL
Issue #49085: Labels: SQL
@dongjoon-hyun  Could you review this renaming PR
Issue #49084: Labels: SQL, STRUCTURED STREAMING, CONNECT
Adding @cloud-fan, @stefankandic, @stevomitric, @uros-db - please take a look when you find some time, thanks!
Issue #49083: Labels: SQL, PYTHON, CONNECT
The remaining test failures are not related to this PR.
Issue #49082: Labels: DOCS, CORE
Could you review this documentation PR, @huaxingao ?
Issue #49081: Labels: DOCS
Could you review this documentation PR, @gengliangwang ?
Issue #49080: Labels: SQL
@gene-db This PR blocks Variants from being used in repartitioning.
Issue #49079: Labels: SQL
cc @dongjoon-hyun @gengliangwang @cloud-fan here is the PR to enable the SQL pipe syntax configuration by default.
Issue #49078: Labels: SQL
Issue #49077: Labels: BUILD
Issue #49076: Labels: SQL, CORE, PYTHON
Merged to master.
Issue #49075: Labels: SQL
@MaxGekk Can you take a look at this one since you have the context of the previous PR?
Issue #49074: Labels: SQL, BUILD, PYTHON, CONNECT
@dongjoon-hyun thanks, add the JIRA number
Issue #49073: Labels: SQL, PYTHON
Merged to master/3.5.
Issue #49072: Labels: SQL
@MaxGekk please review this.
Issue #49071: Labels: SQL
Also cc @LuciferYang 
Issue #49070: Labels: PYTHON, PANDAS API ON SPARK
Issue #49069: Labels: SQL
Merged to master.
Issue #49068: Labels: KUBERNETES, DOCS, INFRA
cc @dongjoon-hyun 
Issue #49067: Labels: BUILD, INFRA
step `Free up disk space`\r\n\r\nbefore:\r\n```\r\nFilesystem      Size  Used Avail Use% Mounted on\r\noverlay          73G   63G   11G  87% /\r\ntmpfs            64M     0   64M   0% /dev\r\nshm              64M     0   64M   0% /dev/shm\r\n/dev/root        73G   63G   11G  87% /__w\r\ntmpfs           3.2G  1.2M  3.2G   1% /run/docker.sock\r\ntmpfs           7.9G     0  7.9G   0% /proc/acpi\r\ntmpfs           7.9G     0  7.9G   0% /proc/scsi\r\ntmpfs           7.9G     0  7.9G   0% /sys/firmware\r\nRemoving large packages\r\nFilesystem      Size  Used Avail Use% Mounted on\r\noverlay          73G   57G   17G  78% /\r\ntmpfs            64M     0   64M   0% /dev\r\nshm              64M     0   64M   0% /dev/shm\r\n/dev/root        73G   57G   17G  78% /__w\r\ntmpfs           3.2G  1.2M  3.2G   1% /run/docker.sock\r\ntmpfs           7.9G     0  7.9G   0% /proc/acpi\r\ntmpfs           7.9G     0  7.9G   0% /proc/scsi\r\ntmpfs           7.9G     0  7.9G   0% /sys/firmware\r\n```\r\n\r\n\r\n\r\nafter:\r\n```\r\nFilesystem      Size  Used Avail Use% Mounted on\r\noverlay          73G   55G   19G  76% /\r\ntmpfs            64M     0   64M   0% /dev\r\nshm              64M     0   64M   0% /dev/shm\r\n/dev/root        73G   55G   19G  76% /__w\r\ntmpfs           3.2G  1.2M  3.2G   1% /run/docker.sock\r\ntmpfs           7.9G     0  7.9G   0% /proc/acpi\r\ntmpfs           7.9G     0  7.9G   0% /proc/scsi\r\ntmpfs           7.9G     0  7.9G   0% /sys/firmware\r\nRemoving large packages\r\nFilesystem      Size  Used Avail Use% Mounted on\r\noverlay          73G   49G   25G  67% /\r\ntmpfs            64M     0   64M   0% /dev\r\nshm              64M     0   64M   0% /dev/shm\r\n/dev/root        73G   49G   25G  67% /__w\r\ntmpfs           3.2G  1.2M  3.2G   1% /run/docker.sock\r\ntmpfs           7.9G     0  7.9G   0% /proc/acpi\r\ntmpfs           7.9G     0  7.9G   0% /proc/scsi\r\ntmpfs           7.9G     0  7.9G   0% /sys/firmware\r\n```\r\n \r\nSo applying a separate image can save ~8G for python tests.
Issue #49066: Labels: KUBERNETES, BUILD
I have already created a new PR https://github.com/apache/spark/pull/49159 for this feature (switch `default` HttpClient implementation from `OkHttp` to `Vert.x`).\r\nI will close this PR. cc @dongjoon-hyun @pan3793 
Issue #49065: Labels: SQL, STRUCTURED STREAMING
Thanks! Merging to master/3.5.
Issue #49064: Labels: SQL
Good job on testing different `NonLeafStatements` with empty compounds!
Issue #49063: Labels: SQL, STRUCTURED STREAMING
cc @siying @brkyvz PTAL
Issue #49062: Labels: SQL, CORE, CONNECT
Merging to master.
Issue #49061: Labels: SQL, Stale
Issue #49060: Labels: SQL, EXAMPLES, PYTHON
Can we file a JIRA, and add it into the PR title?
Issue #49059: Labels: SQL
cc @yaooqinn @dongjoon-hyun @cloud-fan 
Issue #49058: Labels: DOCS
+1, LGTM. Merging to master.\r\nThank you, @yaooqinn.
Issue #49057: Labels: SQL, CONNECT
@ueshin I have removed the TODO comments and enabled those tests. The SQL E2E tests only seem to test the Deserializer. Do you know of any real use-cases for the Serializer? The tests in `ArrowEncoderSuite.scala` do test both.
Issue #49056: Labels: SQL, PYTHON
Merged to master.
Issue #49055: Labels: SQL, PYTHON, CONNECT
@dongjoon-hyun I submitted a follow-up PR #49472 to fix it. Thanks. cc @xinrong-meng 
Issue #49054: Labels: SQL, PYTHON, CONNECT
cc @HyukjinKwon this fixes circular import issue mentioned from https://github.com/apache/spark/pull/48964#discussion_r1868569335
Issue #49053: Labels: SQL, KUBERNETES, SPARK SHELL, CORE, PYTHON, R, CONNECT
gonna close this for now
Issue #49052: Labels: CORE, PYTHON
Merged to master and 3.5, thank you @huangxiaopingRD @dongjoon-hyun @zhengruifeng 
Issue #49051: Labels: INFRA
Merged to master.
Issue #49050: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @yaooqinn.
Issue #49049: Labels: SQL, PYTHON
Merged to master.
Issue #49048: Labels: ML, PYTHON, CONNECT
Issue #49047: Labels: CORE
Merged to master.
Issue #49046: Labels: CORE
All tests passed.\r\n- https://github.com/dongjoon-hyun/spark/actions/runs/12145595104/job/33876924609
Issue #49045: Labels: SQL
Issue #49044: Labels: SQL, YARN, EXAMPLES, DOCS, CONNECT
Issue #49043: Labels: SQL
Please remove draft and add [SQL] component to the title of the PR.
Issue #49042: Labels: BUILD, INFRA
yes, @dongjoon-hyun I plan to split them all
Issue #49041: Labels: PYTHON
CI passed. cc @HyukjinKwon could you take a look when you find some time?
Issue #49040: Labels: BUILD
Merged into master. Thanks @yaooqinn @panbingkun 
Issue #49039: Labels: SQL
Issue #49038: Labels: SQL, ML, PYTHON, CONNECT
Merging to master.
Issue #49037: Labels: SQL
cc @dongjoon-hyun @cloud-fan @gengliangwang this is ready for review at your convenience.
Issue #49036: Labels: CORE
Merged to master.
Issue #49035: Labels: DOCS
cc @HyukjinKwon 
Issue #49034: Labels: INFRA
Merged to master~
Issue #49033: Labels: SQL, PYTHON, CONNECT
@dongjoon-hyun Sure, retriggered [here](https://github.com/ueshin/apache-spark/actions/runs/12150631150/job/33936515254). \r\nBut my GHA can\
Issue #49032: Labels: CORE
Issue #49031: Labels: SQL
thanks, merging to master!
Issue #49030: Labels: SQL
Failed test seems to be unrelated to my changes
Issue #49029: Labels: SQL
Thanks for putting in the work for this.\r\n\r\n@cloud-fan initially suggests a class diagram for the new structure. This sounds like a reasonable idea to begin with.
Issue #49028: Labels: SQL, PYTHON
cc @HyukjinKwon 
Issue #49027: Labels: SQL
@ulysses-you @cloud-fan could you pls review this PR?
Issue #49026: Labels: SQL, Stale
Issue #49025: Labels: DOCS, PYTHON
Merged to master.
Issue #49024: Labels: SQL, PYTHON
thanks, merged to master
Issue #49023: Labels: SQL, PYTHON
BTW, how many test PRs are you going to open, @xinrong-meng ?\r\n\r\nDo you think we can do that in a single batch instead of many small ones like this?
Issue #49022: Labels: SQL, CONNECT
Hi, \r\nI am curious, what is the status of this PR? Was it abandoned ?
Issue #49021: Labels: SQL
hey @viirya mind taking a quick look at this one? Fixes using `ConstantColumnVector`s with the col->row memory leak fix you merged a bit ago
Issue #49020: Labels: SQL, Stale
Issue #49019: Labels: SQL, Stale, AVRO
Issue #49018: Labels: SQL
@sadikovi @HyukjinKwon please take a look. Thanks!
Issue #49017: Labels: SQL, PYTHON
Issue #49016: Labels: SQL, CORE
Merged to master for Apache Spark 4.0.0 on February 2025.
Issue #49015: Labels: SQL, BUILD, Stale, PYTHON, CONNECT
Issue #49014: Labels: SQL, DOCS, PYTHON, CONNECT
I think it is ready for the review now. cc @HyukjinKwon and also cc @xupefei FYI
Issue #49013: Labels: BUILD, DOCS
cc @HyukjinKwon @zhengruifeng @LuciferYang @pan3793 
Issue #49012: Labels: SQL, PYTHON
Merged to master
Issue #49011: Labels: SQL, PYTHON
Merged to master, thank you!
Issue #49010: Labels: BUILD
Issue #49009: Labels: SQL, Stale, CONNECT
Issue #49008: Labels: BUILD
Test first.\r\n\r\nhttps://github.com/netty/netty/security/advisories/GHSA-xq3w-v528-46rv
Issue #49007: Labels: SQL
Merged to master.
Issue #49006: Labels: SQL
Adding @cloud-fan @davidm-db @dejankrak-db @dusantism-db @dtenedor 
Issue #49005: Labels: SQL, CORE, PYTHON
@zhengruifeng @HyukjinKwon @xinrong-meng this is the alternative/follow-on to https://github.com/apache/spark/pull/48038 that includes implementing the input side JVM batching in addition to the Python API updates
Issue #49004: Labels: SQL
cc @yaooqinn @cloud-fan @MaxGekk 
Issue #49003: Labels: SQL, CONNECT
Hi @MaxGekk can you please review this PR again? Thanks!
Issue #49002: Labels: BUILD
Issue #49001: Labels: SQL, PYTHON
Merged to master.
Issue #49000: Labels: SQL, CORE, PYTHON
That makes I/O intensive python udfs much faster! LGTM, thank you!
Issue #48999: Labels: SQL
let me convert it to draft first to avoiding merge by mistake
Issue #48998: Labels: DOCS, PYTHON
thanks, merged to master
Issue #48997: Labels: BUILD
cc @LuciferYang @dongjoon-hyun 
Issue #48996: Labels: SQL, STRUCTURED STREAMING, CORE
CI passed. Thanks! Merging to master.
Issue #48995: Labels: SQL, STRUCTURED STREAMING, BUILD
Issue #48994: Labels: SQL
@cloud-fan Failures seem unrelated, same test is failing in other PRs as well. Can you check please?
Issue #48993: Labels: SQL, STRUCTURED STREAMING
cc @dongjoon-hyun 
Issue #48992: Labels: SQL, STRUCTURED STREAMING, CORE, PYTHON
Issue #48991: Labels: SQL, STRUCTURED STREAMING
Issue #48990: Labels: SQL, STRUCTURED STREAMING
Issue #48989: Labels: SQL
@MaxGekk done
Issue #48988: Labels: SQL
thanks, merging to master!
Issue #48987: Labels: SQL
cc @MaxGekk @cloud-fan 
Issue #48986: Labels: SQL
cc @cloud-fan @zsxwing 
Issue #48985: Labels: SQL, STRUCTURED STREAMING
Thanks! Merging to master.
Issue #48984: Labels: CORE
- https://github.com/HyukjinKwon/spark/actions/runs/12045784573/job/33585064883\r\n\r\n```\r\npy4j.protocol.Py4JJavaError: An error occurred while calling o107.setLogLevel.\r\n: java.util.ConcurrentModificationException\r\n\tat java.base/java.util.HashMap$ValueSpliterator.forEachRemaining(HashMap.java:1784)\r\n\tat java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)\r\n\tat java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)\r\n\tat java.base/java.util.WeakHashMap$ValueSpliterator.forEachRemaining(WeakHashMap.java:1217)\r\n\tat java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)\r\n\tat java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)\r\n\tat java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)\r\n\tat java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)\r\n\tat java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)\r\n\tat java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)\r\n\tat org.apache.logging.log4j.core.LoggerContext.updateLoggers(LoggerContext.java:776)\r\n\tat org.apache.logging.log4j.core.LoggerContext.updateLoggers(LoggerContext.java:766)\r\n\tat org.apache.spark.util.Utils$.setLogLevel(Utils.scala:2322)\r\n\tat org.apache.spark.util.Utils$.setLogLevelIfNeeded(Utils.scala:2331)\r\n\tat org.apache.spark.SparkContext.setLogLevel(SparkContext.scala:400)\r\n\tat org.apache.spark.api.java.JavaSparkContext.setLogLevel(JavaSparkContext.scala:675)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\n```\r\n\r\nseems the problem still exists. There may  another thread traversing `org.apache.logging.log4j.core.util.internal.InternalLoggerRegistry#loggerRefByNameByMessageFactory`, but its entry point is not `Utils.setLogLevel`.\r\n\r\n
Issue #48983: Labels: SQL, CONNECT
cc @MaxGekk @cloud-fan 
Issue #48982: Labels: SQL, PYTHON, CONNECT
Issue #48981: Labels: SQL, YARN, EXAMPLES, DOCS, DSTREAM, CONNECT
cc @viirya 
Issue #48980: Labels: SQL
cc @yaooqinn @wangyum 
Issue #48979: Labels: SQL, CONNECT
Thanks @cloud-fan, also cc @MaxGekk.
Issue #48978: Labels: CORE
Merged to master.
Issue #48977: Labels: INFRA
This should be the last PR
Issue #48976: Labels: BUILD
![Uploading image.pngâ€¦]()\r\n\r\nAll Passed
Issue #48975: Labels: BUILD
Merged to master.\r\nThank you,\xa0@LuciferYang !
Issue #48974: Labels: SQL, Stale
Issue #48973: Labels: SQL, PYTHON, CONNECT
merged to master\r\n
Issue #48972: Labels: BUILD
By using environment variables `SKIP_LOCAL_M2`, the logic of `skip maven local resolver` is limited to `dev/mima` only, and the logic executed `on GA` and `on local` is already consistent.\r\n\r\nBased on this discussion https://github.com/coursier/coursier/issues/2942#issuecomment-2145674637, `coursier` (sbt relies on it) will not solve this problem in the short term.\r\n\r\n@LuciferYang @dongjoon-hyun Can we upgrade `sbt` through this workaround?
Issue #48971: Labels: SQL, DOCS, PYTHON
cc @HyukjinKwon @cloud-fan this is an alternative (and better) approach to https://github.com/apache/spark/pull/48888 to avoid necessary Python data source lookup. And it eliminates the need for users to change the static conf.
Issue #48970: Labels: BUILD
Some issue with the Jackson serialization:\r\n\r\n```\r\nCause: java.lang.RuntimeException: shaded.parquet.com.fasterxml.jackson.databind.exc.InvalidDefinitionException: No serializer found for class org.apache.parquet.schema.LogicalTypeAnnotation$ListLogicalTypeAnnotation and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationFeature.FAIL_ON_EMPTY_BEANS) (through reference chain: org.apache.parquet.hadoop.metadata.ParquetMetadata["fileMetaData"]->org.apache.parquet.hadoop.metadata.FileMetaData["schema"]->org.apache.parquet.schema.MessageType["fields"]->java.util.ArrayList[0]->org.apache.parquet.schema.GroupType["logicalTypeAnnotation"])\r\n```\r\n\r\nDigging deeper
Issue #48969: Labels: SQL, PYTHON
Merged to master.
Issue #48968: Labels: Stale, DOCS
Issue #48967: Labels: BUILD, Stale, INFRA
cc @zhengruifeng  @LuciferYang @dongjoon-hyun @HyukjinKwon
Issue #48966: Labels: PYTHON
Merged to master.
Issue #48965: Labels: SQL, CONNECT
Thank you, @yaooqinn .
Issue #48964: Labels: SQL, PYTHON
A comment for the PR description https://github.com/apache/spark/pull/48827 doesnâ€™t seem to disable â€œDataFrameQueryContextâ€ if I understand correctly :)
Issue #48963: Labels: CORE
@tgravescs Would you help to review this commit?
Issue #48962: Labels: SQL
Issue #48961: Labels: SQL
cc @srielau @gengliangwang @cloud-fan 
Issue #48960: Labels: CORE
cc @dongjoon-hyun 
Issue #48959: Labels: BUILD
Merged to master.
Issue #48958: Labels: SQL, CONNECT
A couple of small comments.
Issue #48957: Labels: BUILD
cc @panbingkun , too.
Issue #48956: Labels: SQL, Stale
Issue #48955: Labels: SQL, CONNECT
I converted this to `Draft` back in order to prevent accidental merging (without JIRA ID), @LuciferYang . Feel free to make it back to normal PR after adding JIRA ID.
Issue #48954: Labels: SQL, PYTHON, CONNECT
thanks, merged to master
Issue #48953: Labels: SQL, PYTHON
Merged to master.
Issue #48952: Labels: WEB UI
Issue #48951: Labels: SQL
@MaxGekk @cloud-fan please review this. This is an important fix for us, as we have queries failing. One example of the failed query is `set;`
Issue #48950: Labels: SQL
Adding @cloud-fan @dejankrak-db @davidm-db @dusantism-db @MaxGekk
Issue #48949: Labels: SQL, PYTHON
Thank you @dtenedor \r\n\r\nMerged to master, thank you all!
Issue #48948: Labels: INFRA
Thank you, @HyukjinKwon and @zhengruifeng . \r\nMerged to master.
Issue #48947: Labels: SQL, Stale, INFRA, PYTHON, R
Issue #48946: Labels: SQL
Although I saw the following PR, can we use the latest version, @panbingkun ?\r\n- #48897
Issue #48945: Labels: BUILD
Merged to master. Thank you, @panbingkun .
Issue #48944: Labels: SQL, STRUCTURED STREAMING
Issue #48943: Labels: SQL
cc @cloud-fan and @viirya 
Issue #48942: Labels: DOCS
+1, LGTM. Merging to master.\r\nThank you, @camilesing.
Issue #48941: Labels: No Labels
Thanks @raboof for pointing that out. Duly noted and updated the PR description accordingly.
Issue #48940: Labels: SQL
cc @cloud-fan @gengliangwang here is the `|> SET` operator :)
Issue #48939: Labels: SQL, DEPLOY
+1, LGTM. Merging to master.\r\nThank you, @dongjoon-hyun.
Issue #48938: Labels: DOCS, CORE
All tests passed.
Issue #48937: Labels: Stale
Not sure what "workflow run detection" is, or how to correct it.\r\nThe output of `git remote -vv` is:\r\n```\r\n# git remote -vv\r\norigin  https://github.com/philwalk/spark.git (fetch)\r\norigin  https://github.com/philwalk/spark.git (push)\r\n```
Issue #48936: Labels: SQL
@cloud-fan please take a look when you get the chance.\r\n\r\nYou raised some valid concerns in the last PR about structs and maps so I think I was able to figure out a nice way to have it work for all data types :)
Issue #48935: Labels: SQL, PYTHON
+1, LGTM. Merging to master.\r\nThank you, @zhengruifeng.
Issue #48934: Labels: SQL
I believe the cause was https://github.com/apache/spark/pull/48120. This is a followup for it.
Issue #48933: Labels: Stale, DOCS
@HyukjinKwon @yaooqinn @allisonwang-db perhaps you could reopen and review? :heart: 
Issue #48932: Labels: INFRA
Issue #48931: Labels: SQL, PYTHON
Merged to master.
Issue #48930: Labels: SQL, ML, MLLIB, STRUCTURED STREAMING, KUBERNETES, SPARK SHELL, DOCS, CORE, INFRA, PYTHON, R, AVRO, PANDAS API ON SPARK, CONNECT, PROTOBUF
gonna close this for now
Issue #48929: Labels: SQL, PYTHON
Merged to master.
Issue #48928: Labels: SQL
cc @dongjoon-hyun and @yaooqinn 
Issue #48927: Labels: SQL, STRUCTURED STREAMING, PYTHON
cc - @HeartSaVioR - PTAL, thx !
Issue #48926: Labels: SQL, PYTHON, PANDAS API ON SPARK, CONNECT
thanks, merged to master
Issue #48925: Labels: SQL, Stale
Issue #48924: Labels: CORE
Could you review this PR, @panbingkun ?
Issue #48923: Labels: CORE
Thank you, @viirya !
Issue #48922: Labels: DOCS
Merged to master.
Issue #48921: Labels: CORE
The newly added UT passed already in the CIs.\r\n- https://github.com/dongjoon-hyun/spark/actions/runs/11958476555/job/33338110615\r\n```\r\n[info] - SPARK-50381: Support spark.master.rest.maxThreads (15 milliseconds)\r\n```
Issue #48920: Labels: SQL, CONNECT
> Looks good but mind listing up affected API in the PR description?\r\n\r\nDone!
Issue #48919: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @yaooqinn.
Issue #48918: Labels: SQL
cc @yaooqinn @viirya 
Issue #48917: Labels: SQL
Issue #48916: Labels: DOCS
+1, LGTM. Merging to master.\r\nThank you, @camilesing.
Issue #48915: Labels: SQL
cc @cloud-fan 
Issue #48914: Labels: SQL, PYTHON, CONNECT
Issue #48913: Labels: SQL, STRUCTURED STREAMING
cc - @HeartSaVioR - PTAL, thx !
Issue #48912: Labels: SQL
cc @yaooqinn @LuciferYang 
Issue #48911: Labels: ML, PYTHON, CONNECT
Merged to master.
Issue #48910: Labels: BUILD
+1, LGTM. Merging to master.\r\nThank you, @panbingkun.
Issue #48909: Labels: SQL
@gene-db @cloud-fan Can you please look at this? Thanks!
Issue #48908: Labels: SQL
BTW, FYI, I added you to the Apache Spark `Committers` group in ASF JIRA system in a few minutes ago.\r\n\r\n**BEFORE**\r\n![Screenshot 2024-11-20 at 08 36 52](https://github.com/user-attachments/assets/ea6bcdaa-61f7-4a6c-9d47-b76be8482a9f)\r\n\r\n**AFTER**\r\n![Screenshot 2024-11-20 at 08 37 02](https://github.com/user-attachments/assets/ad082ca7-9d84-4a26-af1e-4bb116692946)
Issue #48907: Labels: SQL
Issue #48906: Labels: SQL
cc @itholic too
Issue #48905: Labels: SQL
Related issue [SPARK-50364](https://issues.apache.org/jira/browse/SPARK-50364)
Issue #48904: Labels: SQL, PYTHON
Merged to master.
Issue #48903: Labels: SQL, Stale
Issue #48902: Labels: BUILD, INFRA
Merged to master.
Issue #48901: Labels: ML, PYTHON, CONNECT
thanks, merged to master
Issue #48900: Labels: INFRA
thanks, merged to master
Issue #48899: Labels: DOCS
Merged to master and 3.5
Issue #48898: Labels: BUILD
LGTM thank you!
Issue #48897: Labels: SQL
Merged to master.
Issue #48896: Labels: CORE
Issue #48895: Labels: SQL
cc @cloud-fan  @MaxGekk @dongjoon-hyun 
Issue #48894: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @mihailoale-db and @dtenedor for review.
Issue #48893: Labels: SQL
@cloud-fan @MaxGekk could you review this change
Issue #48892: Labels: SQL, PYTHON
Merged to master.
Issue #48891: Labels: SQL, PYTHON
Merged to master.
Issue #48890: Labels: SQL, BUILD, DOCS
cc @dongjoon-hyun @LuciferYang 
Issue #48889: Labels: SQL, AVRO
> cc @gengliangwang\r\n\r\nThanks @MaxGekk !
Issue #48888: Labels: SQL, PYTHON
This PR no longer needed (replaced by https://github.com/apache/spark/pull/48971)
Issue #48887: Labels: SQL, PYTHON, CONNECT
my concern is that the pandas conversion is out of control, what about introducing a similar check in `numpy -> pyarrow`?
Issue #48886: Labels: SQL
Merged into master for Spark 4.0. Thanks @yaooqinn @HyukjinKwon and @panbingkun 
Issue #48885: Labels: SQL, STRUCTURED STREAMING, BUILD
LGTM
Issue #48884: Labels: SQL, STRUCTURED STREAMING, BUILD, CORE, PYTHON
> UDS is recommended for same-host processes communication\r\n\r\nShould we better change all usage in Python worker communication instead of this alone?
Issue #48883: Labels: SQL, CONNECT
@mihailom-db
Issue #48882: Labels: CORE
@cloud-fan @yaooqinn I think this should handle nested LazyTries (as exhibited by the chain of plans in QueryExecutions) nicely.
Issue #48881: Labels: SQL
Issue #48880: Labels: SQL, STRUCTURED STREAMING
@siying @brkyvz PTAL
Issue #48879: Labels: SQL, CONNECT
Adding @cloud-fan @davidm-db @dejankrak-db @dusantism-db 
Issue #48878: Labels: SQL, Stale, DOCS
Issue #48877: Labels: SQL, PYTHON
Merged to master.
Issue #48876: Labels: SQL
@MaxGekk please take a look at this one.
Issue #48875: Labels: SQL, PYTHON, CONNECT
LGTM thank you!
Issue #48874: Labels: SQL, PROTOBUF
+1, LGTM. Merging to master.\r\nThank you, @panbingkun.
Issue #48873: Labels: SQL, CONNECT
+1, LGTM. Merging to master.\r\nThank you, @panbingkun and @dtenedor for review.
Issue #48872: Labels: SQL
@LuciferYang If java21 is affected, it should have happened in the previous PR.
Issue #48871: Labels: GRAPHX, Stale
shall we add a test for it?
Issue #48870: Labels: SQL, BUILD
cc @yaooqinn FYI
Issue #48869: Labels: INFRA
Issue #48868: Labels: INFRA
- https://github.com/LuciferYang/spark/actions/runs/11854044932/job/33035384447\r\n\r\nThe test was largely successful, except for the modules related to mllib, which seems to need some fix to the test cases on macos. I think we can fix them this in the followup.\r\n\r\n```\r\n test_data_loader (pyspark.ml.tests.connect.test_parity_torch_data_loader.TorchDistributorBaselineUnitTestsOnConnect.test_data_loader) ... WARNING: Using incubator modules: jdk.incubator.vector\r\nSetting default log level to "WARN".\r\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\r\nStarted distributed training with 1 executor processes\r\nW1115 13:42:15.675000 65006 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\r\nW1115 13:42:15.675000 65006 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\r\nTraceback (most recent call last):\r\n  File "/Users/runner/work/spark/spark/python/target/5c60ac90-7dd0-42ad-9c5f-4700f5cf9926/tmpg209ldzx/train.py", line 8, in <module>\r\n    output = fn(*args, **kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^\r\n  File "/Users/runner/work/spark/spark/python/pyspark/ml/torch/tests/test_data_loader.py", line 71, in train_function\r\n    return list(data_loader)\r\n           ^^^^^^^^^^^^^^^^^\r\n  File "/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 484, in __iter__\r\n    return self._get_iterator()\r\n           ^^^^^^^^^^^^^^^^^^^^\r\n  File "/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 415, in _get_iterator\r\n    return _MultiProcessingDataLoaderIter(self)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1138, in __init__\r\n    w.start()\r\n  File "/opt/homebrew/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py", line 121, in start\r\n    self._popen = self._Popen(self)\r\n                  ^^^^^^^^^^^^^^^^^\r\n  File "/opt/homebrew/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/context.py", line 224, in _Popen\r\n    return _default_context.get_context().Process._Popen(process_obj)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/opt/homebrew/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/context.py", line 288, in _Popen\r\n    return Popen(process_obj)\r\n           ^^^^^^^^^^^^^^^^^^\r\n  File "/opt/homebrew/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_spawn_posix.py", line 32, in __init__\r\n    super().__init__(process_obj)\r\n  File "/opt/homebrew/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__\r\n    self._launch(process_obj)\r\n  File "/opt/homebrew/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_spawn_posix.py", line 47, in _launch\r\n    reduction.dump(process_obj, fp)\r\n  File "/opt/homebrew/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/reduction.py", line 60, in dump\r\n    ForkingPickler(file, protocol).dump(obj)\r\nAttributeError: Can\
Issue #48867: Labels: SQL
cc @cloud-fan @manuzhang since you recently worked on similar changes
Issue #48866: Labels: SQL, STRUCTURED STREAMING
Issue #48865: Labels: SQL
I am fine with this change but just wanted to make sure - does it affect any end-user usecase?
Issue #48864: Labels: SQL, BUILD, PYTHON, CONNECT
Issue #48863: Labels: SQL, BUILD, PYTHON, CONNECT
Issue #48862: Labels: SQL, STRUCTURED STREAMING
Thanks! Merging to master.
Issue #48861: Labels: SQL, Stale, PYTHON
Issue #48860: Labels: BUILD, DOCS
The verification process is as follows:\r\n\r\n- Run the following command:\r\n```shell\r\nsh dev/spark-test-image/docs/build-docs-on-local\r\n```\r\n\r\n- The process of run is as follows:\r\n```shell\r\n[info] Note: Some input files use or override a deprecated API.\r\n[info] Note: Recompile with -Xlint:deprecation for details.\r\n[warn] multiple main classes detected: run \
Issue #48859: Labels: BUILD, INFRA
thanks, merged to master
Issue #48858: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @vladimirg-db.
Issue #48857: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @vladimirg-db.
Issue #48856: Labels: SQL, PYTHON, CONNECT
LGTM thank you!
Issue #48855: Labels: SQL
cc @cloud-fan 
Issue #48854: Labels: SQL, DOCS
The implementation for this PR ended up getting too big. I can split this into separate PRs.
Issue #48853: Labels: SQL, STRUCTURED STREAMING
@neilramaswamy - thx for writing up a detailed PR description !
Issue #48852: Labels: DOCS
cc @cloud-fan @gengliangwang here is documentation support for the new SQL pipe syntax, which is nearly completed.
Issue #48851: Labels: SQL
@gene-db @cashmand @cloud-fan could you help review? Thanks!
Issue #48850: Labels: CORE
cc @HyukjinKwon 
Issue #48849: Labels: SQL, Stale
Issue #48848: Labels: SQL
Issue #48847: Labels: SQL
Merging to master. Thank you, @srielau and @cloud-fan for review.
Issue #48846: Labels: BUILD
This was tested during RC vote.\r\n- https://github.com/dongjoon-hyun/spark/pull/22
Issue #48845: Labels: BUILD
This was tested during RC vote.\r\n- https://github.com/dongjoon-hyun/spark/pull/21
Issue #48844: Labels: SQL, Stale
Issue #48843: Labels: SQL, DOCS, CORE, PYTHON, CONNECT
LGTM thank you!
Issue #48842: Labels: SQL
cc @dongjoon-hyun as the initiator of SPARK-44444, also cc @cloud-fan, thank you
Issue #48841: Labels: SQL, PYTHON, CONNECT
Merged to master, thank you!
Issue #48840: Labels: DOCS, PYTHON
LGTM thank you!
Issue #48839: Labels: PYTHON
Merged to master.
Issue #48838: Labels: SQL, STRUCTURED STREAMING, CORE, PYTHON
CI has passed: https://github.com/jingz-db/spark/runs/33636466911\r\n\r\nThanks! Merging to master.
Issue #48837: Labels: BUILD
Could you review this PR, @viirya ?
Issue #48836: Labels: BUILD
Could you review this PR, @huaxingao ?
Issue #48835: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @mihailom-db and @cloud-fan @dbatomic for review.
Issue #48834: Labels: BUILD
cc @dongjoon-hyun and @panbingkun 
Issue #48833: Labels: SQL
@MaxGekk please take a look for this revert as we discussed offline.
Issue #48832: Labels: SQL, PYTHON
Merged to master.
Issue #48831: Labels: SQL, PYTHON, CONNECT
LGTM thank you!
Issue #48830: Labels: SQL
cc @cloud-fan Can you take a look? I saw you originally implemented the Staged Table interface
Issue #48829: Labels: SQL
shall we add a test for it?
Issue #48828: Labels: SQL, PYTHON
merged to master
Issue #48827: Labels: SQL
Merged to master.
Issue #48826: Labels: SQL, BUILD, INFRA, PYTHON, CONNECT
also cc @panbingkun 
Issue #48825: Labels: SQL, Stale, CORE
Will setting the following config handle skew cases?\r\n```\r\n--conf spark.shuffle.accurateBlockSkewedFactor=10;\r\n--conf spark.shuffle.accurateBlockThreshold=209715200;\r\n--conf spark.shuffle.maxAccurateSkewedBlockNumber=60\r\n```
Issue #48824: Labels: BUILD, INFRA
thanks, I am also considering similar optimization, we can do it later, since I plan to spin more envs off :)
Issue #48823: Labels: SQL, BUILD, DOCS
ðŸ‘ðŸ»  Thank you so much for taking over this, @yaooqinn .
Issue #48822: Labels: SQL
cc @szehon-ho @cloud-fan @dongjoon-hyun
Issue #48821: Labels: SQL, AVRO
cc @liujiayi771 @cloud-fan @dongjoon-hyun 
Issue #48820: Labels: SQL, PYTHON
cc @ueshin @HyukjinKwon @xinrong-meng @allisonwang-db 
Issue #48819: Labels: SQL, Stale
Issue #48818: Labels: SQL, ML, MLLIB, STRUCTURED STREAMING, WEB UI, BUILD, SPARK SHELL, CORE, PYTHON, R, CONNECT
For anyone interested. I have opened this up so people can take a look. I still need to make a bunch of changes.
Issue #48817: Labels: SQL, BUILD, INFRA, PYTHON, CONNECT
On second thought, maybe we should also add a new image for lint? so that we can upgrade docs and lint separately
Issue #48816: Labels: ML
Merged to master for Apache Spark 4.0 on February 2025.\r\n\r\nThank you, @zhengruifeng .
Issue #48815: Labels: SQL, STRUCTURED STREAMING, BUILD, INFRA, PYTHON
cc @HyukjinKwon @zhengruifeng @dongjoon-hyun @HeartSaVioR @bogao007 
Issue #48814: Labels: SQL, PYTHON
LGTM thank you!
Issue #48813: Labels: DOCS, PYTHON
Issue #48812: Labels: SQL, PYTHON
Mind answering the rest of the questions in the PR description?
Issue #48811: Labels: SQL, Stale
Mind filien a JIRA please?
Issue #48810: Labels: BUILD
```shell\r\n./build/sbt -Phadoop-3 -Pkubernetes -Pkinesis-asl -Phive-thriftserver -Pdocker-integration-tests -Pyarn -Phadoop-cloud -Pspark-ganglia-lgpl -Phive -Pjvm-profiler clean package\r\n```\r\n\r\n```shell\r\n[info] Note: Some input files use or override a deprecated API.\r\n[info] Note: Recompile with -Xlint:deprecation for details.\r\n[warn] multiple main classes detected: run \
Issue #48809: Labels: SQL, PYTHON
LGTM, thank you!
Issue #48808: Labels: SQL, PYTHON
@HeartSaVioR Could you help review this change? Thanks!
Issue #48807: Labels: CORE
cc @JoshRosen 
Issue #48806: Labels: SQL, STRUCTURED STREAMING
cc - @HeartSaVioR @liviazhu-db - PTAL, thx !
Issue #48805: Labels: SQL, BUILD, PYTHON
@HeartSaVioR Could you help review this change? Thanks!
Issue #48804: Labels: SQL
> @stevomitric Could you regenerate results of the benchmark CollationBenchmark, please. We should expect better numbers after your changes, right?\r\n\r\nThey are running, I will post them here once complete. We should expect same or better results.
Issue #48803: Labels: SQL
thanks, merging to master!
Issue #48802: Labels: SQL, PYTHON, CONNECT
Merged to master.
Issue #48801: Labels: SQL, Stale
Can we have a simple test?
Issue #48800: Labels: SQL, STRUCTURED STREAMING, CONNECT
Issue #48799: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @dejankrak-db.
Issue #48798: Labels: SQL, BUILD
> @milastdbx Could you review this PR, please.\r\n\r\nThanks @MaxGekk !
Issue #48797: Labels: ML
cc @rebo16v @srowen @HyukjinKwon @WeichenXu123 
Issue #48796: Labels: SQL
Issue #48795: Labels: SQL
Adding: @cloud-fan @srielau @davidm-db @dejankrak-db @dusantism-db  
Issue #48794: Labels: SQL
@davidm-db @miland-db Rebased, you can review again
Issue #48793: Labels: SQL
thanks, merging to master!
Issue #48792: Labels: SQL, CONNECT
Merged to master.
Issue #48791: Labels: SQL, ML, MLLIB, BUILD, PYTHON, CONNECT
@michTalebzadeh the idea is that we give Spark Connect users the same functionality as existing classic users.
Issue #48790: Labels: BUILD
Link to tests: https://github.com/Fokko/spark/actions/runs/11720553983/job/32646109185
Issue #48789: Labels: SQL
cc @cloud-fan 
Issue #48788: Labels: SQL, CORE, PYTHON
Could you review this PR, @viirya ?
Issue #48787: Labels: SQL
thanks, merging to master!
Issue #48786: Labels: SQL
Gentle ping, @cloud-fan .
Issue #48785: Labels: SQL, PYTHON
Merged to master.\r\n\r\nThank you @zhengruifeng @HyukjinKwon 
Issue #48784: Labels: PYTHON, PANDAS API ON SPARK
Merged to master.\r\n\r\nThank you @zhengruifeng @dongjoon-hyun 
Issue #48783: Labels: SQL, STRUCTURED STREAMING
Thanks! Merging to master.
Issue #48782: Labels: CORE
cc @viirya 
Issue #48781: Labels: DOCS, PYTHON
Could you review this, @xinrong-meng and @zhengruifeng ?
Issue #48780: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @itholic.
Issue #48779: Labels: SQL
> So If I understand correctly, the shredding write chain may be like this:\r\nGet the expected shredded schema (DataType) through some ways (sampling or justs user defined?) -> parquet writer accepts the variant + shredded schema -> cast to shredded InternalRow -> write to parquet file (the actual col type is the group type corresponding to the shredded dataType).\r\n\r\nYes, exactly. For initial implementation and testing, I plan to set the schema explicitly. I think sampling makes sense as a better user experience in the long term, but needs some thought about the best way to implement it.\r\n\r\n> From this perspective, consider the integration with the lake format, lake format generally has its own reader or writer. I feel like that the lake format may still receive the raw variant data, and the same shredding logic must be implemented in the format\
Issue #48778: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @itholic.
Issue #48777: Labels: SQL
Oh. Good to know. Thank you for closing. 
Issue #48776: Labels: CORE
cc @Ngone51 , @cloud-fan 
Issue #48775: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @itholic.
Issue #48774: Labels: SQL
@MaxGekk @stefankandic can you please take a look at this PR?
Issue #48773: Labels: SQL
Had a conversation with @mihailom-db.\r\nWe should use `INTERVAL_ARITHMETIC_OVERFLOW`, add 2 subclasses to it: with hint and without hint and use "without_hint" variation for `Make[DT|YM]Interval`.
Issue #48772: Labels: SQL
cc @cloud-fan, thank you in advance
Issue #48771: Labels: BUILD
we should change to exclude \r\n\r\n```\r\n<exclusion> \r\n       <groupId>io.netty</groupId> \r\n       <artifactId>*</artifactId> \r\n     </exclusion> \r\n```\r\n\r\nfrom zookeeper instead of\r\n\r\n```\r\n<exclusion> \r\n       <groupId>org.jboss.netty</groupId> \r\n       <artifactId>netty</artifactId> \r\n     </exclusion> \r\n```\r\n\r\n\r\n`org.jboss.netty` is the groupId of netty 3.x\r\n\r\n\r\nHowever, I believe it would be better to upgrade netty to 4.1.113, because zk 3.9.3 was compiled with a dependency on netty 4.1.113. Downgrading to use 4.1.110 may introduce uncertainties and potential issues.
Issue #48770: Labels: SQL, PYTHON
cc @allisonwang-db @ueshin 
Issue #48769: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @itholic.
Issue #48768: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @itholic.
Issue #48767: Labels: SQL
Merged to master and 3.5\r\n\r\nThank you @viirya @dongjoon-hyun 
Issue #48766: Labels: SQL, PYTHON
cc @xinrong-meng 
Issue #48765: Labels: SQL
cc @dongjoon-hyun @huaxingao 
Issue #48764: Labels: ML, PYTHON, CONNECT
This should be the last one
Issue #48763: Labels: BUILD
Merged to master.
Issue #48762: Labels: SQL
thanks, merging to master!
Issue #48761: Labels: SQL, PYTHON, CONNECT
thanks all, merged to master
Issue #48760: Labels: SQL
@MaxGekk @stefankandic @stevomitric can you please take a look at this PR?
Issue #48759: Labels: SQL
also cc @uros-db @stefankandic @c27kwan
Issue #48758: Labels: SQL
cc @cloud-fan @dongjoon-hyun @LuciferYang thanks
Issue #48757: Labels: SQL, STRUCTURED STREAMING, BUILD, INFRA, PYTHON
~Currently, I have written a new script with reference to `connect-gen-protos.sh` and `connect-check-protos.py` without merging them into one. If it would be better to integrate them, perhaps by unifying them into a single script like `gen-protos.sh` and using different parameters to accomplish different tasks, please let me know.~
Issue #48756: Labels: SQL, PYTHON, CONNECT
Test first
Issue #48755: Labels: SQL
Could you review this PR, @viirya ?
Issue #48754: Labels: SQL
Looking at this more, the proposed semantics would not be consistent with how aggregation works with pipe operators, where the GROUP BY expressions arrive out of the operator followed by the aggregate functions. I will close this.\r\n\r\nAs an aside, we might want to consider returning errors if any of the aggregate functions contain column references that are not aggregated, since the pipe operator returns the grouping expressions and it is always possible to use a projection (`|> SELECT`) afterwards based on the grouping/aggregate functions.
Issue #48753: Labels: SQL
Can we file a JIRA please?
Issue #48752: Labels: BUILD
Merged to master for Apache Spark 4.0.0 on February 2025.\r\nThank you, @HyukjinKwon and @zhengruifeng .
Issue #48751: Labels: BUILD
Thank you, @HyukjinKwon !
Issue #48750: Labels: SQL, CONNECT
I think the failed test is not related to the changes:\r\n```\r\n[info] OracleIntegrationSuite:\r\n[info] org.apache.spark.sql.jdbc.v2.OracleIntegrationSuite *** ABORTED *** (10 minutes, 19 seconds)\r\n[info]   The code passed to eventually never returned normally. Attempted 589 times over 10.001613945816667 minutes. Last failure \r\n```\r\n\r\n+1, LGTM. Merging to master.\r\nThank you, @stefankandic and @dongjoon-hyun @HyukjinKwon for review.
Issue #48749: Labels: SQL
@MaxGekk @stevomitric please take a look at this PR
Issue #48748: Labels: SQL, PYTHON
Used https://github.com/apache/spark/pull/42398 as a base. Thanks to @Hisoka-X for that pr!  
Issue #48747: Labels: ML
Issue #48746: Labels: BUILD
Issue #48745: Labels: SQL, CONNECT
@LuciferYang Hi, this should fix the reattach execute suite failure in branch-3.5.
Issue #48744: Labels: BUILD, INFRA
cc @dongjoon-hyun @HyukjinKwon  FYI\r\nThis is an issue that only exists in branch-3.5.
Issue #48743: Labels: ML, PYTHON, CONNECT
Merged to master. Thank you, @HyukjinKwon .
Issue #48742: Labels: CORE
Could you review this PR, @LuciferYang ?
Issue #48741: Labels: INFRA
All tests passed.
Issue #48740: Labels: CORE
Could you review this when you have some time, @viirya ?
Issue #48739: Labels: SQL
Added more test, @MaxGekk can we merge this?
Issue #48738: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @vladimirg-db.
Issue #48737: Labels: SQL
@stevomitric @stefankandic @cloud-fan please take a look
Issue #48736: Labels: SQL
@dongjoon-hyun Could you review this PR?
Issue #48735: Labels: SQL, PYTHON
Merged to master.
Issue #48734: Labels: PYTHON
Merged to master.
Issue #48733: Labels: CORE, PYTHON
cc @HyukjinKwon 
Issue #48732: Labels: ML, PYTHON, CONNECT
Merged to master.
Issue #48731: Labels: BUILD
Merged to master.
Issue #48730: Labels: SQL, PYTHON, CONNECT
Could you check the pyspark unit test failures and Python linter failures, @ueshin ?
Issue #48729: Labels: CORE
Thank you, @viirya !
Issue #48728: Labels: SQL, STRUCTURED STREAMING, PYTHON
cc - @jingz-db @HeartSaVioR - PTAL, thx !
Issue #48727: Labels: SQL, STRUCTURED STREAMING, BUILD, EXAMPLES, DOCS, CORE, INFRA, PYTHON, AVRO, PANDAS API ON SPARK, CONNECT, PROTOBUF
Issue #48726: Labels: SQL, STRUCTURED STREAMING
cc - @jerrypeng @HeartSaVioR - PTAL, thx !
Issue #48725: Labels: SQL, CONNECT
Got it. Thank you for updating the PR description.
Issue #48724: Labels: SQL
Mind filing a JIRA please?
Issue #48723: Labels: KUBERNETES
cc @yaooqinn 
Issue #48722: Labels: SQL, PYTHON
Merged to master for Apache Spark 4.0.0 on February 2025.\r\n\r\nThank you, @zhengruifeng .
Issue #48721: Labels: SQL, BUILD
Let me update the benchmark result of `CollationBenchmark` and `CollationNonASCIIBenchmark`\r\n\r\n- `CollationBenchmark`\r\nJDK 17: https://github.com/panbingkun/spark/actions/runs/11611219685\r\nJDK 21: https://github.com/panbingkun/spark/actions/runs/11611222464\r\n\r\n- `CollationNonASCIIBenchmark`\r\nJDK 17: https://github.com/panbingkun/spark/actions/runs/11611241052\r\nJDK 21: https://github.com/panbingkun/spark/actions/runs/11611243469\r\n
Issue #48720: Labels: SQL, SPARK SHELL, CORE, PYTHON, CONNECT
cc @zhengruifeng @HyukjinKwon @LuciferYang 
Issue #48719: Labels: INFRA
Merged to master.
Issue #48718: Labels: SQL, EXAMPLES
Could you review this PR, @LuciferYang ?
Issue #48717: Labels: SQL, STRUCTURED STREAMING
Thanks to @HyukjinKwon , today I will add the PR description.\r\n\r\n
Issue #48716: Labels: SQL, STRUCTURED STREAMING, BUILD, DOCS, PYTHON, DSTREAM, AVRO, CONNECT, PROTOBUF
Issue #48715: Labels: SQL, PYTHON, PANDAS API ON SPARK
LGTM thank you!
Issue #48714: Labels: EXAMPLES
Please note that. This depends on the following to provide the simplest example.\r\n- #48711
Issue #48713: Labels: BUILD, DOCS, INFRA
cc @HyukjinKwon 
Issue #48712: Labels: BUILD
Issue #48711: Labels: EXAMPLES, CORE
All `core` tests passed. \r\n\r\nCould you review this PR, @viirya ?
Issue #48710: Labels: SQL
cc - @ericm-db @HeartSaVioR - PTAL, thx !
Issue #48709: Labels: BUILD
Could you review this, please, @xinrong-meng ?
Issue #48708: Labels: BUILD
Could you review this PR, @huaxingao ?
Issue #48707: Labels: SQL
@MaxGekk tests passed, one unrelated suite failed\r\n![image](https://github.com/user-attachments/assets/ccbaf949-1689-4071-9970-596f066e88c0)\r\n
Issue #48706: Labels: SQL
Merged to master.
Issue #48705: Labels: SQL, PYTHON
Nice work!\r\n\r\nJust wanted to add that PySparkHistogramPlotBase.get_bins can also benefit from this change to remove numpy dependency later.
Issue #48704: Labels: BUILD
According to the commit list, it looks safe. Please let me know when the PR is ready, @LuciferYang .
Issue #48703: Labels: SQL, PYTHON, PANDAS API ON SPARK
LGTM, thank you!
Issue #48702: Labels: SQL
- RegExpReplaceBenchmark\r\n```scala\r\nobject RegExpReplaceBenchmark extends SqlBasedBenchmark {\r\n  private val N = 1000000 // 10_000_00\r\n  private val M = 100\r\n\r\n  private val df = spark.range(N).to(new StructType().add("id", "int")).\r\n    withColumn("subject", concat(col("id"), lit("-"), col("id") * 2)).\r\n    withColumn("regexp", lit("(\\\\d+)")).\r\n    withColumn("rep", lit("num"))\r\n\r\n  private def doBenchmark(): Unit = {\r\n    df.selectExpr("regexp_replace(subject, regexp, rep)").noop()\r\n  }\r\n\r\n  override def runBenchmarkSuite(mainArgs: Array[String]): Unit = {\r\n    runBenchmark("regexp_replace") {\r\n      val benchmark = new Benchmark("regexp_replace", N, output = output)\r\n      benchmark.addCase("optimize", M) { _ =>\r\n        doBenchmark()\r\n      }\r\n      benchmark.run()\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n- Before (Run `3` times)\r\n```shell\r\nRunning benchmark: regexp_replace\r\n  Running case: optimize\r\n  Stopped after 100 iterations, 40159 ms\r\n\r\nOpenJDK 64-Bit Server VM 17.0.10+7-LTS on Mac OS X 15.1\r\nApple M2\r\nregexp_replace:                           Best Time(ms)   Avg Time(ms)   Stdev(ms)    Rate(M/s)   Per Row(ns)   Relative\r\n------------------------------------------------------------------------------------------------------------------------\r\noptimize                                            389            402          12          2.6         389.4       1.0X\r\n\r\n\r\nRunning benchmark: regexp_replace\r\n  Running case: optimize\r\n  Stopped after 100 iterations, 41644 ms\r\n\r\nOpenJDK 64-Bit Server VM 17.0.10+7-LTS on Mac OS X 15.1\r\nApple M2\r\nregexp_replace:                           Best Time(ms)   Avg Time(ms)   Stdev(ms)    Rate(M/s)   Per Row(ns)   Relative\r\n------------------------------------------------------------------------------------------------------------------------\r\noptimize                                            406            416          14          2.5         405.5       1.0X\r\n\r\n\r\nRunning benchmark: regexp_replace\r\n  Running case: optimize\r\n  Stopped after 100 iterations, 39469 ms\r\n\r\nOpenJDK 64-Bit Server VM 17.0.10+7-LTS on Mac OS X 15.1\r\nApple M2\r\nregexp_replace:                           Best Time(ms)   Avg Time(ms)   Stdev(ms)    Rate(M/s)   Per Row(ns)   Relative\r\n------------------------------------------------------------------------------------------------------------------------\r\noptimize                                            385            395          11          2.6         385.0       1.0X\r\n\r\n```\r\n\r\n- After (Run `3` times)\r\n```\r\nRunning benchmark: regexp_replace\r\n  Running case: optimize\r\n  Stopped after 100 iterations, 35651 ms\r\n\r\nOpenJDK 64-Bit Server VM 17.0.10+7-LTS on Mac OS X 15.1\r\nApple M2\r\nregexp_replace:                           Best Time(ms)   Avg Time(ms)   Stdev(ms)    Rate(M/s)   Per Row(ns)   Relative\r\n------------------------------------------------------------------------------------------------------------------------\r\noptimize                                            341            357          23          2.9         340.9       1.0X\r\n\r\n\r\nRunning benchmark: regexp_replace\r\n  Running case: optimize\r\n  Stopped after 100 iterations, 37869 ms\r\n\r\nOpenJDK 64-Bit Server VM 17.0.10+7-LTS on Mac OS X 15.1\r\nApple M2\r\nregexp_replace:                           Best Time(ms)   Avg Time(ms)   Stdev(ms)    Rate(M/s)   Per Row(ns)   Relative\r\n------------------------------------------------------------------------------------------------------------------------\r\noptimize                                            368            379          12          2.7         367.8       1.0X\r\n\r\n\r\nRunning benchmark: regexp_replace\r\n  Running case: optimize\r\n  Stopped after 100 iterations, 34783 ms\r\n\r\nOpenJDK 64-Bit Server VM 17.0.10+7-LTS on Mac OS X 15.1\r\nApple M2\r\nregexp_replace:                           Best Time(ms)   Avg Time(ms)   Stdev(ms)    Rate(M/s)   Per Row(ns)   Relative\r\n------------------------------------------------------------------------------------------------------------------------\r\noptimize                                            328            348          16          3.0         328.2       1.0X\r\n```
Issue #48701: Labels: SQL, PYTHON, CONNECT
+1, LGTM. Merging to master.\r\nThank you, @xinrong-meng and @zhengruifeng for review.
Issue #48700: Labels: SQL, AVRO
cc @dongjoon-hyun @MaxGekk 
Issue #48699: Labels: SQL
cc @cloud-fan @MaxGekk 
Issue #48698: Labels: BUILD
cc @dongjoon-hyun @LuciferYang 
Issue #48697: Labels: SQL, STRUCTURED STREAMING
@siying, I discussed this with @anishshri-db but it will be difficult to propagate this uniqueID across `load` and `commit`/`commitAsync` calls (so that the `load` acquire pass the id to the `commit` release). This will likely need a higher-level API change which we can consider for a larger long-term fix.
Issue #48696: Labels: BUILD
Could you review this, @LuciferYang ?
Issue #48695: Labels: SQL, STRUCTURED STREAMING, Stale, DOCS
Hi! @HeartSaVioR, I skimmed the history to find someone who might be able to review this change and came across you. Would you have time to have a look?
Issue #48694: Labels: SQL, PYTHON
Thank you, @zhengruifeng and @MaxGekk .\r\nMerged to master for Apache Spark 4.0.0 on February 2025.
Issue #48693: Labels: SQL
@dongjoon-hyun Please take a look again. Thanks.
Issue #48692: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @itholic.
Issue #48691: Labels: SQL, AVRO
+1, LGTM. Merging to master.\r\nThank you, @panbingkun.
Issue #48690: Labels: BUILD, INFRA
also cc @yaooqinn 
Issue #48689: Labels: SQL
[Run / Build modules: sql - other tests](https://github.com/itholic/spark/actions/runs/11603964645/job/32311941897#logs) passed on the previous commit (the last one is just rebasing).\r\n\r\n+1, LGTM. Merging to master.\r\nThank you, @itholic.
Issue #48688: Labels: SQL
cc @cloud-fan @MaxGekk 
Issue #48687: Labels: SQL, BUILD, CONNECT
Issue #48686: Labels: SQL, STRUCTURED STREAMING
@jingz-db - can u check if the lint failure is related ?
Issue #48685: Labels: SQL, STRUCTURED STREAMING
Thanks! Merging to master.
Issue #48684: Labels: BUILD
Could you review this PR, @attilapiros ?
Issue #48683: Labels: CORE
After a minor import statement merging, I verified this manually.\r\n```scala\r\n- import java.nio.file.Files\r\n- import java.nio.file.Paths\r\n+ import java.nio.file.{Files, Paths}\r\n```\r\n\r\n```\r\n[info] BlockManagerDecommissionIntegrationSuite:\r\n[info] - SPARK-32850: BlockManager decommission should respect the configuration (enabled=false) (8 seconds, 477 milliseconds)\r\n[info] - SPARK-32850: BlockManager decommission should respect the configuration (enabled=true) (7 seconds, 182 milliseconds)\r\n[info] - verify that an already running task which is going to cache data succeeds on a decommissioned executor after task start (11 seconds, 871 milliseconds)\r\n[info] - verify that an already running task which is going to cache data succeeds on a decommissioned executor after one task ends but before job ends (2 seconds, 884 milliseconds)\r\n[info] - verify that shuffle blocks are migrated (3 seconds, 504 milliseconds)\r\n[info] - verify that both migrations can work at the same time (3 seconds, 376 milliseconds)\r\n[info] - SPARK-36782 not deadlock if MapOutput uses broadcast (3 seconds, 362 milliseconds)\r\n[info] - SPARK-46957: Migrated shuffle files should be able to cleanup from executor (32 seconds, 227 milliseconds)\r\n[info] Run completed in 1 minute, 13 seconds.\r\n[info] Total number of tests run: 8\r\n[info] Suites: completed 1, aborted 0\r\n[info] Tests: succeeded 8, failed 0, canceled 0, ignored 0, pending 0\r\n[info] All tests passed.\r\n[success] Total time: 82 s (01:22), completed Oct 28, 2024, 9:01:32\u202fPM\r\n```\r\n\r\nMerged to master for Apache Spark 4.0.0 on February 2025.
Issue #48682: Labels: BUILD
Could you review this PR, @attilapiros ?
Issue #48681: Labels: ML
Issue #48680: Labels: DOCS, dependencies, ruby
Issue #48679: Labels: SQL
cc  @MaxGekk @cloud-fan 
Issue #48678: Labels: SQL, PYTHON
BTW, is this a subtask of SPARK-44728 , @zhengruifeng ?
Issue #48677: Labels: SQL, PYTHON, CONNECT
Type hints failed weirdly as https://github.com/xinrong-meng/spark/actions/runs/11812734311/job/32908478871, ignoring `#type: ignore` comments.\r\nRebased master
Issue #48676: Labels: SQL, STRUCTURED STREAMING, CONNECT
cc. @zsxwing @brkyvz @viirya Appreciated for reviewing. Thanks in advance.\r\ncc. @cloud-fan as well, since this PR changes the co-used logical/physical nodes between batch and streaming sources.
Issue #48675: Labels: SQL, BUILD
also cc @HyukjinKwon @dongjoon-hyun @HeartSaVioR @bogao007 FYI
Issue #48674: Labels: BUILD
Could you review this PR, @LuciferYang ? There is a dependably alert on this.\r\n- https://github.com/apache/spark/security/dependabot/105
Issue #48673: Labels: BUILD, PROTOBUF
cc @LuciferYang 
Issue #48672: Labels: SQL, PYTHON, CONNECT
thanks @dongjoon-hyun , merged to master
Issue #48671: Labels: BUILD
Could you ping the author of `zstd-jni` to get the confirmation?
Issue #48670: Labels: BUILD, INFRA
Thank you, @zhengruifeng .
Issue #48669: Labels: SQL, PYTHON
Merged to master.
Issue #48668: Labels: SQL
@LuciferYang @wangyum @sunchao could you please review this PR?
Issue #48667: Labels: BUILD
> It looks good to me. Is the PR ready, @panbinkun ?\n\nYep,thanks. â¤ï¸
Issue #48666: Labels: BUILD
It looks good to me, @panbingkun . Is the PR ready?
Issue #48665: Labels: CORE
> Also, to make testing easier, shall we expose the cache expiration time as a conf (internal?) ? This way, we can manipulate this value to be tiny (few seconds) during testing to recreate the failure scenario(s)\r\n\r\nYeah .. I have been testing it by manually changing the expiry time... but let me avoid adding it here for now but in a separate PR.
Issue #48664: Labels: SQL, BUILD, PYTHON, CONNECT
cc @allisonwang-db @cloud-fan @dtenedor 
Issue #48663: Labels: SQL
@cloud-fan can you please take a look at this one?
Issue #48662: Labels: Stale, PYTHON, PANDAS API ON SPARK
The lint error for this PR is an open MyPy bug:\r\n\r\nhttps://github.com/python/mypy/issues/11165
Issue #48661: Labels: SQL
cc @JoshRosen @viirya @dongjoon-hyun @yaooqinn 
Issue #48660: Labels: No Labels
> @urosstan-db Are you going to raise the error from somewhere?\r\n\r\nNo for now, not in Spark to be more precise.
Issue #48659: Labels: INFRA
Could you review this PR, @LuciferYang ?
Issue #48658: Labels: SQL
Issue #48657: Labels: SQL
Thank you @dongjoon-hyun  @MaxGekk  just filed https://issues.apache.org/jira/browse/SPARK-50123
Issue #48656: Labels: SQL
If CI passes, hopefully it can be merged today
Issue #48655: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @itholic.
Issue #48654: Labels: SQL, STRUCTURED STREAMING, BUILD
cc @dongjoon-hyun FYI
Issue #48653: Labels: SQL, Stale
Although we can set `ignoreLeadingWhiteSpace` to `true` to display it correctly, the type `float` & `double` can still be displayed correctly `without` setting it, \r\n```sql\r\nspark-sql (default)> select from_csv(\
Issue #48652: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @itholic.
Issue #48651: Labels: SQL, CORE, PYTHON
Merged to master. Thanks @HyukjinKwon @xupefei for the review!
Issue #48650: Labels: SQL, BUILD, CONNECT
@gengliangwang This [line](https://github.com/apache/spark/blob/28c3dbd213a98fe50ea2d97f257e46f4aff62fd6/sql/core/src/main/scala/org/apache/spark/sql/avro/AvroOptions.scala#L106) is why we need to move `AvroFileFormat`
Issue #48649: Labels: SQL
cc @cloud-fan @gengliangwang :)
Issue #48648: Labels: SQL, PYTHON
LGTM, thank you!
Issue #48647: Labels: BUILD, INFRA
Thank you, @zhengruifeng .
Issue #48646: Labels: SQL, STRUCTURED STREAMING, BUILD, CONNECT
All tests passed.
Issue #48645: Labels: Stale, DOCS
Issue #48644: Labels: BUILD, INFRA
cc @HyukjinKwon \r\nThis is intentionally focusing on Python side only. For Java-side, we have a separate PR for further discussion.
Issue #48643: Labels: PYTHON
Could you review this follow-up, @viirya ?
Issue #48642: Labels: SQL, Stale
@stefankandic @uros-db Could you look at the PR, please.
Issue #48641: Labels: SQL, Stale
Issue #48640: Labels: SQL, Stale
@panbingkun Could you please help review this?
Issue #48639: Labels: DOCS
Could you review this PR, @viirya ?
Issue #48638: Labels: BUILD, DOCS, INFRA, PYTHON
Thank you, @huaxingao !
Issue #48637: Labels: SQL, CONNECT
+1, LGTM. Merging to master.\r\nThank you, @jovanm-db and @LuciferYang for review.
Issue #48636: Labels: SQL, Stale
Issue #48635: Labels: BUILD
cc @HyukjinKwon @dongjoon-hyun , Do you think we can directly clean up these dev settings?\r\n\r\n
Issue #48634: Labels: CORE, PYTHON
Merged to master.
Issue #48633: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @itholic.
Issue #48631: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @itholic.
Issue #48630: Labels: SQL, Stale, CONNECT
cc @HyukjinKwon @zhengruifeng 
Issue #48629: Labels: SQL, STRUCTURED STREAMING, AVRO
can you fill the PR description with a JIRA filed?
Issue #48628: Labels: SQL, PYTHON
Hi ,\r\n\r\nI want to contribute to the project and can help out. Please let me know what to do!\r\n\r\nThanks!\r\n
Issue #48627: Labels: SQL
cc @cloud-fan 
Issue #48626: Labels: SQL
@MaxGekk please have a look when you can; also @uros-db to confirm the UTF8_LCASE part
Issue #48625: Labels: SQL
@yaooqinn as an author of https://github.com/apache/spark/pull/46006, I would like to get your review here :).  
Issue #48624: Labels: SQL, DOCS, PYTHON, CONNECT
+1, LGTM. Merging to master.\r\nThank you, @markonik-db and @mihailom-db @zhengruifeng @HyukjinKwon for review.
Issue #48623: Labels: SQL
The lint failure is unrelated, thanks, merging to master!
Issue #48622: Labels: SQL, CORE, CONNECT
To @xupefei , could you add multiple empty commits on this PR in order to verify your claim?\r\n\r\n> CI will tell.
Issue #48621: Labels: SQL
thanks, merging to master!
Issue #48620: Labels: SQL, STRUCTURED STREAMING
+1, LGTM. Merging to master.\r\nThank you, @itholic.
Issue #48619: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @mihailoale-db and @vladimirg-db for review.
Issue #48618: Labels: KUBERNETES, BUILD
Issue #48617: Labels: SQL, PYTHON
+1, LGTM. Merging to master.\r\nThank you, @zhengruifeng.
Issue #48616: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @jovanm-db.
Issue #48615: Labels: SQL, PYTHON, CONNECT
Merged to master.
Issue #48614: Labels: SQL
The failed tests is related to your changes, it seems. Please, fix it:\r\n```\r\n[info] - TRUNCATE TABLE using V1 catalog V1 command: truncate a partition of non partitioned table *** FAILED *** (97 milliseconds)\r\n[info]   "[_LEGACY_ERROR_TEMP_1267]" did not equal "[PARTITIONS_NOT_FOUND]" (SparkFunSuite.scala:346)\r\n[info]   Analysis:\r\n[info]   "[_LEGACY_ERROR_TEMP_1267]" -> "[PARTITIONS_NOT_FOUND]"\r\n```
Issue #48613: Labels: SQL, PYTHON, CONNECT
merged to master
Issue #48612: Labels: SQL
Thanks @MaxGekk for the review. Just applied the comments
Issue #48611: Labels: ML, MLLIB, BUILD, CORE, DSTREAM
cc @pan3793 and @dongjoon-hyun FYI
Issue #48610: Labels: SQL, CONNECT
cc @MaxGekk @cloud-fan 
Issue #48609: Labels: SQL
cc @dongjoon-hyun @LuciferYang thanks
Issue #48608: Labels: SQL
@uros-db , please take a look at the PR once you have time, thnx!
Issue #48607: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @itholic.
Issue #48606: Labels: ML, PYTHON, CONNECT
Merged to master.
Issue #48605: Labels: SQL, STRUCTURED STREAMING
cc. @cloud-fan Would you mind taking a look? Please cc. to others if you are busy with other stuff. Thanks!
Issue #48604: Labels: SQL, STRUCTURED STREAMING, BUILD, AVRO
Issue #48603: Labels: SQL, BUILD, DOCS, PYTHON, CONNECT
cc @allisonwang-db @dtenedor 
Issue #48602: Labels: SQL, ML, MLLIB, STRUCTURED STREAMING, BUILD, SPARK SHELL, DOCS, CORE, INFRA, PYTHON, AVRO, PANDAS API ON SPARK, CONNECT
Issue #48601: Labels: SQL, STRUCTURED STREAMING, BUILD, AVRO
Issue #48599: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @itholic.
Issue #48598: Labels: SQL
@stefankandic @c27kwan @cstavr @olaky @zhipengmao-db Please, review this PR.
Issue #48597: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @itholic.
Issue #48596: Labels: SQL
yeah
Issue #48595: Labels: SQL, CONNECT
cc @MaxGekk @cloud-fan 
Issue #48594: Labels: SQL
cc @MaxGekk @cloud-fan
Issue #48593: Labels: SQL, STRUCTURED STREAMING, PYTHON, CONNECT
Merged to master.
Issue #48592: Labels: SQL, PYTHON
Merged to master.
Issue #48591: Labels: SQL, PYTHON, CONNECT
Merged to master.
Issue #48590: Labels: SQL, STRUCTURED STREAMING
cc. @hvanhovell Please review and approve. Thanks in advance.
Issue #48589: Labels: SQL, PYTHON, CONNECT
thanks, merged to master
Issue #48588: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @panbingkun and @dongjoon-hyun for review.
Issue #48587: Labels: ML, PYTHON, CONNECT
cc @zhengruifeng This should fix all in https://github.com/apache/spark/actions/runs/11447673972
Issue #48586: Labels: SQL
I think you should sync your branch to the lastest master 
Issue #48585: Labels: SQL
@stefankandic @stevomitric can you plese review this PR?
Issue #48584: Labels: SQL
thanks, merging to master!
Issue #48583: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @itholic.
Issue #48582: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @jovanm-db and @mihailom-db @stefankandic for review.
Issue #48581: Labels: SQL, STRUCTURED STREAMING, PYTHON, CONNECT
Merged to master.
Issue #48580: Labels: SQL, DOCS, PYTHON, CONNECT
@MaxGekk @HyukjinKwon Do we want to not support try_make_interval in pyspark? This PR seems to block it https://github.com/apache/spark/pull/46975. I believe we should update that make_interval is not supported as well, as CalendarIntervalType is not supported.
Issue #48579: Labels: SQL, CONNECT
cc @MaxGekk @cloud-fan 
Issue #48578: Labels: SQL, PYTHON
The logic for constructing the histogram is mostly copied from Pandas on Spark to maintain parity. We can refactor it for reuse in a follow-up.
Issue #48577: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @itholic.
Issue #48576: Labels: SQL, PYTHON
Merged to master. Thanks @zhengruifeng for review!
Issue #48575: Labels: SQL, PYTHON, CONNECT
Merged to master.
Issue #48574: Labels: SQL, PYTHON
Issue #48573: Labels: SQL
cc @karuppayya @viirya @cloud-fan 
Issue #48572: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @itholic.
Issue #48571: Labels: SQL, PYTHON
Merged to master. Thanks @zhengruifeng for review
Issue #48570: Labels: SQL, STRUCTURED STREAMING
The issue is a sort of correctness/data loss (as watermark advances faster than it should be), but it\
Issue #48569: Labels: BUILD
Merged into master for Spark 4.0. Thanks @HyukjinKwon 
Issue #48568: Labels: KUBERNETES, Stale, CORE
Issue #48567: Labels: SQL, PYTHON
+1, LGTM. Merging to master.\r\nThank you, @zhengruifeng and @HyukjinKwon for review.
Issue #48566: Labels: BUILD, Stale
Issue #48565: Labels: ML, MLLIB, INFRA, PYTHON
Merged to master.
Issue #48564: Labels: CORE, PYTHON
cc @xinrong-meng 
Issue #48563: Labels: SQL, PYTHON
Merged to master.
Issue #48562: Labels: SQL, PYTHON, CONNECT
cc @zhengruifeng 
Issue #48561: Labels: SQL, ML, STRUCTURED STREAMING, PYTHON, CONNECT
Merged to master.
Issue #48560: Labels: SQL, PYTHON, CONNECT
Merged to master.
Issue #48559: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @itholic.
Issue #48558: Labels: SQL
cc @dtenedor and @HyukjinKwon 
Issue #48557: Labels: SQL, ML, STRUCTURED STREAMING, DOCS, CORE, INFRA, PYTHON, R, DSTREAM, PANDAS API ON SPARK, CONNECT
Waiting for all GitHub actions passed.
Issue #48556: Labels: SQL
thanks, merging to master!
Issue #48555: Labels: DOCS
cc @yaooqinn 
Issue #48554: Labels: SQL
Issue #48553: Labels: SQL, STRUCTURED STREAMING
cc - @ericm-db @HeartSaVioR - PTAL, thx !
Issue #48552: Labels: SQL, SPARK SHELL, DOCS, CORE, PYTHON
@dongjoon-hyun @HyukjinKwon @LuciferYang @zeal-thinker thanks for the review. Merging to master
Issue #48551: Labels: CORE
jenkins merge
Issue #48550: Labels: WEB UI, CORE
Could you review this backporting PR, @viirya ?
Issue #48549: Labels: WEB UI, CORE
Could you review this backporting PR, @viirya ?
Issue #48548: Labels: WEB UI, CORE
Thank you, @viirya .
Issue #48547: Labels: WEB UI, CORE
Thank you, @viirya .
Issue #48546: Labels: SQL, PYTHON, CONNECT
@stevomitric Please, fix the test failure. It seems it is related:\r\n```\r\n[info] - collation on non-explicit default collation *** FAILED *** (2 milliseconds)\r\n[info]   Incorrect evaluation (codegen off): SYSTEM.BUILTIN.UTF8_BINARY, actual: SYSTEM.BUILTIN.UTF8_BINARY, expected: UTF8_BINARY (ExpressionEvalHelper.scala:261)\r\n[info]   org.scalatest.exceptions.TestFailedException:\r\n```
Issue #48545: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @jovanpavl-db and @uros-db for your review.
Issue #48544: Labels: SQL, WEB UI, CONNECT
@jasonli-db Hi, nice to meet you. Could you briefly review this change? Thanks!
Issue #48543: Labels: SQL
can you fill the PR description please?
Issue #48542: Labels: SQL
cc @cloud-fan 
Issue #48541: Labels: SQL, PYTHON, CONNECT
Merged to master.
Issue #48540: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @zhipengmao-db.
Issue #48539: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @itholic.
Issue #48538: Labels: SQL
Issue #48537: Labels: SQL
Merged to master.
Issue #48536: Labels: SQL, PYTHON, CONNECT
Merged to master.
Issue #48535: Labels: WEB UI
Could you review this PR when you have some time, @HyukjinKwon ?
Issue #48534: Labels: WEB UI
Could you review this PR when you have some time, @viirya ?
Issue #48533: Labels: INFRA
thank you @Yikun @dongjoon-hyun and @HyukjinKwon \r\n\r\nmerged to master
Issue #48532: Labels: SQL
cc @MaxGekk 
Issue #48531: Labels: SQL, CORE, PYTHON, CONNECT
cc @MaxGekk 
Issue #48530: Labels: SQL, PYTHON, CONNECT
cc @MaxGekk 
Issue #48529: Labels: SQL, DOCS
cc @cloud-fan @gengliangwang here is aggregation support. This should be the last non-trivial pipe operator left.
Issue #48528: Labels: BUILD
Could you review this PR, @viirya ?
Issue #48527: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @uros-db and @HyukjinKwon for review.
Issue #48526: Labels: SQL
Issue #48525: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @uros-db and @HyukjinKwon for review.
Issue #48524: Labels: SQL, BUILD, DOCS, INFRA, PYTHON, CONNECT
This PR was simply rebased to `master` branch to bring the following update.\r\n- #48638\r\n- #48643 \r\n- #48644\r\n- #48646
Issue #48523: Labels: SQL
@cloud-fan 
Issue #48522: Labels: BUILD
Could you review this infra PR for Python 3.13 support, @huaxingao ?\r\n\r\nThe image build succeeded already and I manually validate. And, the CI result is irrelevant to this PR because Python 3.13 is only used in Daily CI seperately.\r\n- https://github.com/apache/spark/actions/workflows/build_python_3.13.yml
Issue #48521: Labels: SQL
@uros-db @stefankandic @stevomitric @vladanvasi-db Could you take a look at the changes, please.
Issue #48520: Labels: BUILD, INFRA
thanks @dongjoon-hyun for reviews!
Issue #48519: Labels: SQL, PYTHON, CONNECT
@itholic should we use PySparkLogger instead?
Issue #48518: Labels: BUILD
thanks, merged to master
Issue #48517: Labels: SQL, STRUCTURED STREAMING
cc. @cloud-fan @hvanhovell Could you please take a look? Thanks!
Issue #48516: Labels: PYTHON, PANDAS API ON SPARK
Issue #48515: Labels: INFRA
Merged to master.
Issue #48514: Labels: SQL
Fixed the failed tests. Thanks!
Issue #48513: Labels: SQL, PYTHON, PANDAS API ON SPARK
@xinrong-meng please rebase to enable a recent test image refactor
Issue #48512: Labels: SQL, PYTHON
@zhengruifeng would you please review?
Issue #48511: Labels: SQL, PYTHON, CONNECT
Issue #48510: Labels: SQL
Issue #48509: Labels: SQL, CONNECT
+1, LGTM. Merging to master.\r\nThank you, @panbingkun and @cloud-fan for review.
Issue #48508: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @itholic.
Issue #48507: Labels: SQL
Issue #48506: Labels: SQL
the linter failure is unrelated, thanks, merging to 3.4!
Issue #48505: Labels: SQL
thanks, merging to 3.5!
Issue #48504: Labels: BUILD
Merged to master, thank you @panbingkun @HyukjinKwon 
Issue #48503: Labels: SQL
cc @dtenedor @chenhao-db @srielau 
Issue #48502: Labels: No Labels
Issue #48501: Labels: SQL
Can we include the benchmark result files too? See also "Testing with GitHub Actions workflow" at https://spark.apache.org/developer-tools.html
Issue #48500: Labels: SQL, DOCS, PYTHON, CONNECT
@dongjoon-hyun I do agree that the title is not reflecting the right change, but opening a new PR might be an overkill and also cause confusion in development later. The main point of this PR is what ticket suggests `Remove the ANSI config suggestion in INVALID_URL`. I would suggest renaming the title, but keeping the changes in one PR, as these changes suggest the reason for removing and also the solution/substitute suggestion we provide for spark users. Separating them would make developer work much harder, and the second PR you suggested would be mostly tests changes.
Issue #48499: Labels: SQL
@MaxGekk @HyukjinKwon I added tests and fixed one test in DataFrameSuite, as it was not completely using aggFn parameter
Issue #48498: Labels: SQL
cc @cloud-fan , @ulysses-you , @yaooqinn , @LuciferYang from #47533 
Issue #48497: Labels: Stale, CORE
can you fill the PR description please?
Issue #48496: Labels: SQL
@MaxGekk the problem here is that legacy_error_temp_2042 would have returned the same message as ARITHMETIC_OVERFLOW, but someone just added a new method in QueryExecutionErrors for codeGen path, even though in eval path we threw the same error, but just under different class. I can add a golden file test, to throw this error, but I am not sure if golden files call codeGen or eval path?
Issue #48495: Labels: SQL, DOCS
+1, LGTM. Merging to master.\r\nThank you, @uros-db and @stefankandic @mihailom-db for review.
Issue #48494: Labels: SQL, CORE
cc @cloud-fan @dongjoon-hyun, thanks
Issue #48493: Labels: SQL
- Benchmark code as follows:\r\n```scala\r\nobject RandstrBenchmark extends SqlBasedBenchmark {\r\n  private val N = 1000000 // 1_000_00\r\n  private val M = 100\r\n\r\n  private val df = spark.range(N).to(new StructType().add("id", "int"))\r\n\r\n  private def doBenchmark(): Unit = {\r\n    df.selectExpr("randStr(10, 20)").noop()\r\n  }\r\n\r\n  override def runBenchmarkSuite(mainArgs: Array[String]): Unit = {\r\n    runBenchmark("randStr") {\r\n      val benchmark = new Benchmark("randStr", N, output = output)\r\n      benchmark.addCase("optimize", M) { _ =>\r\n        doBenchmark()\r\n      }\r\n      benchmark.run()\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n- Before (run 3 times)\r\n```\r\nRunning benchmark: randStr\r\n  Running case: optimize\r\n  Stopped after 100 iterations, 12265 ms\r\n\r\nOpenJDK 64-Bit Server VM 17.0.10+7-LTS on Mac OS X 15.0.1\r\nApple M2\r\nrandStr:                                  Best Time(ms)   Avg Time(ms)   Stdev(ms)    Rate(M/s)   Per Row(ns)   Relative\r\n------------------------------------------------------------------------------------------------------------------------\r\noptimize                                            107            123          21          9.4         106.9       1.0X\r\n\r\n\r\nRunning benchmark: randStr\r\n  Running case: optimize\r\n  Stopped after 100 iterations, 11298 ms\r\n\r\nOpenJDK 64-Bit Server VM 17.0.10+7-LTS on Mac OS X 15.0.1\r\nApple M2\r\nrandStr:                                  Best Time(ms)   Avg Time(ms)   Stdev(ms)    Rate(M/s)   Per Row(ns)   Relative\r\n------------------------------------------------------------------------------------------------------------------------\r\noptimize                                            107            113           7          9.3         107.0       1.0X\r\n\r\n\r\nRunning benchmark: randStr\r\n  Running case: optimize\r\n  Stopped after 100 iterations, 11181 ms\r\n\r\nOpenJDK 64-Bit Server VM 17.0.10+7-LTS on Mac OS X 15.0.1\r\nApple M2\r\nrandStr:                                  Best Time(ms)   Avg Time(ms)   Stdev(ms)    Rate(M/s)   Per Row(ns)   Relative\r\n------------------------------------------------------------------------------------------------------------------------\r\noptimize                                            107            112           5          9.4         106.7       1.0X\r\n```\r\n\r\n- After (run 3 times)\r\n```\r\nRunning benchmark: randStr\r\n  Running case: optimize\r\n  Stopped after 100 iterations, 10362 ms\r\n\r\nOpenJDK 64-Bit Server VM 17.0.10+7-LTS on Mac OS X 15.0.1\r\nApple M2\r\nrandStr:                                  Best Time(ms)   Avg Time(ms)   Stdev(ms)    Rate(M/s)   Per Row(ns)   Relative\r\n------------------------------------------------------------------------------------------------------------------------\r\noptimize                                             98            104           6         10.2          98.0       1.0X\r\n\r\n\r\nRunning benchmark: randStr\r\n  Running case: optimize\r\n  Stopped after 100 iterations, 10380 ms\r\n\r\nOpenJDK 64-Bit Server VM 17.0.10+7-LTS on Mac OS X 15.0.1\r\nApple M2\r\nrandStr:                                  Best Time(ms)   Avg Time(ms)   Stdev(ms)    Rate(M/s)   Per Row(ns)   Relative\r\n------------------------------------------------------------------------------------------------------------------------\r\noptimize                                             98            104           7         10.2          97.9       1.0X\r\n\r\n\r\nRunning benchmark: randStr\r\n  Running case: optimize\r\n  Stopped after 100 iterations, 10230 ms\r\n\r\nOpenJDK 64-Bit Server VM 17.0.10+7-LTS on Mac OS X 15.0.1\r\nApple M2\r\nrandStr:                                  Best Time(ms)   Avg Time(ms)   Stdev(ms)    Rate(M/s)   Per Row(ns)   Relative\r\n------------------------------------------------------------------------------------------------------------------------\r\noptimize                                             97            102           4         10.3          97.5       1.0X\r\n```
Issue #48492: Labels: SQL, PYTHON
@zhengruifeng @HyukjinKwon may I get a review please?
Issue #48491: Labels: KUBERNETES, BUILD
cc @dongjoon-hyun @LuciferYang 
Issue #48490: Labels: SQL
cc @dtenedor @MaxGekk 
Issue #48489: Labels: BUILD
cc @dongjoon-hyun and @panbingkun 
Issue #48488: Labels: CORE
@LuciferYang @dongjoon-hyun since you created these methods
Issue #48487: Labels: CORE
LGTM, the tests in Build (pull_request_target) all passed. Thank you!
Issue #48486: Labels: SQL
cc @maryannxue 
Issue #48485: Labels: CORE
LGTM, thank you!
Issue #48484: Labels: SQL
cc @yaooqinn @ulysses-you 
Issue #48483: Labels: SQL, CORE
Merged to master.
Issue #48482: Labels: R
cc @HyukjinKwon 
Issue #48481: Labels: SQL
thanks, merging to master!
Issue #48480: Labels: SQL
Issue #48479: Labels: SQL, Stale, CONNECT
@hvanhovell fyi
Issue #48478: Labels: YARN, Stale, CORE
@srowen 
Issue #48477: Labels: SQL
@hvanhovell fyi
Issue #48476: Labels: SQL
Issue #48475: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @vladimirg-db.
Issue #48474: Labels: INFRA
thank you @dongjoon-hyun !
Issue #48473: Labels: SQL, CONNECT
The difference between this and https://github.com/apache/spark/pull/48452 is that the `Invoke object` in this version is implemented using `Scala`.\r\nScala(`Invoke object`): https://github.com/apache/spark/pull/48473\r\nJava(`Invoke object`): https://github.com/apache/spark/pull/48452
Issue #48472: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @jovanpavl-db and @uros-db for review.
Issue #48471: Labels: SQL
Thanks @MaxGekk for the review! Applied the comments
Issue #48470: Labels: SQL, Stale
cc @wangyum @cloud-fan 
Issue #48469: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @itholic.
Issue #48468: Labels: BUILD, YARN
cc @yaooqinn @LuciferYang 
Issue #48467: Labels: SQL, CONNECT
cc @MaxGekk @cloud-fan 
Issue #48466: Labels: SQL
cc @MaxGekk @cloud-fan 
Issue #48465: Labels: BUILD
cc @dongjoon-hyun @LuciferYang 
Issue #48464: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @harshmotw-db and @cloud-fan for review.
Issue #48463: Labels: BUILD, dependencies, java
Issue #48462: Labels: BUILD, dependencies, java
Issue #48461: Labels: BUILD
@pan3793 Can you have a look on this, since this is a follow up on SPARK-47118 
Issue #48460: Labels: SQL, STRUCTURED STREAMING
LGTM pending tests. @HeartSaVioR can you please help merge this if tests pass? Thanks in advance!
Issue #48459: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @stefankandic and @uros-db @jovanpavl-db @HyukjinKwon for review.
Issue #48458: Labels: SQL
@cloud-fan could you review? Thanks!
Issue #48457: Labels: YARN, CORE
Issue #48456: Labels: SQL
thanks, merging to master!
Issue #48455: Labels: SQL, DOCS, PYTHON, CONNECT
+1, LGTM. Merging to master.\r\nThank you, @uros-db and @HyukjinKwon for review.
Issue #48454: Labels: SQL, PYTHON
+1, LGTM. Merging to master.\r\nThank you, @uros-db.
Issue #48453: Labels: SQL
@Hisoka-X @MaxGekk 
Issue #48452: Labels: SQL, CONNECT
Issue #48451: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @itholic.
Issue #48450: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @mihailom-db and @srielau for review.
Issue #48449: Labels: SQL, AVRO
Merged to master. Thanks @MaxGekk for the review!
Issue #48448: Labels: PYTHON, PANDAS API ON SPARK
LGTM, thank you!
Issue #48447: Labels: SQL, PYTHON
Merged to master, thank you!
Issue #48446: Labels: KUBERNETES
cc @dongjoon-hyun @yaooqinn 
Issue #48445: Labels: PYTHON, PANDAS API ON SPARK
Merged to master, thank you!
Issue #48444: Labels: SQL
<img width="677" alt="image" src="https://github.com/user-attachments/assets/02ba2a1b-debe-4fa9-ad3a-ed6c712ac2b1">\r\n
Issue #48443: Labels: SQL, Stale, CONNECT
Issue #48442: Labels: SQL, CORE
@cloud-fan @dongjoon-hyun @HyukjinKwon In the PR, I am trying to close the door of raising Spark exceptions without error conditions/classes. Unfortunately, at the moment this is one of a couple ways when users might get `SparkThrowable` in which `condition` (`error class`) is `null`.
Issue #48441: Labels: SQL
cc @panbingkun @MaxGekk 
Issue #48440: Labels: SQL, STRUCTURED STREAMING, BUILD, CORE, PYTHON, CONNECT
@srielau @panbingkun @nchammas @cloud-fan Could you review the PR, please.
Issue #48439: Labels: SQL, PYTHON, PANDAS API ON SPARK
Merged to master.
Issue #48438: Labels: DOCS
@yaooqinn, since you reviewed my last PR (which accidentally caused this regression), can you take a look? Thanks!
Issue #48437: Labels: SQL, PYTHON, PANDAS API ON SPARK
thanks @MaxGekk \r\nmerged to master
Issue #48436: Labels: SQL, Stale
Please take a look when you have the time @mihailom-db @cloud-fan 
Issue #48433: Labels: SQL, Stale
LGTM. One question: Are we also going to rename `errorClass` in classifyException from JDBCUtils?\r\n
Issue #48432: Labels: CORE
Merging the trivial fix to master.
Issue #48431: Labels: SQL, CORE
@srielau @panbingkun @nchammas @cloud-fan Could you review the PR, please.
Issue #48430: Labels: SQL, Stale, CONNECT
Issue #48429: Labels: SQL
cc @cloud-fan 
Issue #48428: Labels: SQL, CONNECT
+1, LGTM. Merging to master.\r\nThank you, @panbingkun.
Issue #48427: Labels: KUBERNETES
Could you review this when you have some time? cc @dongjoon-hyun @cloud-fan 
Issue #48426: Labels: BUILD
### Manual verification is as follows:\r\n- To verify if there will be errors during compilation, in the class `CheckAnalysis`, change the call to `SparkThrowable#getCondition` to call `SparkThrowable#getErrorClass`\r\n  <img width="1321" alt="image" src="https://github.com/user-attachments/assets/6aa95fc9-5f56-4785-8dcb-09eef5998609">\r\n\r\n- Run the following compilation commands\r\n```\r\n./build/sbt -Phadoop-3 -Pkinesis-asl -Pdocker-integration-tests -Phive -Phadoop-cloud -Pspark-ganglia-lgpl -Phive-thriftserver -Pyarn -Pkubernetes -Pvolcano Test/package streaming-kinesis-asl-assembly/assembly connect/assembly\r\n```\r\n\r\n- Compilation will ultimately fail\r\n  <img width="1393" alt="image" src="https://github.com/user-attachments/assets/013e2200-cc8c-4347-a51f-55d0cdf13a02">\r\n
Issue #48425: Labels: SQL, MLLIB, STRUCTURED STREAMING, KUBERNETES, WEB UI, EXAMPLES, CORE, R, DSTREAM, AVRO
> As you are here, may I ask you to fix other places:\r\n> \r\n> ```\r\n> find . -name "*.scala" -print0|xargs -0 grep \
Issue #48424: Labels: STRUCTURED STREAMING, PYTHON
@HyukjinKwon sorry for the problematic PR. I re-upload it and hopefully now it is OK.
Issue #48423: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @stefankandic and @zhipengmao-db for review.
Issue #48422: Labels: SQL, PYTHON, CONNECT
Merged to master.
Issue #48421: Labels: BUILD
@HyukjinKwon Please take a look If you have time, thanks ~\r\n\r\nI have checked the Maven test and SparkR on Windows test on GA, and briefly tested spark-shell and connect-shell after ` dev/make-distribution.sh --tgz -Phive`. They are all functioning successful with this pr.
Issue #48420: Labels: No Labels
GA passed. Merged into master for Spark 4.0. Thanks @panbingkun @MaxGekk @HyukjinKwon @yaooqinn 
Issue #48419: Labels: STRUCTURED STREAMING, PYTHON
I am going to merge this to fix up the build.\r\n\r\nMerged to master.
Issue #48418: Labels: STRUCTURED STREAMING, PYTHON
cc - @HeartSaVioR @WweiL - PTAL, thx !
Issue #48417: Labels: STRUCTURED STREAMING, PYTHON
Will merge this to fix up the build. Otherwise, I will revert this and https://github.com/apache/spark/commit/2af653688c20dde87eebaa6bd4dc21123fab74cc if it still fails.
Issue #48416: Labels: SQL
cc @MaxGekk 
Issue #48415: Labels: SQL, PYTHON
Irrelevant tests failed, retriggering:\r\n```\r\nERROR [3.661s]: test_listener_events (pyspark.sql.tests.streaming.test_streaming_listener.StreamingListenerTests.test_listener_events)\r\n\r\nERROR [0.145s]: test_streaming_progress (pyspark.sql.tests.streaming.test_streaming_listener.StreamingListenerTests.test_streaming_progress)\r\n```
Issue #48414: Labels: STRUCTURED STREAMING, PYTHON
Merged to master.
Issue #48413: Labels: SQL
cc @cloud-fan @gengliangwang this is the PR to support LIMIT/OFFSET + sorting. There are a few more changes in the `AstBuilder` for this one but still contained only in the parser.
Issue #48412: Labels: SQL
Can you re-trigger Github Action jobs?
Issue #48411: Labels: PYTHON
The following is mentioned on the downloadings page (https://spark.apache.org/docs/3.5.3/#downloading)\r\n> Java 8 prior to version 8u371 support is deprecated as of Spark 3.5.0\r\n\r\nFor some reason, I misread this and was under the impression that support for Java 8 was deprecated in its entirety as of 3.5.0.\r\n\r\nI added a new commit where I updated the documentation and included Java 8 back in, with an exception for versions prior to 8u371.
Issue #48410: Labels: SQL, CONNECT
Merged to master.
Issue #48409: Labels: BUILD
Issue #48408: Labels: SQL, Stale
Issue #48407: Labels: SQL
ping @wangyum @cloud-fan 
Issue #48406: Labels: INFRA
cc @LuciferYang @dongjoon-hyun @HyukjinKwon
Issue #48405: Labels: KUBERNETES
Issue #48404: Labels: SQL, PYTHON
Merged to master.
Issue #48403: Labels: SQL, BUILD
<img width="276" alt="image" src="https://github.com/user-attachments/assets/6dac9117-32a9-443c-9d02-1c6d0cb2a8df">\r\n\r\nall maven test passed
Issue #48402: Labels: SQL, WEB UI, CORE, CONNECT
The GA jobs actually all passed. Thanks, merging to master!
Issue #48401: Labels: SQL, STRUCTURED STREAMING
PR to move Avro files: https://github.com/apache/spark/pull/48650
Issue #48400: Labels: SQL, Stale
Issue #48399: Labels: SQL, BUILD, CONNECT
https://github.com/apache/spark/actions/runs/11255598249/job/31295526084\r\n\r\n```\r\nscaladoc error: fatal error: object scala in compiler mirror not found.\r\nError:  Failed to execute goal net.alchim31.maven:scala-maven-plugin:4.9.1:doc-jar (attach-scaladocs) on project spark-connect-shims_2.13: MavenReportException: Error while creating archive: wrap: Process exited with an error: 1 (Exit value: 1) -> [Help 1]\r\nError:  \r\nError:  To see the full stack trace of the errors, re-run Maven with the -e switch.\r\nError:  Re-run Maven using the -X switch to enable full debug logging.\r\nError:  \r\nError:  For more information about the errors and possible solutions, please read the following articles:\r\nError:  [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException\r\nError:  \r\nError:  After correcting the problems, you can resume the build with the command\r\nError:    mvn <args> -rf :spark-connect-shims_2.13\r\nError: Process completed with exit code 1.\r\n```\r\n\r\n![image](https://github.com/user-attachments/assets/ddb57ff3-1c60-49e7-a715-694605c6c754)\r\n
Issue #48398: Labels: SQL, ML
merged to master.
Issue #48397: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @RaleSapic.
Issue #48396: Labels: SQL
+1, LGTM. Merging to 3.4.\r\nThank you, @panbingkun.
Issue #48395: Labels: SQL
cc @cloud-fan @dongjoon-hyun thanks
Issue #48393: Labels: SQL, CORE, PYTHON, CONNECT
cc @MaxGekk \r\nI am still verifying the PR for branch-3.4 locally.\r\nThanks!
Issue #48392: Labels: SQL
Merged to master.
Issue #48391: Labels: SQL, CORE
- branch 3.4 + scala 2.12.17\r\n```scala\r\n(base) âžœ  spark-trunk git:(branch-3.4) âœ— serialver -classpath core/target/spark-core_2.12-3.4.4-SNAPSHOT.jar:build/scala-2.12.17/lib/scala-library.jar org.apache.spark.util.Lazy\r\norg.apache.spark.util.Lazy:    private static final long serialVersionUID = 7964587975756091988L;\r\n```
Issue #48390: Labels: SQL, STRUCTURED STREAMING, BUILD, Stale
cc @cloud-fan @HyukjinKwon @dongjoon-hyun this is a breaking change. I am fine with putting this up for discussion on the dev list, but I also feel that this well within the mandate for Spark 4.
Issue #48389: Labels: No Labels
+1, LGTM. Merging to master.\r\nThank you, @huangxiaopingRD.
Issue #48388: Labels: SQL, PYTHON
Merged to master.
Issue #48387: Labels: SQL, PYTHON, CONNECT
+1, LGTM. Merging to master.\r\nThank you, @dusantism-db.
Issue #48386: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @jovanpavl-db and @uros-db @mihailom-db for review.
Issue #48385: Labels: SQL, PYTHON, CONNECT
+1, LGTM. Merging to master.\r\nThank you, @panbingkun and @HyukjinKwon for review.
Issue #48384: Labels: SQL
The Docker integration test failure seems not related to this PR.\r\n\r\ncc @MaxGekk @srielau fyi
Issue #48383: Labels: SQL
Merged to master.
Issue #48382: Labels: SQL, STRUCTURED STREAMING
cc. @cloud-fan Please take a look, thanks!
Issue #48381: Labels: SQL
CI passed. cc @MaxGekk @srielau fyi
Issue #48380: Labels: BUILD
wait 6.1.1 release https://github.com/apache/datasketches-java/releases
Issue #48379: Labels: SQL
@cloud-fan Can you look at this PR? Thanks!
Issue #48378: Labels: BUILD
> https://github.com/apache/parquet-java/issues/3021: Upgrade Avro dependency to 1.11.4\r\n\r\nSpark is currently using Avro 1.12.0
Issue #48377: Labels: BUILD
Issue #48376: Labels: SQL, CONNECT
cc @hvanhovell 
Issue #48375: Labels: SQL
the pyspark failure is unrelated, thanks, merging to master!
Issue #48374: Labels: SQL, BUILD, CONNECT
Merging to master
Issue #48373: Labels: SQL, STRUCTURED STREAMING, CORE, PYTHON
Hi ,\r\n\r\nI want to contribute to the project and can help out. Please let me know what to do!\r\n\r\nThanks!
Issue #48372: Labels: CORE
Merged to master.
Issue #48371: Labels: DOCS
cc @viirya 
Issue #48370: Labels: SQL
Merged to master.
Issue #48369: Labels: SQL, PYTHON, CONNECT
Merged to master.
Issue #48368: Labels: SQL, Stale, CORE
What should be EXECUTE_QUERY errors? 
Issue #48367: Labels: SQL, AVRO
+1, LGTM. Merging to master.\r\nThank you, @itholic.
Issue #48366: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @itholic.
Issue #48365: Labels: SQL, PYTHON, CONNECT
Merged to master.
Issue #48364: Labels: SQL, PYTHON, CONNECT
After this PR, we can pretty speed up to add compatibility tests for each API\r\n\r\ncc @HyukjinKwon @hvanhovell FYI
Issue #48363: Labels: SQL, PYTHON, CONNECT
thanks, merged to master
Issue #48362: Labels: SQL
Can we add some details on why we are reverting to the description please ? For example: bug still exists in scenario foo, or new bug introduced for xyz, etc ?\nThanks
Issue #48361: Labels: SQL, CORE, PYTHON
python linter failed
Issue #48360: Labels: SQL
cc @huaxingao @dongjoon-hyun 
Issue #48359: Labels: SQL
cc @cloud-fan @gengliangwang here is the support for UNION ALL and other set operations.
Issue #48358: Labels: DOCS, CORE
Hi @attilapiros and @dongjoon-hyun, given that @holdenk did not object, can we consider shipping the docs change to make the docs match the code? And we can revert both patches if there are new issues identified before 4.0.0 GA
Issue #48357: Labels: CORE
Issue #48356: Labels: SQL, STRUCTURED STREAMING
This PR depends on https://github.com/apache/spark/pull/48355
Issue #48355: Labels: SQL, STRUCTURED STREAMING
This PR depends on https://github.com/apache/spark/pull/47932 and https://github.com/apache/spark/pull/47895
Issue #48354: Labels: SQL, ML, STRUCTURED STREAMING, PYTHON, CONNECT
Issue #48353: Labels: CORE
cc @MaxGekk @dongjoon-hyun @HyukjinKwon @attilapiros If you have time, please help review this clean revert , which has caused the compilation failure of branch-3.5.
Issue #48352: Labels: CORE
Thank you, @LuciferYang .
Issue #48351: Labels: SQL
The tests are now passing. Could you make a review @MaxGekk? Thanks.
Issue #48350: Labels: SQL, CONNECT
@rangadi Hello, nice to meet you here! This is a minor code optimization as part of an attempt to get rid of the use of global locks in the spark connect service code. Could you review the code please? The code semantics should be the same as before. Thanks.
Issue #48349: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @jovanpavl-db and @uros-db @mihailom-db for review.
Issue #48348: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @dusantism-db.
Issue #48347: Labels: ML, EXAMPLES, DOCS, PYTHON
also cc @WeichenXu123 for visibility
Issue #48346: Labels: SQL
cc @srielau @cloud-fan @MaxGekk 
Issue #48345: Labels: CORE
Merged to master.
Issue #48344: Labels: KUBERNETES
cc @LuciferYang 
Issue #48343: Labels: PYTHON
Merged to master for Apache Spark 4.0.0 on February 2025.\r\n\r\nThank you, @HyukjinKwon and @itholic .
Issue #48342: Labels: BUILD
Merged to master.
Issue #48341: Labels: SQL, PYTHON, CONNECT
Issue #48340: Labels: SQL, Stale
cc @wangyum 
Issue #48339: Labels: SQL
@MaxGekk Could you provide correct `sqlState` for the introduced error class.
Issue #48338: Labels: SQL
> Should we remove this comment?\r\n\r\nYes, please, do that.
Issue #48337: Labels: SQL, Stale
+CC @shardulm94 
Issue #48336: Labels: SQL
Merged to master.
Issue #48335: Labels: SQL
The Oracle integration test is not related to the changes, and passed on the previous run:\r\n```\r\n[info] OracleIntegrationSuite:\r\n[info] org.apache.spark.sql.jdbc.OracleIntegrationSuite *** ABORTED *** (10 minutes, 18 seconds)\r\n[info]   The code passed to eventually never returned normally. Attempted 599 times over 10.014775141716667 minutes. Last failure message: ORA-12541: Cannot connect. No listener at host 10.1.0.31 port 44657. (CONNECTION_ID=jYNU58dhQbyjNykzpYuyew==)\r\n```\r\n\r\n+1, LGTM. Merging to master.\r\nThank you, @mihailom-db.
Issue #48334: Labels: SQL
Merged to branch-3.4. Thank you, @stefankandic and @MaxGekk .
Issue #48333: Labels: SQL
Merged to branch-3.5.\r\n\r\nThank you, @stefankandic and @MaxGekk .
Issue #48332: Labels: SQL
@MaxGekk this PR is ready for merge, let me know when you re-review it so I can rerun the CIs, so we do not break something, as these runs are from yesterday.
Issue #48331: Labels: SQL
cc: @cloud-fan to take a look.
Issue #48330: Labels: BUILD
Image build passed.\r\n```\r\n$ docker run -it --rm ghcr.io/dongjoon-hyun/apache-spark-ci-image:master-11152626644 python3.13 --version\r\nPython 3.13.0rc3\r\n```
Issue #48329: Labels: BUILD
Hi, @HyukjinKwon . According to the description of SPARK-46645, the problem happened when the test case started to run, right? Please let me know if I missed something here.
Issue #48328: Labels: INFRA
Could you review this PR, @huaxingao ?
Issue #48327: Labels: SQL, PYTHON, CONNECT
Merged to master.
Issue #48326: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @uros-db.
Issue #48325: Labels: SQL
cc @cloud-fan FYI..
Issue #48324: Labels: SQL, PYTHON, CONNECT
@HyukjinKwon @hvanhovell @cloud-fan @dongjoon-hyun \r\nWould it be OK to add `storageLevel` arg to Dataset `localCheckpoint` API? It would simplify the use case in Delta MergeIntoMaterializeSource that I describe, and there is a precedent with `persist` having a `storageLevel` arg.
Issue #48323: Labels: SQL, DOCS
The test failure of `AdaptiveQueryExecSuite` is not related to changes. I re-ran it locally, BTW.\r\n\r\n+1, LGTM. Merging to master.\r\nThank you, @dusantism-db.
Issue #48322: Labels: SQL, Stale
ping @cloud-fan 
Issue #48321: Labels: SQL, Stale
I will add JIRA item as well in future, if we decide to go with this PR.
Issue #48320: Labels: SQL, CORE, CONNECT
@vicennial This PR changed after your stamp. Could you re-review the change again?\r\n@hvanhovell Please take a look :D
Issue #48319: Labels: SQL, PYTHON
Could you review this when you have some time, @viirya ?
Issue #48318: Labels: SQL, STRUCTURED STREAMING, BUILD
Issue #48317: Labels: SQL, STRUCTURED STREAMING
cc - @neilramaswamy @HeartSaVioR - PTAL, thx !
Issue #48316: Labels: CORE
Thank you, @viirya !
Issue #48315: Labels: SQL
@cloud-fan please take a look at this when you get the chance
Issue #48314: Labels: SQL, BUILD
Just a test for the new datasketches-memory release, no need to pay attention.\r\n\r\nhttps://github.com/apache/datasketches-memory/issues/213
Issue #48313: Labels: SQL
@uros-db Are you ok w/ the changes?
Issue #48312: Labels: BUILD, Stale
I have no issues with IntelliJ IDEA 2024.2.3, btw, have you checked this?\r\n\r\n![image](https://github.com/user-attachments/assets/06854115-bf56-47f8-959f-23cc322dcc1d)\r\n
Issue #48311: Labels: SQL, Stale
Issue #48310: Labels: BUILD
Issue #48309: Labels: SQL
cc. @cloud-fan Would you mind take a look at this? Thanks!
Issue #48308: Labels: SQL
thanks, merging to 3.5!
Issue #48307: Labels: SQL, CORE, PYTHON
cc @viirya and @huaxingao from #48251
Issue #48306: Labels: SQL, ML, MLLIB, Stale, PYTHON
> If we need to open this, shall we move the package location from `internal` to a more proper package location, @holdenk ?\r\n\r\nSeems reasonable to me.\r\n
Issue #48305: Labels: INFRA
Could you review this when you have some time, @huaxingao ?
Issue #48304: Labels: SQL
lgtm
Issue #48303: Labels: SQL
cc @sunchao 
Issue #48302: Labels: SQL
> > Currently, there are no tests for the NULLIF function. We should add tests to prevent regressions.\r\n> \r\n> There are some tests in:\r\n> \r\n> https://github.com/apache/spark/blob/c0a1ea2a4c4218fc15b8f990ed2f5ea99755d322/sql/core/src/test/scala/org/apache/spark/sql/DataFrameFunctionsSuite.scala#L327-L334\r\n> \r\n> Implementation of `nullif` depends on the SQL config `spark.sql.alwaysInlineCommonExpr`. How about to test the expr w/ enabled/disabled the flag?\r\n\r\nAdded
Issue #48301: Labels: SQL
cc @peter-toth @viirya 
Issue #48300: Labels: SQL
Can we add a test?
Issue #48299: Labels: KUBERNETES, DOCS
Hi @dongjoon-hyun could you please take a look, thank you !
Issue #48298: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @exmy.
Issue #48297: Labels: SQL, STRUCTURED STREAMING
@dongjoon-hyun, this issue has been around since the time that we added multiple stateful operators to Structured Streaming. The Left-semi join logic that you linked previously is correct, and Jungtaek preserves that behavior in this PR.
Issue #48296: Labels: SQL, Stale
Please review @pan3793 @cloud-fan @HyukjinKwon 
Issue #48295: Labels: BUILD
This is blocked by \r\n- https://github.com/apache/hadoop/pull/7079
Issue #48294: Labels: BUILD
> Thank you. Is this ready, @panbingkun ?\r\n\r\nYeah, thanks! â¤ï¸
Issue #48293: Labels: SQL, CONNECT
Merged to master.
Issue #48292: Labels: SQL, STRUCTURED STREAMING
cc - @HeartSaVioR @siying - PTAL, thx !
Issue #48291: Labels: SQL
cc @dongjoon-hyun 
Issue #48290: Labels: SQL, STRUCTURED STREAMING, PYTHON
https://github.com/bogao007/spark/actions/runs/11433439704/job/31805443260\r\nIt only failed with org.apache.spark.sql.SparkSessionE2ESuite.
Issue #48289: Labels: SQL, BUILD
Hi, @yaooqinn . It would be great if we can have this test coverage in the release branches. Could you review this as the author?
Issue #48288: Labels: SQL
@mrk-andreev Could you fix the failed tests:\r\n```\r\n[info] - Error conditions are correctly formatted *** FAILED *** (103 milliseconds)\r\n[info]   "...023"\r\n[info]     },\r\n[info]     "SCALAR_[FUNCTION_NOT_COMPATIBLE" : {\r\n[info]       "message" : [\r\n[info]         "ScalarFunction <scalarFunc> not overrides method \
Issue #48287: Labels: CORE, PYTHON
This seams to be the only `raise IOError` we have.\r\n\r\n![image](https://github.com/user-attachments/assets/d1b57a80-e18e-49a9-b157-0362fce78ef1)\r\n
Issue #48286: Labels: SQL
thanks, merging to master/3.5!
Issue #48285: Labels: BUILD
gas-connector -> gcs-connector 
Issue #48284: Labels: SQL
cc @viirya @allisonwang-db @gengliangwang 
Issue #48283: Labels: SQL, CONNECT
cc @HyukjinKwon 
Issue #48282: Labels: SQL, PYTHON, CONNECT
Merged to master.
Issue #48281: Labels: SQL, MLLIB, STRUCTURED STREAMING, BUILD, SPARK SHELL, YARN, CORE, DSTREAM, CONNECT
Merged into master for Spark 4.0. Thanks @HyukjinKwon 
Issue #48280: Labels: BUILD
Got it. Thank you. That sounds enough for now because Java 23 is not LTS.\r\nMerged to master.
Issue #48279: Labels: SQL
We should say more about how the dead lock happens, e.g. the order how these two threads obtain locks.
Issue #48278: Labels: INFRA
Followup to https://github.com/apache/spark/pull/48269 \r\n@yaooqinn @dongjoon-hyun 
Issue #48277: Labels: SQL, ML, STRUCTURED STREAMING, PYTHON, CONNECT
cc @HyukjinKwon @zhengruifeng 
Issue #48276: Labels: SQL, ML
Merged into master for Spark 4.0. Thanks @zhengruifeng and @dongjoon-hyun 
Issue #48275: Labels: KUBERNETES
Thank you for making a PR, @fe2s .
Issue #48274: Labels: SQL, STRUCTURED STREAMING
cc - @HeartSaVioR - PTAL, thx !
Issue #48273: Labels: SQL, Stale, PYTHON, CONNECT
What do you mean by `ghfix`, @zhengruifeng ?
Issue #48272: Labels: SQL
cc @yaooqinn and @LuciferYang 
Issue #48271: Labels: SQL
Could you review this, @huaxingao ? After backporting, I found that the difference of `import` in branch-3.5.\r\n\r\nIn CI, the compilation already passed and `Unit Test` is running.\r\n```\r\n========================================================================\r\nRunning Spark unit tests\r\n========================================================================\r\n```
Issue #48270: Labels: SQL
cc @gengliangwang @cloud-fan here is the SQL pipe JOIN operator. This is the last "simple" one that is just adding a single "with*" method call that already exists in the AstBuilder.
Issue #48269: Labels: BUILD, PYTHON, PANDAS API ON SPARK
Merged to master.
Issue #48268: Labels: BUILD
Issue #48267: Labels: SQL, BUILD
Issue #48266: Labels: SQL, CONNECT
Because I messed up...
Issue #48265: Labels: SQL
BTW, please create JIRA ticker and link it in the PR title.
Issue #48264: Labels: SQL, CONNECT
@HyukjinKwon Could you take a look at this documentation improvement on `RuntimeConfig#get`? Thanks.
Issue #48263: Labels: INFRA
cc @HyukjinKwon 
Issue #48262: Labels: SQL
cc @LuciferYang @dongjoon-hyun 
Issue #48261: Labels: SQL, Stale
cc @MaxGekk @cloud-fan 
Issue #48260: Labels: SQL
cc @srielau @cloud-fan 
Issue #48259: Labels: SQL, PYTHON
cc @itholic 
Issue #48258: Labels: SQL, BUILD, AVRO, PROTOBUF
Issue #48257: Labels: SQL
Hi @dongjoon-hyun , the entire `DelegatingCatalogExtension` class is marked as Evolving, which already means semi-public APIs. We can probably add `@DeveloperApi` to all DS v2 APIs?\r\n\r\nAnd yes, we want to backport this to 3.5.
Issue #48256: Labels: SQL, PYTHON
@zhengruifeng @HyukjinKwon may I get your review please?
Issue #48255: Labels: SQL
@cloud-fan 
Issue #48254: Labels: SQL, STRUCTURED STREAMING, PYTHON
Issue #48253: Labels: SQL, STRUCTURED STREAMING, PYTHON
Thanks! Merging to master.
Issue #48252: Labels: SQL, CONNECT
Issue #48251: Labels: SQL, PYTHON
cc @dongjoon-hyun @cloud-fan @sunchao @huaxingao 
Issue #48250: Labels: SQL, STRUCTURED STREAMING
Issue #48249: Labels: KUBERNETES
Could you review this PR, @huaxingao ?
Issue #48248: Labels: SQL, ML, MLLIB, STRUCTURED STREAMING, KUBERNETES, YARN, EXAMPLES, CORE, DSTREAM
Also, cc @panbingkun since he is working on this area.
Issue #48247: Labels: SQL
Issue #48246: Labels: SQL, BUILD, PYTHON, CONNECT
@dongjoon-hyun good point, but I think we cannot reuse existing sql side `.sql` files for now, because this test is mainly for python side feature, e.g.\r\n```\r\n        df0 = self.spark.range(10)\r\n        df1 = self.spark.sql(\r\n            "SELECT * FROM {df} WHERE id > ?",\r\n            args=[1],\r\n            df=df0,\r\n        )\r\n```\r\nwhich takes a PySpark dataframe `df0` as a named argument.\r\n\r\nBut probably it is doable to introduce a similar framework for PySpark in the future.
Issue #48245: Labels: SQL
Merged to master for Apache Spark 4.0.0.
Issue #48244: Labels: SQL, PYTHON, CONNECT
merged to master
Issue #48243: Labels: SQL
@cloud-fan - a tiny followup cleanup.
Issue #48242: Labels: SQL, Stale
cc @srielau @cloud-fan 
Issue #48241: Labels: SQL, Stale
Issue #48240: Labels: SQL
Gentle ping @wangyum @zhengruifeng 
Issue #48239: Labels: SQL, PYTHON
cc @itholic 
Issue #48238: Labels: YARN
cc @LuciferYang  @cloud-fan @dongjoon-hyun
Issue #48237: Labels: SQL, Stale
## size(map_from_arrays(array(...), array(...)))\r\n### Benchmark code:\r\n```scala\r\nobject SizeBenchmark extends SqlBasedBenchmark {\r\n  private val N = 10_000_00\r\n  private val M = 100\r\n\r\n  private val path = "/Users/panbingkun/Developer/spark/spark-community/SizeBenchmark"\r\n  private val df = spark.range(N).to(new StructType().add("id", "int")).\r\n    withColumn("id1", col("id") + 1).\r\n    withColumn("id2", col("id") + 2).\r\n    withColumn("id3", col("id") + 3).\r\n    withColumn("id4", col("id") + 4).\r\n    withColumn("id5", col("id") + 5)\r\n  df.write.parquet(path)\r\n  private val table = spark.read.parquet(path)\r\n\r\n  private def doBenchmark(): Unit = {\r\n    table.selectExpr("size(map_from_arrays(array(id, id1, id2), array(id3, id4, id5)))").noop()\r\n  }\r\n\r\n  override def runBenchmarkSuite(mainArgs: Array[String]): Unit = {\r\n    runBenchmark("size") {\r\n      val benchmark = new Benchmark("size", N, output = output)\r\n      benchmark.addCase("optimize", M) { _ =>\r\n        doBenchmark()\r\n      }\r\n      benchmark.run()\r\n    }\r\n  }\r\n}\r\n\r\n```\r\n\r\n### Benchmark Result:\r\n#### Before\r\n```shell\r\nRunning benchmark: size\r\n  Running case: optimize\r\n  Stopped after 100 iterations, 15653 ms\r\n\r\nOpenJDK 64-Bit Server VM 17.0.10+7-LTS on Mac OS X 15.0\r\nApple M2\r\nsize:                                     Best Time(ms)   Avg Time(ms)   Stdev(ms)    Rate(M/s)   Per Row(ns)   Relative\r\n------------------------------------------------------------------------------------------------------------------------\r\noptimize                                            142            157           8          7.0         142.0       1.0X\r\n\r\n\r\nRunning benchmark: size\r\n  Running case: optimize\r\n  Stopped after 100 iterations, 17672 ms\r\n\r\nOpenJDK 64-Bit Server VM 17.0.10+7-LTS on Mac OS X 15.0\r\nApple M2\r\nsize:                                     Best Time(ms)   Avg Time(ms)   Stdev(ms)    Rate(M/s)   Per Row(ns)   Relative\r\n------------------------------------------------------------------------------------------------------------------------\r\noptimize                                            160            177          25          6.3         159.9       1.0X\r\n\r\n\r\nRunning benchmark: size\r\n  Running case: optimize\r\n  Stopped after 100 iterations, 15140 ms\r\n\r\nOpenJDK 64-Bit Server VM 17.0.10+7-LTS on Mac OS X 15.0\r\nApple M2\r\nsize:                                     Best Time(ms)   Avg Time(ms)   Stdev(ms)    Rate(M/s)   Per Row(ns)   Relative\r\n------------------------------------------------------------------------------------------------------------------------\r\noptimize                                            141            151          13          7.1         140.6       1.0X\r\n\r\n```\r\n\r\n#### After\r\n```shell\r\nAfter:\r\n\r\nRunning benchmark: size\r\n  Running case: optimize\r\n  Stopped after 100 iterations, 3923 ms\r\n\r\nOpenJDK 64-Bit Server VM 17.0.10+7-LTS on Mac OS X 15.0\r\nApple M2\r\nsize:                                     Best Time(ms)   Avg Time(ms)   Stdev(ms)    Rate(M/s)   Per Row(ns)   Relative\r\n------------------------------------------------------------------------------------------------------------------------\r\noptimize                                             24             39          13         42.4          23.6       1.0X\r\n\r\n\r\nRunning benchmark: size\r\n  Running case: optimize\r\n  Stopped after 100 iterations, 3778 ms\r\n\r\nOpenJDK 64-Bit Server VM 17.0.10+7-LTS on Mac OS X 15.0\r\nApple M2\r\nsize:                                     Best Time(ms)   Avg Time(ms)   Stdev(ms)    Rate(M/s)   Per Row(ns)   Relative\r\n------------------------------------------------------------------------------------------------------------------------\r\noptimize                                             31             38           7         32.1          31.2       1.0X\r\n\r\n\r\nRunning benchmark: size\r\n  Running case: optimize\r\n  Stopped after 100 iterations, 3040 ms\r\n\r\nOpenJDK 64-Bit Server VM 17.0.10+7-LTS on Mac OS X 15.0\r\nApple M2\r\nsize:                                     Best Time(ms)   Avg Time(ms)   Stdev(ms)    Rate(M/s)   Per Row(ns)   Relative\r\n------------------------------------------------------------------------------------------------------------------------\r\noptimize                                             23             30           7         42.8          23.4       1.0X\r\n```
Issue #48236: Labels: SQL, PYTHON
@zhengruifeng may I get a review please? Thank you!
Issue #48235: Labels: SQL
Merged to master.
Issue #48234: Labels: DOCS, dependencies, ruby
Issue #48233: Labels: BUILD, Stale
any update on this one @panbingkun 
Issue #48232: Labels: SQL, STRUCTURED STREAMING
Thanks! Merging to master.
Issue #48231: Labels: CORE, PYTHON
cc @HyukjinKwon 
Issue #48230: Labels: SQL, STRUCTURED STREAMING, PYTHON
Issue #48229: Labels: SQL, BUILD, CONNECT
Merging to master.
Issue #48228: Labels: SQL
The test failure is unrelated, thanks, merging to master!
Issue #48227: Labels: SQL, PYTHON, PANDAS API ON SPARK
Might need to run `dev/reformat-python` :)
Issue #48226: Labels: SQL
Issue #48225: Labels: SQL
cc @cloud-fan would you mind taking a look when you find some time? thanks
Issue #48224: Labels: SQL, CONNECT
cc @MaxGekk @cloud-fan 
Issue #48223: Labels: SQL, PYTHON, CONNECT
Merged to master.
Issue #48222: Labels: SQL
thanks, merging to master!
Issue #48221: Labels: SQL
Merged to master.
Issue #48220: Labels: SQL, Stale
@dongjoon-hyun @mridulm @HyukjinKwon Can you please help to review this PR.
Issue #48219: Labels: SQL, PYTHON
Merged to master, thank you!
Issue #48218: Labels: SQL, PYTHON
LGTM thank you!
Issue #48217: Labels: SQL, STRUCTURED STREAMING, CONNECT
BTW, please fill the PR description, @hvanhovell . 
Issue #48216: Labels: YARN
This pull request is intended for branch-3.5 and cherry-pick to branch-3.4. #48214 is the corresponding master branch pull request.
Issue #48215: Labels: SQL, DOCS, PYTHON
cc @cashmand For changes in the README file.
Issue #48214: Labels: YARN
BTW, according to the original code, this seems to be very old bug, right? Then, we need to backport this to `branch-3.4` too.
Issue #48213: Labels: SQL, STRUCTURED STREAMING, BUILD, CONNECT
Merging.
Issue #48212: Labels: SQL, STRUCTURED STREAMING, CONNECT
Merging.
Issue #48211: Labels: SQL, PYTHON
@cloud-fan @JoshRosen \r\nGiven the change, do you think it would make sense to add a copy() API to Dataset, sth like\r\n```\r\n/**\r\n * Create a copy of this Dataset with a fresh execution.\r\n *\r\n * While a Dataset object caches its query plan, this will create a new Dataset that will\r\n * start from scratch from the parsed logical plan.\r\n */\r\ndef copy(): Dataset[T] = {\r\n  new Dataset[T](this.sparkSession, this.queryExecution.logical, this.encoder)\r\n}\r\n```\r\nso that users can re-run all stages that are otherwise lazy cached?\r\nIt was relevant also before this change, because I don\
Issue #48210: Labels: SQL
ping @cloud-fan Please help me review this PR.
Issue #48209: Labels: SQL, BUILD, CONNECT
Manually tested the connect-jvm-client and connect-server modules using Maven, and all passed.\r\n\r\nMerged into master. 
Issue #48208: Labels: SQL, CONNECT
@juliuszsompolski Hi again! I know... this change is a bit complicated, so I wouldn\
Issue #48207: Labels: SQL, PYTHON
Merged to master.
Issue #48206: Labels: SQL, DOCS, PYTHON, CONNECT
FYI there is a similar effort in https://github.com/databricks/runtime/pull/82979\r\nBut it got reverted https://github.com/databricks/runtime/pull/98628/\r\nDouble confirm: have we checked with Kent Marten on this one?\r\n
Issue #48205: Labels: SQL, STRUCTURED STREAMING
cc - @ericm-db @HeartSaVioR - PTAL, thx !
Issue #48204: Labels: BUILD, CORE
Test first
Issue #48203: Labels: SQL
cc @cloud-fan \r\n\r\n
Issue #48202: Labels: SQL, Stale
After set `-XX:PerMethodRecompilationCutoff=10000`:\r\n![profile_executor_after](https://github.com/user-attachments/assets/148208d5-4144-46b6-b75b-6a9e23c169e5)\r\n
Issue #48201: Labels: YARN
Merged to master.
Issue #48200: Labels: SQL, CONNECT
cc @HyukjinKwon @grundprinzip @TakawaAkirayo 
Issue #48199: Labels: DOCS
maybe cc @viirya 
Issue #48198: Labels: KUBERNETES, CORE
cc @gengliangwang @LuciferYang 
Issue #48197: Labels: CORE
I have updated the number after this change.
Issue #48196: Labels: SQL, ML, STRUCTURED STREAMING, BUILD, CORE, PYTHON, AVRO, CONNECT
@srielau @panbingkun @nchammas @cloud-fan Could you review the PR, please.
Issue #48195: Labels: SQL, CONNECT
Merging to master.
Issue #48194: Labels: SQL
Merged to master.
Issue #48193: Labels: SQL
+1, LGTM. Merging to master.\r\nThank you, @HyukjinKwon.
Issue #48192: Labels: BUILD, DOCS
For the record, this is blocked by:\r\n- https://github.com/lightbend/genjavadoc/issues/364\r\n- https://github.com/com-lihaoyi/Ammonite/pull/1561
Issue #48191: Labels: SQL
Merged to master.
Issue #48190: Labels: SQL
cc: @cloud-fan @dbatomic to take a look.
Issue #48189: Labels: DOCS, CORE
Merged to master.
Issue #48188: Labels: SQL
Master branch is guarded from the `NullPointerException` caused by [SPARK-49739](https://issues.apache.org/jira/browse/SPARK-49739) [here](https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/jdbc/JDBCOptions.scala#L59). We should consider backporting the fix from https://github.com/apache/spark/pull/46955.
Issue #48187: Labels: SQL
@MaxGekk could you review please?
Issue #48186: Labels: SQL
Waiting for CI.
Issue #48185: Labels: SQL, STRUCTURED STREAMING, Stale
@HeartSaVioR \r\nCan you take a look ?\r\n
Issue #48184: Labels: SQL, PYTHON, CONNECT
merged to master
Issue #48183: Labels: SQL
> Should we preserve the version in `since`: `1.0.0`?\r\n\r\nThat makes sense, let me update it.
Issue #48182: Labels: SQL, Stale
Issue #48181: Labels: KUBERNETES
Also, I revised the PR description by adding K8s reference links because this is a community patch.
Issue #48180: Labels: ML, MLLIB, BUILD, PYTHON, PANDAS API ON SPARK
there is a new panda version https://pandas.pydata.org/pandas-docs/version/2.2.3/whatsnew/v2.2.3.html that have support for numpy 2.1https://github.com/pandas-dev/pandas/pull/59444
Issue #48179: Labels: SQL
cc @HyukjinKwon @zhengruifeng @allisonwang-db @xinrong-meng @MaxGekk 
Issue #48178: Labels: BUILD
Merged to master.
Issue #48177: Labels: SQL, CONNECT
@chenhao-db @cloud-fan This PR follows up on [the previous PR](https://github.com/apache/spark/pull/47920) that added support for duplicate keys where one corner case was left out. Can you review this PR? Thanks!
Issue #48176: Labels: No Labels
Merged to master.
Issue #48175: Labels: INFRA
Merged to master.\r\n\r\nThe website is now live. https://apache.github.io/spark/\r\n\r\nBTW, This patch also brings the unexpected [action](https://github.com/apache/spark/actions/workflows/pages/pages-build-deployment) alive again. I will ask INFRA to disable it one more time\r\n
Issue #48174: Labels: SQL
Not attempting to fix this behaviour  as it seems its like that since very begining
Issue #48173: Labels: SQL, CONNECT
Converting this back to draft as we think this change is a breaking change and there is a better way of doing it.
Issue #48172: Labels: SQL, Stale
@cloud-fan Can you go over this PR again whenever you have time? Thanks!
Issue #48171: Labels: BUILD
Could you review this PR when you have some time, @viirya ?
Issue #48170: Labels: BUILD, dependencies, java
Issue #48169: Labels: DOCS, dependencies, ruby
Issue #48168: Labels: SQL
Thanks, merging to master
Issue #48167: Labels: BUILD
Merged to master.
Issue #48166: Labels: SQL
Issue #48165: Labels: SQL
Can you link the PR with test changes here please?
Issue #48164: Labels: PYTHON, PANDAS API ON SPARK
Merged to master. Thank you all.
Issue #48163: Labels: SQL
thanks, merged to master
Issue #48162: Labels: SQL
@cloud-fan ready for merge
Issue #48161: Labels: PYTHON, PANDAS API ON SPARK
Thank you @dongjoon-hyun !
Issue #48160: Labels: SQL
@MaxGekk @yaooqinn @LuciferYang @guykhazma , this is a backport to 3.4 for #44524 can u please review this
Issue #48159: Labels: SQL, PYTHON, CONNECT
thanks, merged to master
Issue #48158: Labels: SQL, CONNECT
Issue #48157: Labels: SQL, PYTHON, CONNECT
thanks @dongjoon-hyun @xinrong-meng and @HyukjinKwon \r\n\r\nmerged to master
Issue #48156: Labels: BUILD, CORE
ready to go?
Issue #48155: Labels: SQL, BUILD
any update on this one @panbingkun ?
Issue #48154: Labels: BUILD
Or, we can remove the benchmark code from this PR.
Issue #48153: Labels: SQL, STRUCTURED STREAMING
@HeartSaVioR \r\nCan you take a look ?
Issue #48152: Labels: SQL
@panbingkun for reference, this mistake slipped in
Issue #48151: Labels: SQL, BUILD, CONNECT
Merging to master.
Issue #48150: Labels: SQL
Not needed.
Issue #48149: Labels: SQL, STRUCTURED STREAMING
> If PruneFilters triggers, we can lose a stateful operator and fail a query.\r\n\r\nCould we explain this better? Why and how the stateful operator is lost, and how does it fail?
Issue #48148: Labels: SQL, STRUCTURED STREAMING
cc - @jingz-db @HeartSaVioR - PTAL, thx !
Issue #48147: Labels: SQL, CONNECT
Merging to master.
Issue #48146: Labels: SQL, STRUCTURED STREAMING, BUILD, CONNECT
Merging to master
Issue #48145: Labels: SQL
@andylam-db @sigmod @cloud-fan 
Issue #48144: Labels: SQL
Can we add some tests?
Issue #48143: Labels: SQL, DOCS, PYTHON, CONNECT
cc @HyukjinKwon @MaxGekk here is the DataFrame support for the new `randstr` and `uniform` functions :)
Issue #48142: Labels: SQL, CONNECT
@jdesjean Hi, nice to meet you! Could you review this trivial change? Thanks!
Issue #48141: Labels: INFRA
Merged to master to recover CIs.
Issue #48140: Labels: BUILD
Test first
Issue #48139: Labels: SQL, BUILD, DOCS, INFRA, PYTHON, CONNECT
I guess we need to skip the UTs when `plotly` not installed, like\r\n\r\nhttps://github.com/apache/spark/blob/f3edc0c3570ea4b28f68607d6404c6b8d0801161/python/pyspark/pandas/tests/plot/test_frame_plot_plotly.py#L39
Issue #48138: Labels: SQL, Stale
Mind keeping the PR description template (https://github.com/apache/spark/blob/master/.github/PULL_REQUEST_TEMPLATE) and filing a JIRA?
Issue #48137: Labels: SQL, PYTHON, CONNECT
thanks @xinrong-meng , merged to master
Issue #48136: Labels: INFRA
Merged to master.\r\n\r\nThank you very much @dongjoon-hyun 
Issue #48135: Labels: SQL, PYTHON, CONNECT
Nice fix, thank you!
Issue #48134: Labels: CORE
cc @HyukjinKwon 